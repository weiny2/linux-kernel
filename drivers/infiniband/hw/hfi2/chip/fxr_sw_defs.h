/*
*------------------------------------------------------------------------------
*                                                                              
*  INTEL CONFIDENTIAL                                                          
*                                                                              
*  Copyright 2018 Intel Corporation All Rights Reserved.                 
*                                                                              
*  The source code contained or described herein and all documents related     
*  to the source code ("Material") are owned by Intel Corporation or its    
*  suppliers or licensors. Title to the Material remains with Intel            
*  Corporation or its suppliers and licensors. The Material contains trade     
*  secrets and proprietary and confidential information of Intel or its        
*  suppliers and licensors. The Material is protected by worldwide copyright   
*  and trade secret laws and treaty provisions. No part of the Material may    
*  be used, copied, reproduced, modified, published, uploaded, posted,         
*  transmitted, distributed, or disclosed in any way without Intel's prior     
*  express written permission.                                                 
*                                                                              
*  No license under any patent, copyright, trade secret or other intellectual  
*  property right is granted to or conferred upon you by disclosure or         
*  delivery of the Materials, either expressly, by implication, inducement,    
*  estoppel or otherwise. Any license under such intellectual property rights  
*  must be express and approved by Intel in writing.                           
*                                                                              
*------------------------------------------------------------------------------
*  Auto-generated by /p/hdk/rtl/proj_tools/sl2_tools/sl2_tools-srvr10nm-18ww26b/scripts/i_csrs/i_csrs.pl
*  i_csrs.pl Version 1.5 last modified on Thursday 6/28/18 12:45:58
*  /p/hdk/rtl/proj_tools/sl2_tools/sl2_tools-srvr10nm-18ww26b/scripts/i_csrs/i_csrs.pl -C -RVREGS -ST fxr_sw -o /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/fxr /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/020_TOC.xml /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/110_Link_Fabric_Sublayer.xml /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/131_Portals_Transport_Layer.xml /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/200_Software_Interfaces.xml /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/140_OutstandingRequest_and_Reliability.xml /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/163_Programmable_Engine.xml /nfs/sc/disks/slx_0108/pvesv/fxr_autogen/repo_xml/260_PerfCounters.xml
*------------------------------------------------------------------------------
*/

#ifndef DEF_FXR_SW_SW_DEF
#define DEF_FXR_SW_SW_DEF

#define PTL_RANK_ANY						4294967295
#define PTL_UID_ANY						4294967295
#define PTL_PID_ANY						4095
#define PTL_LID_ANY						16777215
#define PTL_NO_ACK_REQ						0
#define PTL_OC_ACK_REQ						0
#define PTL_CT_ACK_REQ						2
#define PTL_ACK_REQ						2
#define PTL_CT_NONE						0
#define PTL_EQ_NONE						0
#define PTL_EVENT_COMM_DISABLE					1
#define PTL_EVENT_SUCCESS_DISABLE				2
#define PTL_EVENT_OVER_DISABLE					4
#define PTL_EVENT_LINK_DISABLE					8
#define PTL_EVENT_FLOWCTRL_DISABLE				16
#define PTL_EVENT_UNLINK_DISABLE				32
#define PTL_IOVEC						64
#define PTL_EVENT_CT_BYTES					128
#define PTL_EVENT_CT_OVERFLOW					256
#define PTL_EVENT_CT_COMM					512
#define PTL_USE_ONCE						1024
#define PTL_ACK_DISABLE						2048
#define PTL_UNEXPECTED_HDR_DISABLE				4096
#define PTL_NO_ATOMIC						8192
#define PTL_MANAGE_LOCAL					16384
#define PTL_ME_NO_TRUNCATE					32768
#define PTL_OP_PUT						65536
#define PTL_OP_GET						131072
#define PTL_MAY_ALIGN						262144
#define PTL_EVENT_CT_LINK					524288
#define PTL_IS_ACCESSIBLE					1048576
#define PTL_MD_EVENT_SUCCESS_DISABLE				1
#define PTL_MD_EVENT_CT_BYTES					2
#define PTL_MD_EVENT_CT_REPLY					4
#define PTL_MD_EVENT_CT_SEND					8
#define PTL_MD_EVENT_CT_ACK					16
#define PTL_MD_EVENT_SEND_DISABLE				32
#define PTL_MD_RESERVED_IOV					64
#define NONPTL_SC4						128
#define PTL_MD_VOLATILE						256
#define PTL_MD_UNORDERED					512
#define FXR_NUM_NIS						4
#define FXR_NUM_PTES						256
#define FXR_NUM_EVENT_HANDLES					2048
#define FXR_MAX_ENTRIES						65535
#define FXR_PTE_SIZE						32
#define FXR_CT_SIZE						32
#define FXR_EQD_SIZE						16
#define FXR_ENTRY_SIZE						128
#define FXR_PTE_OFFSET						0
#define FXR_PTE_ARRAY_SIZE					32768
#define FXR_CT_OFFSET						32768
#define FXR_CT_ARRAY_SIZE					262144
#define FXR_EQD_OFFSET						294912
#define FXR_EQD_ARRAY_SIZE					131072
#define FXR_EQ_HEAD_OFFSET					425984
#define FXR_EQ_HEAD_ARRAY_SIZE					32768
#define FXR_TRIG_OP_OFFSET					458752
#define NONPTL_RCV_EAGER_FULL_CNT				0
#define NONPTL_RCV_HDR_OVERFLOW_CNT				1
#define NONPTL_RCV_INVALID_CTX_CNT				2
#define NONPTL_RCV_DISABLED_CTX_CNT				3
#define NONPTL_RCV_TID_GEN_MISMATCH_CNT				4
#define NONPTL_RCV_TID_SEQ_MISMATCH_CNT				5
#define AUTH_COMPLETE						0
#define AUTH_SUCCESS						1

/*
*  Enumerations from tables
*/
/* Enumeration from Table titled: L2 Fabric Packet Type Encoding (Enum - l2_t) - 2 bits
*                        In File: 020_TOC.xml
*/
#if defined(__STDC__)

enum l2 {
          HDR_8B = 0,           /* 8B L2 header. See Section 8.2.2.1 */
         HDR_10B = 1,           /* 10B L2 header. See Section 8.2.2.2 */
         HDR_16B = 2,           /* 16B L2 header. See Section 8.2.2.3 */
         HDR_EXT = 3            /* 9B L2 header or Future L2 headers. See L2Ext below. */
};

#else

#define   HDR_8B   0            /* 8B L2 header. See Section 8.2.2.1 */
#define  HDR_10B   1            /* 10B L2 header. See Section 8.2.2.2 */
#define  HDR_16B   2            /* 16B L2 header. See Section 8.2.2.3 */
#define  HDR_EXT   3             /* 9B L2 header or Future L2 headers. See L2Ext below. */

#endif


/* Enumeration from Table titled: L2 Extension Encoding (Enum - l2ext_t) - 4 bits
*                        In File: 020_TOC.xml
*/
#if defined(__STDC__)

enum l2ext {
                  HDR_9B = 0,           /* 9B L2 header. See Section 8.2.2.4 */
            HDR_FUTURE_0 = 1,           /* Future L2 Expansion. See Section 8.2.2.5 */
            HDR_FUTURE_1 = 1,           
            HDR_FUTURE_2 = 2,           
            HDR_FUTURE_3 = 3,           
            HDR_FUTURE_4 = 4,           
            HDR_FUTURE_5 = 5,           
            HDR_FUTURE_6 = 6,           
            HDR_FUTURE_7 = 7,           
            HDR_FUTURE_8 = 8,           
            HDR_FUTURE_9 = 9,           
           HDR_FUTURE_10 = 10,          
           HDR_FUTURE_11 = 11,          
           HDR_FUTURE_12 = 12,          
           HDR_FUTURE_13 = 13,          
           HDR_FUTURE_14 = 14           
};

#else

#define           HDR_9B   0            /* 9B L2 header. See Section 8.2.2.4 */
#define     HDR_FUTURE_0   1            /* Future L2 Expansion. See Section 8.2.2.5 */
#define     HDR_FUTURE_1   1            
#define     HDR_FUTURE_2   2            
#define     HDR_FUTURE_3   3            
#define     HDR_FUTURE_4   4            
#define     HDR_FUTURE_5   5            
#define     HDR_FUTURE_6   6            
#define     HDR_FUTURE_7   7            
#define     HDR_FUTURE_8   8            
#define     HDR_FUTURE_9   9            
#define    HDR_FUTURE_10   10           
#define    HDR_FUTURE_11   11           
#define    HDR_FUTURE_12   12           
#define    HDR_FUTURE_13   13           
#define    HDR_FUTURE_14   14            

#endif


/* Enumeration from Table titled: L4 Encoding for the Different Packet Formats (Enum - l4_t) - 8 bits
*                        In File: 020_TOC.xml
*/
#if defined(__STDC__)

enum l4 {
                           L4_FM = 8,           /* Fabric Management */
                           L4_IB = 9,           /* Infiniband Local */
                    L4_IB_GLOBAL = 10,          /* Infiniband Global */
                          L4_ETH = 120,         /* Ethernet Packet */
                L4_ETH_EXCEPTION = 121,         /* Ethernet Exception Packet */
                         PTL_RTS = 240,         /* Portals Request To Send (RTS) for Put/Atomic/Get */
                    PTL_REND_REQ = 241,         /* Portals Basic Rendezvous Request (Put/Atomic/Get) */
                  PTL_REND_EVENT = 242,         /* Portals Rendezvous Event */
                PTL_E2E_CTRL_REQ = 243,         /* Portals E2E Control Request. Ordering rules dependent on OPCODE. */
               PTL_E2E_CTRL_RESP = 244,         /* Portals E2E Control Response. */
                    PTL_VERBS_RC = 245,         /* Reserved */
                     PTL_REQUEST = 248,         /* Portals Request (Put/Atomic/Get) */
               PTL_FETCH_REQUEST = 249,         /* Portals Fetching Request (FetchAtomic/TwoOperand Atomics) */
                    PTL_RESPONSE = 250,         /* Portals Reply / Portal Full ACK / E2E Extended ACK */
                          PTL_UD = 251,         /* Reserved */
              PTL_E2E_BASIC_ACK0 = 252,         /* Portals E2E Basic ACK, pkt_id[15:14]=00b */
              PTL_E2E_BASIC_ACK1 = 253,         /* Portals E2E Basic ACK, pkt_id[15:14]=01b */
              PTL_E2E_BASIC_ACK2 = 254,         /* Portals E2E Basic ACK, pkt_id[15:14]=10b */
              PTL_E2E_BASIC_ACK3 = 255          /* Portals E2E Basic ACK, pkt_id[15:14]=11b */
};

#else

#define                    L4_FM   8            /* Fabric Management */
#define                    L4_IB   9            /* Infiniband Local */
#define             L4_IB_GLOBAL   10           /* Infiniband Global */
#define                   L4_ETH   120          /* Ethernet Packet */
#define         L4_ETH_EXCEPTION   121          /* Ethernet Exception Packet */
#define                  PTL_RTS   240          /* Portals Request To Send (RTS) for Put/Atomic/Get */
#define             PTL_REND_REQ   241          /* Portals Basic Rendezvous Request (Put/Atomic/Get) */
#define           PTL_REND_EVENT   242          /* Portals Rendezvous Event */
#define         PTL_E2E_CTRL_REQ   243          /* Portals E2E Control Request. Ordering rules dependent on OPCODE. */
#define        PTL_E2E_CTRL_RESP   244          /* Portals E2E Control Response. */
#define             PTL_VERBS_RC   245          /* Reserved */
#define              PTL_REQUEST   248          /* Portals Request (Put/Atomic/Get) */
#define        PTL_FETCH_REQUEST   249          /* Portals Fetching Request (FetchAtomic/TwoOperand Atomics) */
#define             PTL_RESPONSE   250          /* Portals Reply / Portal Full ACK / E2E Extended ACK */
#define                   PTL_UD   251          /* Reserved */
#define       PTL_E2E_BASIC_ACK0   252          /* Portals E2E Basic ACK, pkt_id[15:14]=00b */
#define       PTL_E2E_BASIC_ACK1   253          /* Portals E2E Basic ACK, pkt_id[15:14]=01b */
#define       PTL_E2E_BASIC_ACK2   254          /* Portals E2E Basic ACK, pkt_id[15:14]=10b */
#define       PTL_E2E_BASIC_ACK3   255           /* Portals E2E Basic ACK, pkt_id[15:14]=11b */

#endif


/* Enumeration from Table titled: RC Encoding (Enum - rc_t) - 3 bits
*                        In File: 020_TOC.xml
*/
#if defined(__STDC__)

enum rc {
                   RC_IN_ORDER_0 = 0,           /* Routing method 0 for in-order traffic */
                   RC_IN_ORDER_1 = 1,           /* Routing method 1 for in-order traffic */
                   RC_IN_ORDER_2 = 2,           /* Routing method 2 for in-order traffic */
                   RC_IN_ORDER_3 = 3,           /* Routing method 3 for in-order traffic */
               RC_OUT_OF_ORDER_0 = 4,           /* Routing method 0 for out-of-order traffic. Often it is used for adaptive routing. */
               RC_OUT_OF_ORDER_1 = 5,           /* Routing method 1 for out-of-order traffic. Often it is used for adaptive routing. */
               RC_OUT_OF_ORDER_2 = 6,           /* Routing method 2 for out-of-order traffic. Often it is used for adaptive routing. */
               RC_OUT_OF_ORDER_3 = 7            /* Routing method 3 for out-of-order traffic. Often it is used for adaptive routing. */
};

#else

#define            RC_IN_ORDER_0   0            /* Routing method 0 for in-order traffic */
#define            RC_IN_ORDER_1   1            /* Routing method 1 for in-order traffic */
#define            RC_IN_ORDER_2   2            /* Routing method 2 for in-order traffic */
#define            RC_IN_ORDER_3   3            /* Routing method 3 for in-order traffic */
#define        RC_OUT_OF_ORDER_0   4            /* Routing method 0 for out-of-order traffic. Often it is used for adaptive routing. */
#define        RC_OUT_OF_ORDER_1   5            /* Routing method 1 for out-of-order traffic. Often it is used for adaptive routing. */
#define        RC_OUT_OF_ORDER_2   6            /* Routing method 2 for out-of-order traffic. Often it is used for adaptive routing. */
#define        RC_OUT_OF_ORDER_3   7             /* Routing method 3 for out-of-order traffic. Often it is used for adaptive routing. */

#endif


/* Enumeration from Table titled: OPCODE Assignments for Basic Requests (PTL_REQUEST), Rendezvous RTS (PTL_RTS), Rendezvous Requests (PTL_REND_REQ), and Rendezvous Events (PTL_REND_EVENT) (Enum - ptl_op_req_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_op_req {
             PTL_REQ_PUT = 0,           /* Put data to the target address */
             PTL_REQ_GET = 1,           /* Get data from the target address and return it to the initiator */
           PTL_REQ_ERROR = 2,           /* Transfer aborted in error at the initiator. This opcode enables the initiator to clean up any pending connection state (e.g. rendezvous state). */
        PTL_REQ_GET_ECTS = 3,           /* A Get request (PTL_REQ_GET) that was issues as part of a transaction where an ECTS was received. This may only be used with PTL_REND_REQ and has special processing semantics at the target. */
             PTL_REQ_MIN = 4,           /* Compute the minimum of the initiator and target value[TargetMem] <- [PacketPayload] < [TargetMem] ? [PacketPayload] : [TargetMem] */
             PTL_REQ_MAX = 5,           /* Compute the maximum of the initiator and target value[TargetMem] <- [PacketPayload] >[TargetMem] ? [PacketPayload] : [TargetMem] */
             PTL_REQ_SUM = 6,           /* Compute the sum of the initiator and target value. This is a non-saturating addition, so that the result will simply roll-over.[TargetMem] <- [PacketPaylaod] + [TargetMem] */
            PTL_REQ_DIFF = 7,           /* Compute the difference of the target and initiator value (target-initiator). This is a non-saturating subtraction, so that the result will simply roll-over.[TargetMem] <- [TargetMem] - [PacketPaylaod] */
            PTL_REQ_PROD = 8,           /* Compute the product of the initiator and target value. The result is the low N bits of an NxN product.[TargetMem] <- [PacketPaylaod] * [TargetMem] */
             PTL_REQ_LOR = 9,           /* Compute the logical OR of the initiator and target value[TargetMem] <- [PacketPaylaod] || [TargetMem]if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
            PTL_REQ_LAND = 10,          /* Compute the logical AND of the initiator and target value[TargetMem] <- [PacketPaylaod] && [TargetMem]if (PacketPayload != 0) && TargetMem !=0) TargetMem = 1; */
            PTL_REQ_LXOR = 11,          /* Compute the logical XOR of the initiator and target value[TargetMem] <- ([PacketPayload] && ![TargetMem]) || (![PacketPayload] && [TargetMem])(there is not a logical XOR operator in C)if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
             PTL_REQ_BOR = 12,          /* Compute the bitwise OR of the initiator and target value[TargetMem] <- [PacketPayload] | [TargetMem] */
            PTL_REQ_BAND = 13,          /* Compute the bitwise AND of the initiator and target value[TargetMem] <- [PacketPayload] & [TargetMem] */
            PTL_REQ_BXOR = 14           /* Compute the bitwise XOR of the initiator and target value[TargetMem] <- [PacketPayload] ^ [TargetMem] */
};

#else

#define      PTL_REQ_PUT   0            /* Put data to the target address */
#define      PTL_REQ_GET   1            /* Get data from the target address and return it to the initiator */
#define    PTL_REQ_ERROR   2            /* Transfer aborted in error at the initiator. This opcode enables the initiator to clean up any pending connection state (e.g. rendezvous state). */
#define PTL_REQ_GET_ECTS   3            /* A Get request (PTL_REQ_GET) that was issues as part of a transaction where an ECTS was received. This may only be used with PTL_REND_REQ and has special processing semantics at the target. */
#define      PTL_REQ_MIN   4            /* Compute the minimum of the initiator and target value[TargetMem] <- [PacketPayload] < [TargetMem] ? [PacketPayload] : [TargetMem] */
#define      PTL_REQ_MAX   5            /* Compute the maximum of the initiator and target value[TargetMem] <- [PacketPayload] >[TargetMem] ? [PacketPayload] : [TargetMem] */
#define      PTL_REQ_SUM   6            /* Compute the sum of the initiator and target value. This is a non-saturating addition, so that the result will simply roll-over.[TargetMem] <- [PacketPaylaod] + [TargetMem] */
#define     PTL_REQ_DIFF   7            /* Compute the difference of the target and initiator value (target-initiator). This is a non-saturating subtraction, so that the result will simply roll-over.[TargetMem] <- [TargetMem] - [PacketPaylaod] */
#define     PTL_REQ_PROD   8            /* Compute the product of the initiator and target value. The result is the low N bits of an NxN product.[TargetMem] <- [PacketPaylaod] * [TargetMem] */
#define      PTL_REQ_LOR   9            /* Compute the logical OR of the initiator and target value[TargetMem] <- [PacketPaylaod] || [TargetMem]if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
#define     PTL_REQ_LAND   10           /* Compute the logical AND of the initiator and target value[TargetMem] <- [PacketPaylaod] && [TargetMem]if (PacketPayload != 0) && TargetMem !=0) TargetMem = 1; */
#define     PTL_REQ_LXOR   11           /* Compute the logical XOR of the initiator and target value[TargetMem] <- ([PacketPayload] && ![TargetMem]) || (![PacketPayload] && [TargetMem])(there is not a logical XOR operator in C)if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
#define      PTL_REQ_BOR   12           /* Compute the bitwise OR of the initiator and target value[TargetMem] <- [PacketPayload] | [TargetMem] */
#define     PTL_REQ_BAND   13           /* Compute the bitwise AND of the initiator and target value[TargetMem] <- [PacketPayload] & [TargetMem] */
#define     PTL_REQ_BXOR   14            /* Compute the bitwise XOR of the initiator and target value[TargetMem] <- [PacketPayload] ^ [TargetMem] */

#endif


/* Enumeration from Table titled: OPCODE Assignments for Fetching Operations, including Swap, CSwap, and Fetching Atomics (Enum - ptl_fetch_op_req_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_fetch_op_req {
                   PTL_REQ_FETCHING_SWAP = 0,           /* Swap the initiator and target value, and return the target value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] */
                    PTL_REQ_FETCHING_MIN = 4,           /* Compute the minimum of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] < [TargetMem] ? [PacketPayload] : [TargetMem] */
                    PTL_REQ_FETCHING_MAX = 5,           /* Compute the maximum of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] >[TargetMem] ? [PacketPayload] : [TargetMem] */
                    PTL_REQ_FETCHING_SUM = 6,           /* Compute the sum of the initiator and target value and return the original value. This is a non-saturating addition, so that the result will simply roll-over.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPaylaod] + [TargetMem] */
                   PTL_REQ_FETCHING_DIFF = 7,           /* Compute the difference of the target and initiator value (target-initiator) and return the original value. This is a non-saturating subtraction, so that the result will simply roll-over.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [TargetMem] - [PacketPaylaod] */
                   PTL_REQ_FETCHING_PROD = 8,           /* Compute the product of the initiator and target value and return the original value. The result is the low N bits of an NxN product.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPaylaod] * [TargetMem] */
                    PTL_REQ_FETCHING_LOR = 9,           /* Compute the logical OR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPaylaod] || [TargetMem]if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
                   PTL_REQ_FETCHING_LAND = 10,          /* Compute the logical AND of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem] [TargetMem] <- [PacketPaylaod] && [TargetMem]if (PacketPayload != 0) && TargetMem !=0) TargetMem = 1; */
                   PTL_REQ_FETCHING_LXOR = 11,          /* Compute the logical XOR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- ([PacketPayload] && ![TargetMem]) || (![PacketPayload] && [TargetMem])(there is not a logical XOR operator in C)if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
                    PTL_REQ_FETCHING_BOR = 12,          /* Compute the bitwise OR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] | [TargetMem] */
                   PTL_REQ_FETCHING_BAND = 13,          /* Compute the bitwise AND of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] & [TargetMem] */
                   PTL_REQ_FETCHING_BXOR = 14,          /* Compute the bitwise XOR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] ^ [TargetMem] */
                  PTL_REQ_FETCHING_CSWAP = 17,          /* A conditional version of the swap operation. If the value of the operand is equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] == [TargetMem] ? [PacketPayload] : [TargetMem] */
               PTL_REQ_FETCHING_CSWAP_NE = 18,          /* A conditional version of the swap operation. If the value of the operand is not equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] != [TargetMem] ? [PacketPayload] : [TargetMem] */
               PTL_REQ_FETCHING_CSWAP_LE = 19,          /* A conditional version of the swap operation. If the value of the operand is less than or equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] <= [TargetMem] ? [PacketPayload] : [TargetMem] */
               PTL_REQ_FETCHING_CSWAP_LT = 20,          /* A conditional version of the swap operation. If the value of the operand is less than the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] < [TargetMem] ? [PacketPayload] : [TargetMem] */
               PTL_REQ_FETCHING_CSWAP_GE = 21,          /* A conditional version of the swap operation. If the value of the operand is greater than or equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] >= [TargetMem] ? [PacketPayload] : [TargetMem] */
               PTL_REQ_FETCHING_CSWAP_GT = 22,          /* A conditional version of the swap operation. If the value of the operand is greater than the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] >[TargetMem] ? [PacketPayload] : [TargetMem] */
                  PTL_REQ_FETCHING_MSWAP = 23           /* A masked version of the swap operation. Update the bits of the target value that are set to 1 in the operand using the bits in the initiator value. Return the target value. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- ([TargetMem] & ~[Operand]) | ([PacketPayload] & [Operand]) */
};

#else

#define            PTL_REQ_FETCHING_SWAP   0            /* Swap the initiator and target value, and return the target value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] */
#define             PTL_REQ_FETCHING_MIN   4            /* Compute the minimum of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] < [TargetMem] ? [PacketPayload] : [TargetMem] */
#define             PTL_REQ_FETCHING_MAX   5            /* Compute the maximum of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] >[TargetMem] ? [PacketPayload] : [TargetMem] */
#define             PTL_REQ_FETCHING_SUM   6            /* Compute the sum of the initiator and target value and return the original value. This is a non-saturating addition, so that the result will simply roll-over.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPaylaod] + [TargetMem] */
#define            PTL_REQ_FETCHING_DIFF   7            /* Compute the difference of the target and initiator value (target-initiator) and return the original value. This is a non-saturating subtraction, so that the result will simply roll-over.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [TargetMem] - [PacketPaylaod] */
#define            PTL_REQ_FETCHING_PROD   8            /* Compute the product of the initiator and target value and return the original value. The result is the low N bits of an NxN product.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPaylaod] * [TargetMem] */
#define             PTL_REQ_FETCHING_LOR   9            /* Compute the logical OR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPaylaod] || [TargetMem]if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
#define            PTL_REQ_FETCHING_LAND   10           /* Compute the logical AND of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem] [TargetMem] <- [PacketPaylaod] && [TargetMem]if (PacketPayload != 0) && TargetMem !=0) TargetMem = 1; */
#define            PTL_REQ_FETCHING_LXOR   11           /* Compute the logical XOR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- ([PacketPayload] && ![TargetMem]) || (![PacketPayload] && [TargetMem])(there is not a logical XOR operator in C)if (PacketPayload != 0) || TargetMem !=0) TargetMem = 1; */
#define             PTL_REQ_FETCHING_BOR   12           /* Compute the bitwise OR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] | [TargetMem] */
#define            PTL_REQ_FETCHING_BAND   13           /* Compute the bitwise AND of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] & [TargetMem] */
#define            PTL_REQ_FETCHING_BXOR   14           /* Compute the bitwise XOR of the initiator and target value and return the original value[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [PacketPayload] ^ [TargetMem] */
#define           PTL_REQ_FETCHING_CSWAP   17           /* A conditional version of the swap operation. If the value of the operand is equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] == [TargetMem] ? [PacketPayload] : [TargetMem] */
#define        PTL_REQ_FETCHING_CSWAP_NE   18           /* A conditional version of the swap operation. If the value of the operand is not equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] != [TargetMem] ? [PacketPayload] : [TargetMem] */
#define        PTL_REQ_FETCHING_CSWAP_LE   19           /* A conditional version of the swap operation. If the value of the operand is less than or equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] <= [TargetMem] ? [PacketPayload] : [TargetMem] */
#define        PTL_REQ_FETCHING_CSWAP_LT   20           /* A conditional version of the swap operation. If the value of the operand is less than the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] < [TargetMem] ? [PacketPayload] : [TargetMem] */
#define        PTL_REQ_FETCHING_CSWAP_GE   21           /* A conditional version of the swap operation. If the value of the operand is greater than or equal to the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] >= [TargetMem] ? [PacketPayload] : [TargetMem] */
#define        PTL_REQ_FETCHING_CSWAP_GT   22           /* A conditional version of the swap operation. If the value of the operand is greater than the target value, the initiator and target value are swapped. The target value is always returned. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- [Operand] >[TargetMem] ? [PacketPayload] : [TargetMem] */
#define           PTL_REQ_FETCHING_MSWAP   23            /* A masked version of the swap operation. Update the bits of the target value that are set to 1 in the operand using the bits in the initiator value. Return the target value. This operation is limited to single data items.[ReplyPacketPayload] <- [TargetMem][TargetMem] <- ([TargetMem] & ~[Operand]) | ([PacketPayload] & [Operand]) */

#endif


/* Enumeration from Table titled: OPCODE Assignments for Verbs RC Requests (Enum - ptl_op_rc_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_op_rc {
               PTL_RC_SEND_FIRST = 0,           /* The first packet in a multi-packet send. A message with a first packet must have a last packet. */
              PTL_RC_SEND_MIDDLE = 1,           /* Any packets that are not the first or last packet in a multi packet message. A message with a middle packet must also have a first and last packet. */
                PTL_RC_SEND_LAST = 2,           /* The last packet in a message. A single packet message will only have a last packet. */
            PTL_RC_SEND_LAST_IMM = 3,           /* The last packet in a message that contains immediate data. A single packet message will only have a last packet. */
            PTL_RC_SEND_LAST_INV = 4,           /* The last packet in a message that contains an RKEY to be invalidated. A single packet message will only have a last packet. */
               PTL_RC_LAST_ERROR = 5,           /* An in-flight message caused an error at the initiator as is terminating. This is used to terminate a SEND operation or an RDMA with Immediate operation. */
                  PTL_RC_RDMA_WR = 8,           /* An RDMA packet. May be the first, middle, or last packet for a standard RDMA write. May be any packet other than the first or last packet for an RDMA write with immediate. */
        PTL_RC_RDMA_WR_FIRST_IMM = 9,           /* The first packet in an RDMA Write with immediate. A message with a first packet must also have a last packet. */
         PTL_RC_RDMA_WR_LAST_IMM = 10,          /* The last packet in an RDMA Write with immediate. A message with a last packet may be a single packet message, or may have a first packet and 0 or more RDMA_WR packets. */
                  PTL_RC_RDMA_RD = 11,          /* An RDMA read request. An RDMA read request is generated for each packet of response that is needed. */
            PTL_RC_RDMA_CMP_SWAP = 12,          /* A single packet, compare and swap operation */
           PTL_RC_RDMA_FETCH_ADD = 13,          /* A single packet, fetch and add operation. */
                PTL_RC_EXCEPTION = 16           /* An exception packet that is used for software to software control. This is a single packet message only. */
};

#else

#define        PTL_RC_SEND_FIRST   0            /* The first packet in a multi-packet send. A message with a first packet must have a last packet. */
#define       PTL_RC_SEND_MIDDLE   1            /* Any packets that are not the first or last packet in a multi packet message. A message with a middle packet must also have a first and last packet. */
#define         PTL_RC_SEND_LAST   2            /* The last packet in a message. A single packet message will only have a last packet. */
#define     PTL_RC_SEND_LAST_IMM   3            /* The last packet in a message that contains immediate data. A single packet message will only have a last packet. */
#define     PTL_RC_SEND_LAST_INV   4            /* The last packet in a message that contains an RKEY to be invalidated. A single packet message will only have a last packet. */
#define        PTL_RC_LAST_ERROR   5            /* An in-flight message caused an error at the initiator as is terminating. This is used to terminate a SEND operation or an RDMA with Immediate operation. */
#define           PTL_RC_RDMA_WR   8            /* An RDMA packet. May be the first, middle, or last packet for a standard RDMA write. May be any packet other than the first or last packet for an RDMA write with immediate. */
#define PTL_RC_RDMA_WR_FIRST_IMM   9            /* The first packet in an RDMA Write with immediate. A message with a first packet must also have a last packet. */
#define  PTL_RC_RDMA_WR_LAST_IMM   10           /* The last packet in an RDMA Write with immediate. A message with a last packet may be a single packet message, or may have a first packet and 0 or more RDMA_WR packets. */
#define           PTL_RC_RDMA_RD   11           /* An RDMA read request. An RDMA read request is generated for each packet of response that is needed. */
#define     PTL_RC_RDMA_CMP_SWAP   12           /* A single packet, compare and swap operation */
#define    PTL_RC_RDMA_FETCH_ADD   13           /* A single packet, fetch and add operation. */
#define         PTL_RC_EXCEPTION   16            /* An exception packet that is used for software to software control. This is a single packet message only. */

#endif


/* Enumeration from Table titled: OPCODE Assignments for UD Requests (Enum - ptl_op_ud_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_op_ud {
             PTL_UD_SEND = 0,           /* UD Send for Verbs */
         PTL_UD_SEND_IMM = 1,           /* UD Send with Immediate for Verbs */
        PTL_UD_EXCEPTION = 2            /* An exception packet that is used for software to software control. This is a single packet message only. */
};

#else

#define      PTL_UD_SEND   0            /* UD Send for Verbs */
#define  PTL_UD_SEND_IMM   1            /* UD Send with Immediate for Verbs */
#define PTL_UD_EXCEPTION   2             /* An exception packet that is used for software to software control. This is a single packet message only. */

#endif


/* Enumeration from Table titled: OPCODE Assignments for Portals Responses (Enum - ptl_op_response_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_op_response {
                                 PTL_ACK = 0,           /* Normal Portals ACKVerbs: Normal ACK */
                         PTL_ACK_REFUSED = 1,           /* Portals ACK was refused by the target process. The stateful response is needed to convey to the initiator side implementation that a PTL_EVENT_ACK should not be delivered for this operation. This allows the initiator to free resources that might be reserved for the purpose. PTL_ACK_REFUSED may be generated in cases where the message does not match any buffer at the target or in cases where the target has explicitly indicated that the buffer should not generate an ACK. */
                               PTL_REPLY = 2,           /* Normal Portals Reply */
                          PTL_REPLY_ECTS = 3,           /* A Portals reply to a PTL_REQ_GET_ECTS. These packets receive an acknowledgement, but do not retransmit and do not notify the target of an error. Errors are returned to the initiator, which notifies the target in the Event message.Note for posterity: this could have been stateless; however, implementation oriented decisions caused this to be set as stateful. */
                         PTL_SHORT_REPLY = 4,           /* Portals Reply (response to a Get/Swap/Fetching Atomic operation) with only enough information for an OC event. This enables a smaller packet format. */
                        PTL_NACK_PTE_DIS = 5,           /* The Portals operation encountered a disabled PT Entry, or the operation caused a PT Entry to become disabled. This NACK frequently occurs as the result of a flow-control error.Verbs: Flow control was invoked */
                          PTL_NACK_PERMV = 6,           /* The Portals operation failed the permissions check at the targetVerbs: Permissions violation on the QP or RKey. */
                            PTL_NACK_OPV = 7,           /* The Portals operation specified an invalid operation (Put/Get) for the ME or LE it resolved toVerbs: Illegal operation (Read/Write/Atomic) at the target. */
                           PTL_NACK_SEGV = 8,           /* The Portals operation resolved to a virtual address that would have caused a segmentation fault.Verbs: Memory access encountered a segmentation fault. */
                        PTL_NACK_INV_TGT = 9,           /* The Portals operation specified an invalid target PID or target PT Index. Verbs: Invalid QP or Invalid RKey at target */
                    PTL_NACK_UNSUPPORTED = 10,          /* Indicates that an unsupported operation was attempted. */
                  PTL_NACK_UNCORRECTABLE = 11,          /* Indicates that an uncorrectable error was detected after the E2E sequence number checks. Promoted from PTL_ACK, PTL_ACK_REFUSED, PTL_REPLY, or PTL_SHORT_REPLY. */
                        PTL_E2E_ONLY_ACK = 16,          /* Used for an E2E extended ACK format */
               PTL_E2E_ONLY_ACK_DISTANCE = 17,          /* A distance adjusting acknowledgment */
          PTL_E2E_ONLY_ACK_UNCORRECTABLE = 18,          /* Indicates that an uncorrectable error was detected after the E2E sequence number checks. Promoted from PTL_E2E_ONLY_ACK. Because this is not stateful, this is best effort delivery only and could be interpreted as a simple ack. */
                   PTL_E2E_ONLY_NACK_OOS = 19,          /* A packet was received out-of-sequence. The next expected sequence number is indicated in the Expected PSN field. An echo of the request PSN is contained in ACK_PSN. */
                    PTL_E2E_ONLY_NACK_NC = 21,          /* A packet was received, but the local sequence table indicates that the nodes are not connected for this traffic class. The packet is not retransmitted and is treated as completed by the initiator (e.g. failed). This failure tears down the connection at the initiator. */
              PTL_E2E_ONLY_NACK_RESOURCE = 22,          /* A packet was received, but local reliability resource exhaustion (e.g. resources for handling out-of-order packets) prevented accepting it. */
                                 PTL_CTS = 24,          /* The initiator may send the data and does not need to include an event message after completing the data. */
                                PTL_ECTS = 25,          /* The target was unable to allocate state to track completion for this message. The initiator must track completion and send and event message after all acknowledgments for the rendezvous operation have been received. */
          PTL_E2E_ONLY_ACK_OPPORTUNISTIC = 26           /* INTERNAL ONLY: This is a reserved opcode for a known internal HFI condition. It indicates that a tuple mismatch was detected in the end-to-end reliability logic and is used in internal loopback paths, This results in an Ack being generated back to the target opportunistically (specifically designed to prevent a known protocol deadlock case). */
};

#else

#define                          PTL_ACK   0            /* Normal Portals ACKVerbs: Normal ACK */
#define                  PTL_ACK_REFUSED   1            /* Portals ACK was refused by the target process. The stateful response is needed to convey to the initiator side implementation that a PTL_EVENT_ACK should not be delivered for this operation. This allows the initiator to free resources that might be reserved for the purpose. PTL_ACK_REFUSED may be generated in cases where the message does not match any buffer at the target or in cases where the target has explicitly indicated that the buffer should not generate an ACK. */
#define                        PTL_REPLY   2            /* Normal Portals Reply */
#define                   PTL_REPLY_ECTS   3            /* A Portals reply to a PTL_REQ_GET_ECTS. These packets receive an acknowledgement, but do not retransmit and do not notify the target of an error. Errors are returned to the initiator, which notifies the target in the Event message.Note for posterity: this could have been stateless; however, implementation oriented decisions caused this to be set as stateful. */
#define                  PTL_SHORT_REPLY   4            /* Portals Reply (response to a Get/Swap/Fetching Atomic operation) with only enough information for an OC event. This enables a smaller packet format. */
#define                 PTL_NACK_PTE_DIS   5            /* The Portals operation encountered a disabled PT Entry, or the operation caused a PT Entry to become disabled. This NACK frequently occurs as the result of a flow-control error.Verbs: Flow control was invoked */
#define                   PTL_NACK_PERMV   6            /* The Portals operation failed the permissions check at the targetVerbs: Permissions violation on the QP or RKey. */
#define                     PTL_NACK_OPV   7            /* The Portals operation specified an invalid operation (Put/Get) for the ME or LE it resolved toVerbs: Illegal operation (Read/Write/Atomic) at the target. */
#define                    PTL_NACK_SEGV   8            /* The Portals operation resolved to a virtual address that would have caused a segmentation fault.Verbs: Memory access encountered a segmentation fault. */
#define                 PTL_NACK_INV_TGT   9            /* The Portals operation specified an invalid target PID or target PT Index. Verbs: Invalid QP or Invalid RKey at target */
#define             PTL_NACK_UNSUPPORTED   10           /* Indicates that an unsupported operation was attempted. */
#define           PTL_NACK_UNCORRECTABLE   11           /* Indicates that an uncorrectable error was detected after the E2E sequence number checks. Promoted from PTL_ACK, PTL_ACK_REFUSED, PTL_REPLY, or PTL_SHORT_REPLY. */
#define                 PTL_E2E_ONLY_ACK   16           /* Used for an E2E extended ACK format */
#define        PTL_E2E_ONLY_ACK_DISTANCE   17           /* A distance adjusting acknowledgment */
#define   PTL_E2E_ONLY_ACK_UNCORRECTABLE   18           /* Indicates that an uncorrectable error was detected after the E2E sequence number checks. Promoted from PTL_E2E_ONLY_ACK. Because this is not stateful, this is best effort delivery only and could be interpreted as a simple ack. */
#define            PTL_E2E_ONLY_NACK_OOS   19           /* A packet was received out-of-sequence. The next expected sequence number is indicated in the Expected PSN field. An echo of the request PSN is contained in ACK_PSN. */
#define             PTL_E2E_ONLY_NACK_NC   21           /* A packet was received, but the local sequence table indicates that the nodes are not connected for this traffic class. The packet is not retransmitted and is treated as completed by the initiator (e.g. failed). This failure tears down the connection at the initiator. */
#define       PTL_E2E_ONLY_NACK_RESOURCE   22           /* A packet was received, but local reliability resource exhaustion (e.g. resources for handling out-of-order packets) prevented accepting it. */
#define                          PTL_CTS   24           /* The initiator may send the data and does not need to include an event message after completing the data. */
#define                         PTL_ECTS   25           /* The target was unable to allocate state to track completion for this message. The initiator must track completion and send and event message after all acknowledgments for the rendezvous operation have been received. */
#define   PTL_E2E_ONLY_ACK_OPPORTUNISTIC   26            /* INTERNAL ONLY: This is a reserved opcode for a known internal HFI condition. It indicates that a tuple mismatch was detected in the end-to-end reliability logic and is used in internal loopback paths, This results in an Ack being generated back to the target opportunistically (specifically designed to prevent a known protocol deadlock case). */

#endif


/* Enumeration from Table titled: OPCODE Assignments for E2E Control Packets (Enum - ptl_op_e2e_ctrl_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_op_e2e_ctrl {
              PTL_SINGLE_CONNECT = 0,           /* Establish a new connection between nodes for a specific traffic class. Because only one connection request is allowed to be pending at one time, the endpoint may choose to make these messages ordered or unordered (based on the RC). */
              PTL_SINGLE_DESTROY = 1,           /* Remove an existing connection between a pair of nodes for a specific traffic class. Destroy messages are one-way, fire and forget operations. Because only one connection request is allowed to be pending at one time, the endpoint may choose to make these messages ordered or unordered (based on the RC). */
                  PTL_E2E_FILLER = 2,           /* Replaces a deleted packet to maintain the sequence number space. PSN field is used to update the ordered or unordered sequence number space based on the routing code - just as it is with a standard packet.PTL_E2E_FILLER packets must inherit the RC (and, hence, ordering constraints) from the packet they replace.PTL_E2E_FILLER packets may also be used at any time the initiator needs to advance the sequence number space or to cause an E2E Ack of a previously sent packet. */
                   PTL_E2E_ESTAB = 3,           /* A new connection has been established (or re-established) using the sequence numbers included. These messages are unordered. */
                    PTL_E2E_NACK = 4,           /* The new connection establishment failed (e.g. was out of range for the DLID or TC, encountered an uncorrectable error, etc). A PTL_E2E_STATUS_REQ may also receive a PTL_E2E_NACK if the nodes are not connected. This would also be generated in response to E2E requests if the node was not booted. These messages are unordered. */
              PTL_E2E_STATUS_REQ = 5,           /* Requests the current status of the target (receive) side of the connection for a given <SLID, DLID, TC> tuple. Generates a PTL_E2E_STATUS_RESP. Because the usage model for these messages is likely to be unresolved corner cases, the endpoint is allowed to set the RC to choose ordered or unordered operation. */
             PTL_E2E_STATUS_RESP = 6,           /* Carries the current status of a connection for a given <SLID, DLID, TC> tuple, which includes the maximum sequence distance and current expected PSN for both the ordered and unordered channels. These messages are unordered, as are most responses. */
                           TBD_0 = 7,           
                           TBD_1 = 7,           
                           TBD_2 = 8,           
                           TBD_3 = 9,           
                           TBD_4 = 10,          
                           TBD_5 = 11,          
                           TBD_6 = 12,          
                           TBD_7 = 13,          
                           TBD_8 = 14,          
                           TBD_9 = 15,          
                          TBD_10 = 16,          
                          TBD_11 = 17,          
                          TBD_12 = 18,          
                          TBD_13 = 19,          
                          TBD_14 = 20,          
                          TBD_15 = 21,          
                          TBD_16 = 22,          
                          TBD_17 = 23,          
                          TBD_18 = 24,          
                          TBD_19 = 25,          
                          TBD_20 = 26,          
                          TBD_21 = 27,          
                          TBD_22 = 28,          
                          TBD_23 = 29,          
                          TBD_24 = 30           
};

#else

#define       PTL_SINGLE_CONNECT   0            /* Establish a new connection between nodes for a specific traffic class. Because only one connection request is allowed to be pending at one time, the endpoint may choose to make these messages ordered or unordered (based on the RC). */
#define       PTL_SINGLE_DESTROY   1            /* Remove an existing connection between a pair of nodes for a specific traffic class. Destroy messages are one-way, fire and forget operations. Because only one connection request is allowed to be pending at one time, the endpoint may choose to make these messages ordered or unordered (based on the RC). */
#define           PTL_E2E_FILLER   2            /* Replaces a deleted packet to maintain the sequence number space. PSN field is used to update the ordered or unordered sequence number space based on the routing code - just as it is with a standard packet.PTL_E2E_FILLER packets must inherit the RC (and, hence, ordering constraints) from the packet they replace.PTL_E2E_FILLER packets may also be used at any time the initiator needs to advance the sequence number space or to cause an E2E Ack of a previously sent packet. */
#define            PTL_E2E_ESTAB   3            /* A new connection has been established (or re-established) using the sequence numbers included. These messages are unordered. */
#define             PTL_E2E_NACK   4            /* The new connection establishment failed (e.g. was out of range for the DLID or TC, encountered an uncorrectable error, etc). A PTL_E2E_STATUS_REQ may also receive a PTL_E2E_NACK if the nodes are not connected. This would also be generated in response to E2E requests if the node was not booted. These messages are unordered. */
#define       PTL_E2E_STATUS_REQ   5            /* Requests the current status of the target (receive) side of the connection for a given <SLID, DLID, TC> tuple. Generates a PTL_E2E_STATUS_RESP. Because the usage model for these messages is likely to be unresolved corner cases, the endpoint is allowed to set the RC to choose ordered or unordered operation. */
#define      PTL_E2E_STATUS_RESP   6            /* Carries the current status of a connection for a given <SLID, DLID, TC> tuple, which includes the maximum sequence distance and current expected PSN for both the ordered and unordered channels. These messages are unordered, as are most responses. */
#define                    TBD_0   7            
#define                    TBD_1   7            
#define                    TBD_2   8            
#define                    TBD_3   9            
#define                    TBD_4   10           
#define                    TBD_5   11           
#define                    TBD_6   12           
#define                    TBD_7   13           
#define                    TBD_8   14           
#define                    TBD_9   15           
#define                   TBD_10   16           
#define                   TBD_11   17           
#define                   TBD_12   18           
#define                   TBD_13   19           
#define                   TBD_14   20           
#define                   TBD_15   21           
#define                   TBD_16   22           
#define                   TBD_17   23           
#define                   TBD_18   24           
#define                   TBD_19   25           
#define                   TBD_20   26           
#define                   TBD_21   27           
#define                   TBD_22   28           
#define                   TBD_23   29           
#define                   TBD_24   30            

#endif


/* Enumeration from Table titled: Encoding of the BECN Field (Enum - becn_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum becn {
         NO_BECN = 0,           /* No backward explicit congestion notification */
            BECN = 1            /* Backward explicit congestion notification */
};

#else

#define  NO_BECN   0            /* No backward explicit congestion notification */
#define     BECN   1             /* Backward explicit congestion notification */

#endif


/* Enumeration from Table titled: Encoding of the FECN Field (Enum - fecn_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum fecn {
         NO_FECN = 0,           /* No forward explicit congestion notification */
            FECN = 1            /* Forward explicit congestion notification */
};

#else

#define  NO_FECN   0            /* No forward explicit congestion notification */
#define     FECN   1             /* Forward explicit congestion notification */

#endif


/* Enumeration from Table titled: Encoding of the ACK_OPCODE Field (Enum - ack_op_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ack_op {
          PTL_E2E_NO_ACK = 0,           /* This packet does not include an E2E Ack. Maximum distance and expected PSN are not valid. */
             PTL_E2E_ACK = 1            /* This packet has an E2E acknowledgment (or negative acknowledgement) for the specified packet. */
};

#else

#define   PTL_E2E_NO_ACK   0            /* This packet does not include an E2E Ack. Maximum distance and expected PSN are not valid. */
#define      PTL_E2E_ACK   1             /* This packet has an E2E acknowledgment (or negative acknowledgement) for the specified packet. */

#endif


/* Enumeration from Table titled: Encoding of the Network Interface (NI) Field (Enum - ni_t) - 2 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ni {
         PTL_NONMATCHING_LOGICAL = 0,           /* Non-matching, logically addressed */
        PTL_NONMATCHING_PHYSICAL = 1,           /* Non-matching, physically addressed */
            PTL_MATCHING_LOGICAL = 2,           /* Matching, logically addressed */
           PTL_MATCHING_PHYSICAL = 3            /* Matching, physically addressed */
};

#else

#define  PTL_NONMATCHING_LOGICAL   0            /* Non-matching, logically addressed */
#define PTL_NONMATCHING_PHYSICAL   1            /* Non-matching, physically addressed */
#define     PTL_MATCHING_LOGICAL   2            /* Matching, logically addressed */
#define    PTL_MATCHING_PHYSICAL   3             /* Matching, physically addressed */

#endif


/* Enumeration from Table titled: Encoding of the Acknowledgment Request (ACK_REQ) Field (Enum - ptl_L4_ack_req_t) - 2 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_L4_ack_req {
                 PTL_E2E_ACK_REQ = 0,           /* No Portals acknowledgment is requested or an operation completed acknowledgment is requested. Both cases cause an E2E ACK to be generated. */
              PTL_E2E_NR_ACK_REQ = 1,           /* Only used for Get operations. A counting event was used at the initiator (i.e. only the information in a REPLY_8B packet is needed), and the target should not retransmit the reply if it gets lost. */
                PTL_FULL_ACK_REQ = 2,           /* A stateful acknowledgment was requested. This will have enough information for a Portals full ack or counting ack */
             PTL_FULL_NR_ACK_REQ = 3            /* A stateful acknowledgment was requested, but the target should not try to retransmit it if it gets lost. This prevents retries for both acknowledgments and Replies. */
};

#else

#define          PTL_E2E_ACK_REQ   0            /* No Portals acknowledgment is requested or an operation completed acknowledgment is requested. Both cases cause an E2E ACK to be generated. */
#define       PTL_E2E_NR_ACK_REQ   1            /* Only used for Get operations. A counting event was used at the initiator (i.e. only the information in a REPLY_8B packet is needed), and the target should not retransmit the reply if it gets lost. */
#define         PTL_FULL_ACK_REQ   2            /* A stateful acknowledgment was requested. This will have enough information for a Portals full ack or counting ack */
#define      PTL_FULL_NR_ACK_REQ   3             /* A stateful acknowledgment was requested, but the target should not try to retransmit it if it gets lost. This prevents retries for both acknowledgments and Replies. */

#endif


/* Enumeration from Table titled: Encoding of the List (LS) Field (Enum - ptl_list_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_list {
               PTL_PRIORITY_LIST = 0,           /* Indicates that the request matched the priority list */
               PTL_OVERFLOW_LIST = 1            /* Indicates that the request matched the overflow list */
};

#else

#define        PTL_PRIORITY_LIST   0            /* Indicates that the request matched the priority list */
#define        PTL_OVERFLOW_LIST   1             /* Indicates that the request matched the overflow list */

#endif


/* Enumeration from Table titled: Encoding of the Header Data (HD) Field (Enum - hd_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum hd {
           HDR_DATA_ZERO = 0,           /* Header data at the initiator was specified as zero */
        HDR_DATA_NONZERO = 1            /* Header data at the initiator contained a nonzero value */
};

#else

#define    HDR_DATA_ZERO   0            /* Header data at the initiator was specified as zero */
#define HDR_DATA_NONZERO   1             /* Header data at the initiator contained a nonzero value */

#endif


/* Enumeration from Table titled: Atomic DType Field (Enum - ptl_datatype_t) - 6 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_datatype {
                                    NONE = 0,           /* None */
                              PTL_INT8_T = 2,           /* 8 bit signed integer */
                             PTL_UINT8_T = 3,           /* 8 bit unsigned integer */
                             PTL_INT16_T = 4,           /* 16 bit signed integer */
                            PTL_UINT16_T = 5,           /* 16 bit unsigned integer */
                             PTL_INT32_T = 6,           /* 32 bit signed integer */
                            PTL_UINT32_T = 7,           /* 32 bit unsigned integer */
                             PTL_INT64_T = 8,           /* 64 bit signed integer */
                            PTL_UINT64_T = 9,           /* 64 bit unsigned integer */
                            PTL_INT128_T = 10,          /* 128 bit signed integer */
                           PTL_UINT128_T = 11,          /* 128 bit unsigned integer */
                               PTL_FLOAT = 16,          /* 32 bit floating-point (single precision, IEEE) */
                       PTL_FLOAT_COMPLEX = 17,          /* 32 bit complex floating-point (single precision, IEEE) */
                              PTL_DOUBLE = 18,          /* 64 bit floating-point (double precision, IEEE) */
                      PTL_DOUBLE_COMPLEX = 19,          /* 64 bit complex floating-point (double precision, IEEE) */
                      PTL_LONG_DOUBLE_96 = 20,          /* 96 bit floating-point (long double precision, IEEE) */
              PTL_LONG_DOUBLE_96_COMPLEX = 21,          /* 96 bit complex floating-point (long double precision, IEEE) */
                     PTL_LONG_DOUBLE_128 = 22,          /* 128 bit floating-point (long double precision, IEEE) */
             PTL_LONG_DOUBLE_128_COMPLEX = 23           /* 128 bit complex floating-point (long double precision, IEEE) */
};

#else

#define                             NONE   0            /* None */
#define                       PTL_INT8_T   2            /* 8 bit signed integer */
#define                      PTL_UINT8_T   3            /* 8 bit unsigned integer */
#define                      PTL_INT16_T   4            /* 16 bit signed integer */
#define                     PTL_UINT16_T   5            /* 16 bit unsigned integer */
#define                      PTL_INT32_T   6            /* 32 bit signed integer */
#define                     PTL_UINT32_T   7            /* 32 bit unsigned integer */
#define                      PTL_INT64_T   8            /* 64 bit signed integer */
#define                     PTL_UINT64_T   9            /* 64 bit unsigned integer */
#define                     PTL_INT128_T   10           /* 128 bit signed integer */
#define                    PTL_UINT128_T   11           /* 128 bit unsigned integer */
#define                        PTL_FLOAT   16           /* 32 bit floating-point (single precision, IEEE) */
#define                PTL_FLOAT_COMPLEX   17           /* 32 bit complex floating-point (single precision, IEEE) */
#define                       PTL_DOUBLE   18           /* 64 bit floating-point (double precision, IEEE) */
#define               PTL_DOUBLE_COMPLEX   19           /* 64 bit complex floating-point (double precision, IEEE) */
#define               PTL_LONG_DOUBLE_96   20           /* 96 bit floating-point (long double precision, IEEE) */
#define       PTL_LONG_DOUBLE_96_COMPLEX   21           /* 96 bit complex floating-point (long double precision, IEEE) */
#define              PTL_LONG_DOUBLE_128   22           /* 128 bit floating-point (long double precision, IEEE) */
#define      PTL_LONG_DOUBLE_128_COMPLEX   23            /* 128 bit complex floating-point (long double precision, IEEE) */

#endif


/* Enumeration from Table titled: Message Status Field (Enum - ptl_status_t) - 3 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_status {
                      PTL_MSG_OK = 0,           /* The operation completed successfully */
           PTL_MSG_UNCORRECTABLE = 1,           /* An uncorrectable error was encountered for this message. The connection may not be in a known state. This includes cases where the original packets may have timed out. */
              PTL_MSG_TERMINATED = 2,           /* The message was terminated in a controlled manner. This can include things such as tear down operations. */
                    PTL_MSG_SEGV = 3            /* A segmentation fault was encountered during the processing of the message. */
};

#else

#define               PTL_MSG_OK   0            /* The operation completed successfully */
#define    PTL_MSG_UNCORRECTABLE   1            /* An uncorrectable error was encountered for this message. The connection may not be in a known state. This includes cases where the original packets may have timed out. */
#define       PTL_MSG_TERMINATED   2            /* The message was terminated in a controlled manner. This can include things such as tear down operations. */
#define             PTL_MSG_SEGV   3             /* A segmentation fault was encountered during the processing of the message. */

#endif


/* Enumeration from Table titled: Transmit Command Type (Enum - tx_ctype_t) - 4 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum tx_ctype {
                     RTS = 0,           /* Portals Request to Send (RTS) for a Put, Atomic, or Get operation */
             RDV_REQUEST = 1,           /* Portals Basic Rendezvous Request (Put/Atomic/Get) */
               RDV_EVENT = 2,           /* Portals Basic Rendezvous Event */
                E2E_CTRL = 3,           /* Portals E2E Control */
                 VoNP_RC = 5,           /* Verbs over Native Protocol for reliable connections */
           NonPortalsMsg = 6,           /* Generate one of the non-Portals message types (some variants are privileged) */
            LocalCommand = 7,           /* Issue a command to the local HFI, including state modification and connection state control. The Local Command type uses the non_portals_cmd_t encoding for local commands. */
                 REQUEST = 8,           /* Portals Basic Request (Put/Atomic/Get) */
        FETCHING_REQUEST = 9,           /* Portals Fetching Request (FetchAtomic/Two Operand Atomics) */
                Response = 10,          /* Portals Reply / Portal Full ACK */
                      UD = 11,          /* Unreliable Datagrams (will cover all future unreliable datagrams) */
              BASIC_ACK0 = 12,          /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=00b */
              BASIC_ACK1 = 13,          /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=01b */
              BASIC_ACK2 = 14,          /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=10b */
              BASIC_ACK3 = 15           /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=11b */
};

#else

#define              RTS   0            /* Portals Request to Send (RTS) for a Put, Atomic, or Get operation */
#define      RDV_REQUEST   1            /* Portals Basic Rendezvous Request (Put/Atomic/Get) */
#define        RDV_EVENT   2            /* Portals Basic Rendezvous Event */
#define         E2E_CTRL   3            /* Portals E2E Control */
#define          VoNP_RC   5            /* Verbs over Native Protocol for reliable connections */
#define    NonPortalsMsg   6            /* Generate one of the non-Portals message types (some variants are privileged) */
#define     LocalCommand   7            /* Issue a command to the local HFI, including state modification and connection state control. The Local Command type uses the non_portals_cmd_t encoding for local commands. */
#define          REQUEST   8            /* Portals Basic Request (Put/Atomic/Get) */
#define FETCHING_REQUEST   9            /* Portals Fetching Request (FetchAtomic/Two Operand Atomics) */
#define         Response   10           /* Portals Reply / Portal Full ACK */
#define               UD   11           /* Unreliable Datagrams (will cover all future unreliable datagrams) */
#define       BASIC_ACK0   12           /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=00b */
#define       BASIC_ACK1   13           /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=01b */
#define       BASIC_ACK2   14           /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=10b */
#define       BASIC_ACK3   15            /* Portals E2E Basic ACK, pkt_hdr_id[15:14]=11b */

#endif


/* Enumeration from Table titled: Transmit Transfer Type (Enum - transfer_type_t) - 2bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum transfer_type {
        BUFFERED = 0,           /* Uses a buffered OMB entry to hold the payload */
             PIO = 1,           /* Uses programmed I/O to push the data, but uses DMA to retransmit it */
             DMA = 2,           /* Uses DMA to transfer the data */
         SPECIAL = 3            /* Uses the Low Overhead command format to bundle two BUFFERED Put/Atomic or two DMA Get operations into one command. See Section 22.3.1.1.3, 'Low Overhead, Small Operation Launch' */
};

#else

#define BUFFERED   0            /* Uses a buffered OMB entry to hold the payload */
#define      PIO   1            /* Uses programmed I/O to push the data, but uses DMA to retransmit it */
#define      DMA   2            /* Uses DMA to transfer the data */
#define  SPECIAL   3             /* Uses the Low Overhead command format to bundle two BUFFERED Put/Atomic or two DMA Get operations into one command. See Section 22.3.1.1.3, 'Low Overhead, Small Operation Launch' */

#endif


/* Enumeration from Table titled: Atomic Operation Encoding (Enum - ptl_op_t) - 5 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_op {
                PTL_SWAP = 0,           
                 PTL_MIN = 4,           
                 PTL_MAX = 5,           
                 PTL_SUM = 6,           
                PTL_DIFF = 7,           
                PTL_PROD = 8,           
                 PTL_LOR = 9,           
                PTL_LAND = 10,          
                PTL_LXOR = 11,          
                 PTL_BOR = 12,          
                PTL_BAND = 13,          
                PTL_BXOR = 14,          
               PTL_CSWAP = 17,          
            PTL_CSWAP_NE = 18,          
            PTL_CSWAP_LE = 19,          
            PTL_CSWAP_LT = 20,          
            PTL_CSWAP_GE = 21,          
            PTL_CSWAP_GT = 22,          
               PTL_MSWAP = 23           
};

#else

#define         PTL_SWAP   0            
#define          PTL_MIN   4            
#define          PTL_MAX   5            
#define          PTL_SUM   6            
#define         PTL_DIFF   7            
#define         PTL_PROD   8            
#define          PTL_LOR   9            
#define         PTL_LAND   10           
#define         PTL_LXOR   11           
#define          PTL_BOR   12           
#define         PTL_BAND   13           
#define         PTL_BXOR   14           
#define        PTL_CSWAP   17           
#define     PTL_CSWAP_NE   18           
#define     PTL_CSWAP_LE   19           
#define     PTL_CSWAP_LT   20           
#define     PTL_CSWAP_GE   21           
#define     PTL_CSWAP_GT   22           
#define        PTL_MSWAP   23            

#endif


/* Enumeration from Table titled: Command Assignments for NonPortals Messages (Enum - nonptl_cmd_t) - 7 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum nonptl_cmd {
                     GENERAL_DMA = 0,           /* Performs a generic DMA using the IOVEC format. 8B, 10B, or 16B packets are fully formed in memory, but the HFI inserts the CRC. 9B packets insert the start and stop byte in hardware and also perform the required endian swap in hardware.Note: 9B packets cannot be mixed with other packet types in a given GENERAL_DMA command.Note: Unused entries (invalid entries or entries between an end of packet marker and start of packet marker) are not allowed in the GENERAL_DMA format. */
               GENERAL_DMA_NOCRC = 1,           /* Performs a generic DMA using the IOVEC format. Packets are fully formed in memory, but the HFI does not insert the CRC. It is illegal to use the 9B option bit in the IOVEC entry for this command.Note: Unused entries (invalid entries or entries between an end of packet marker and start of packet marker) are not allowed in the GENERAL_DMA format. */
                        MGMT_DMA = 2,           /* Performs a DMA of management packets (uses SC15). Otherwise the MGMT_DMA command behaves like a GENERAL_DMA.Note: 9B packets cannot be mixed with other packet types in a given MGMT_DMA command.Note: Unused entries (invalid entries or entries between an end of packet marker and start of packet marker) are not allowed in the GENERAL_DMA format. */
                     OFED_9B_DMA = 4,           /* 9B packet formats without GRH */
                 OFED_9B_DMA_GRH = 5,           /* 9B packet formats, with GRH, */
                     OFED_9B_PIO = 6,           /* 9B packet formats using PIO path. */
                    OFED_16B_DMA = 8,           /* 16B packet formats */
                OFED_16B_DMA_GRH = 9,           /* 16B packet formats, with GRH */
                    OFED_16B_PIO = 10,          /* 16B packet formats using PIO path */
              KDETH_9B_EAGER_DMA = 16,          /* 9B packet formats, */
             KDETH_16B_EAGER_DMA = 17,          /* 16B packet formats */
                KDETH_9B_TID_DMA = 20,          /* 9B packet formats */
               KDETH_16B_TID_DMA = 21,          /* 16B packet formats */
                    KDETH_9B_PIO = 24,          
                   KDETH_16B_PIO = 25,          /* This command slot is specifically reserved for KDETH_16B_PIO. KDETH_16B_PIO is not a committed command and will be evaluated at a later point. */
              LOCAL_CMD_DLID_RTT = 127          /* Local command: write to the DLID relocation table using the format in Figure 22-32. */
};

#else

#define              GENERAL_DMA   0            /* Performs a generic DMA using the IOVEC format. 8B, 10B, or 16B packets are fully formed in memory, but the HFI inserts the CRC. 9B packets insert the start and stop byte in hardware and also perform the required endian swap in hardware.Note: 9B packets cannot be mixed with other packet types in a given GENERAL_DMA command.Note: Unused entries (invalid entries or entries between an end of packet marker and start of packet marker) are not allowed in the GENERAL_DMA format. */
#define        GENERAL_DMA_NOCRC   1            /* Performs a generic DMA using the IOVEC format. Packets are fully formed in memory, but the HFI does not insert the CRC. It is illegal to use the 9B option bit in the IOVEC entry for this command.Note: Unused entries (invalid entries or entries between an end of packet marker and start of packet marker) are not allowed in the GENERAL_DMA format. */
#define                 MGMT_DMA   2            /* Performs a DMA of management packets (uses SC15). Otherwise the MGMT_DMA command behaves like a GENERAL_DMA.Note: 9B packets cannot be mixed with other packet types in a given MGMT_DMA command.Note: Unused entries (invalid entries or entries between an end of packet marker and start of packet marker) are not allowed in the GENERAL_DMA format. */
#define              OFED_9B_DMA   4            /* 9B packet formats without GRH */
#define          OFED_9B_DMA_GRH   5            /* 9B packet formats, with GRH, */
#define              OFED_9B_PIO   6            /* 9B packet formats using PIO path. */
#define             OFED_16B_DMA   8            /* 16B packet formats */
#define         OFED_16B_DMA_GRH   9            /* 16B packet formats, with GRH */
#define             OFED_16B_PIO   10           /* 16B packet formats using PIO path */
#define       KDETH_9B_EAGER_DMA   16           /* 9B packet formats, */
#define      KDETH_16B_EAGER_DMA   17           /* 16B packet formats */
#define         KDETH_9B_TID_DMA   20           /* 9B packet formats */
#define        KDETH_16B_TID_DMA   21           /* 16B packet formats */
#define             KDETH_9B_PIO   24           
#define            KDETH_16B_PIO   25           /* This command slot is specifically reserved for KDETH_16B_PIO. KDETH_16B_PIO is not a committed command and will be evaluated at a later point. */
#define       LOCAL_CMD_DLID_RTT   127           /* Local command: write to the DLID relocation table using the format in Figure 22-32. */

#endif


/* Enumeration from Table titled: Valid Type (Enum - flag_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum flag {
               FXR_FALSE = 0,           /* boolean false */
                FXR_TRUE = 1            /* boolean true */
};

#else

#define        FXR_FALSE   0            /* boolean false */
#define         FXR_TRUE   1             /* boolean true */

#endif


/* Enumeration from Table titled: Verbs NACK Reason Codes (Enum - nack_reason_t) - 6 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum nack_reason {
                VERBS_OK = 0,           /* No Error. */
            FLOW_CONTROL = 1,           /* Flow control was encountered. PTE is disabled. */
              INVALID_QP = 2,           /* QP encountered was invalid */
            INVALID_RKEY = 3,           /* RKEY was invalid */
             PERMISSIONS = 4,           /* Permissions were denied on the receive queue or RKey */
                     OPV = 5,           /* Disallowed operation attempted at target */
                    SEGV = 6,           /* Memory access encountered a segmentation fault */
             UNSUPPORTED = 7,           /* Unsupported operation attempted */
           UNCORRECTABLE = 8,           /* Uncorrectable error encountered */
               TOO_SHORT = 9,           /* The target receive queue entry was too short for the message. */
         INITIATOR_ERROR = 10,          /* Initiator encountered an error and sent PTL_RC_LAST_ERROR */
        INV_INVALID_RKEY = 11,          /* A send with invalidate was received for an invalid RKEY */
                 EQ_FULL = 12,          /* The EQ was full when it was time to post an event. */
               MR_IN_USE = 13,          /* This will not be stored in QP state. It is used for local signaling only. */
          QP_PERMISSIONS = 14           /* This will not be stored in the QP state. It is used for local signaling only. */
};

#else

#define         VERBS_OK   0            /* No Error. */
#define     FLOW_CONTROL   1            /* Flow control was encountered. PTE is disabled. */
#define       INVALID_QP   2            /* QP encountered was invalid */
#define     INVALID_RKEY   3            /* RKEY was invalid */
#define      PERMISSIONS   4            /* Permissions were denied on the receive queue or RKey */
#define              OPV   5            /* Disallowed operation attempted at target */
#define             SEGV   6            /* Memory access encountered a segmentation fault */
#define      UNSUPPORTED   7            /* Unsupported operation attempted */
#define    UNCORRECTABLE   8            /* Uncorrectable error encountered */
#define        TOO_SHORT   9            /* The target receive queue entry was too short for the message. */
#define  INITIATOR_ERROR   10           /* Initiator encountered an error and sent PTL_RC_LAST_ERROR */
#define INV_INVALID_RKEY   11           /* A send with invalidate was received for an invalid RKEY */
#define          EQ_FULL   12           /* The EQ was full when it was time to post an event. */
#define        MR_IN_USE   13           /* This will not be stored in QP state. It is used for local signaling only. */
#define   QP_PERMISSIONS   14            /* This will not be stored in the QP state. It is used for local signaling only. */

#endif


/* Enumeration from Table titled: Receive CQ Command (Enum - rx_cq_cmd_t) - 12 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum rx_cq_cmd {
                         PT_READ = 0,           /* Generate an event (PTL_EVENT_PT_READ) with the contents of the lower 16 bytes of the Portal table entry. */
                 PT_UPDATE_LOWER = 1,           /* Must not be used to create or manipulate a fastpath entry. If the operation would result in a Fast Path entry, the operation will fail without changing the Portal Table Entry. May be used to convert a fastpath entry to a non-fastpath entry or to manipulate non-fastpath entries. Updates the lower 16 bytes of the Portal Table Entry under mask. This operation enables commands containing only 64B to perform common updates (e.g. PTE_ENABLE/PTE_DISABLE). Races caused by other partial updates are the responsibility of the library, which should use extreme caution.In order to prevent modifications of privileged fields in Gen1 Portal Table Entries, the following pseudo-code test is applied://unprivileged accesses must not flip from FP=1 to FP=0/BC=1.if (old_PTEntry.FP==1 && new_PTEntry.FP==0 && new_PTEntry.BC==1) fail_the_write(); //unpriviledged accesses must not flip the BC bit to being set.if (old_PTEntry.BC==0 && new_PTEntry.BC==1) fail_the_write();//Limit writes to the Enable bit and bottom 38 bits for the E/TID=1//case plus the TID Base Index and TIDPairCnt// a 1 allows a write.  Mask away mask bits that are not allowed.if (old_PTEntry.BC==1 && old_PTEntry.ETID==1) {mask_bytes_low= mask_bytes_low & 0x0080003FFFFFFFFF;mask_bytes_high=mask_bytes_high & 0x00000000000FFFFF;} // In the E/TID=0 case, limit accesses to the Enable bit, EagerTail,// and EagerHead fields.if (old_PTEntry.BC==1 && old_PTEntry.ETID==0) { mask_bytes_low= mask_bytes_low & 0x0080000000000000; mask_bytes_high=mask_bytes_high & 0x0000000007FF07FF;} */
                        PT_WRITE = 2,           /* Directly store a PT Entry. Only Allowed to convert a Portal Table Entry to Fast Path and manipulate fast path Portal Table Entries. If the operation would not result in a Fast Path entry, the operation will fail without changing the Portal Table Entry.If PT_WRITE targets a matching NI, the valid bit is set to zero. */
                       PT_UPDATE = 3,           /* Uses a larger (128B) command format to update the entire PT Entry under mask.Only Allowed to convert a Portal Table Entry to Fast Path and manipulate fast path Portal Table Entries. If the operation would not result in a Fast Path entry, the operation will fail without changing the Portal Table Entry.For all fields above the first 128 bits, this operation performs a write instead of an update. This is a microarchitectural limitation due to the read width of the Portal Table Entry.If PT_UPDATE targets a matching NI, the valid bit is set to zero. */
            PT_UPDATE_LOWER_PRIV = 4,           /* Updates the lower 16 bytes of the Portal Table Entry under mask. This operation enables commands containing only 64B to perform common updates (e.g. PTE_ENABLE/PTE_DISABLE). Races caused by other partial updates are the responsibility of the library, which should use extreme caution. This access does not filter any of the PTE accesses. */
                  EQ_DESC_UPDATE = 5,           /* Update EQ Descriptor under mask (update an arbitrary set of sub-fields). Limited to kernel use models. */
            EQ_DESC_HEAD_REFETCH = 6,           /* Force the EQD cache to refetch the EQD Head Pointer from main memory. Only PID and EQH are relevant in the command. */
                 EQ_DESC_RESERVE = 7,           /* Reserve an entry in the corresponding EQD. If reservation fails, flow control is not entered but the failure is indicated in the PTL_CMD_COMPLETE event, if requested. Only PID and EQH are relevant in the command. */
                 EQ_DESC_RELEASE = 8,           /* Release a reservation in the corresponding EQD. Only PID and EQH are relevant in the command. */
                 APPEND_PRIORITY = 64,          /* Append and ME or LE (chosen by the NI) to the priority list. */
                 APPEND_OVERFLOW = 65,          /* Append and ME or LE (chosen by the NI) to the overflow list. */
                          SEARCH = 66,          /* Search the unexpected header list for matching items and return matches. */
                   SEARCH_DELETE = 67,          /* Search the unexpected header list for matching items, return matches, and delete them from the unexpected header list. Generate a COMM_*_OVERFLOW event on success or a SEARCH event on failure. */
                          UNLINK = 68,          /* Unlink the specified ME handle. If the specified handle is found to be invalid/unlinked, then PTL_IN_USE is returned. */
                    ASYNC_UNLINK = 69,          /* Asynchronous unlink of the specified ME/LE handle. Causes an PTL_EVENT_AUTO_UNLINK on the EQ associated with the PTE for the ME/LE handle when the unlink is completed.If an ME is in use at the time of the ASYNC_UNLINK, the ME is removed from the matching list and marked to be freed. This will cause it to generate an unlink event when the refcount goes to zero.If the ME is already unlinked, nothing is returned, since an earlier unlink event should have been generated. */
                     ENTRY_WRITE = 70,          /* Write a ME/LE entry. Used for maintaining the Eager list for a 'backward compatibility' entry as well as for cleanup (eg. PTFree). */
                    REFCOUNT_DEC = 71,          /* Decrement the ME/LE refcount as the result of a reply to a Get completing. NB: This is an internal command that will only be issued by the OTR logic. */
                      ENTRY_READ = 72,          /* Generate an event containing the contents of the ME. The event can store the next/previous and 56 bytes of the ME as shown in the entry read event format. See Figure 22-61 and Table 22-154 */
                      SCRUB_PEER = 73,          /* Invoke scrubbing of the peer identified by INITIATOR_ID and USER_ID in the context of the PID (CMD_PID), PTL_IDX, and NI indicated in the command. This enables software to start a specific clean-up of resources related to that peer. Rendezvous tracking entries associated with that peer are eliminated and refcounts are decremented appropriately. Entries that would have delivered an event on completion deliver that event with a fail type of PTL_NI_UNDELIVERABLE.Wildcard options can be used when specifying both the INITIATOR_ID and USER_ID selection criteria.When SCRUB_PEER has delivered all of the events associated with terminated messages, it delivers a PTL_CMD_COMPLETE (if requested) */
                      RECVQ_INIT = 74,          /* Initialize a receive queue. Set the next and previous pointers to invalid. Other fields are undefined. Do not perform a PTE lookup. The ME handle of the receive queue is placed in the lower 16 bits of the min free field. This is illustrated in Figure 22-36. */
                    RECVQ_APPEND = 75,          /* Add an entry to the receive queue. Command PID is the PID for the receive queue. ME Handle contains the new ME handle to use. The ME handle of the receive queue is placed in the lower 16 bits of the min free field. This is illustrated in Figure 22-36. */
                        QP_WRITE = 76,          /* Write to the queue pair state of a queue pair. */
                    RECVQ_UNLINK = 77,          /* Remove first unused entry from the receive queue. Command PID is the PID for the receive queue. The ME Handle of the receive queue is placed in the lower 16 bits of the min free field. This is illustrated in Figure 22-36.Completion of the RECVQ_UNLINK generates a PTL_CMD_COMPLETE event. In addition to the typical command complete event fields, it places the USER_PTR from the ME that is unlinked into the space typically used by HDR_DATA. The ptl_ni_fail_t in the event will be set to PTL_NI_CANCELLED. */
                      RKEY_WRITE = 78,          /* Write to an RKey location in unexpected header (UH) space. The MEHandle becomes the handle into UH space. This semantically matches an ENTRY_WRITE, except that it writes to UH space and is privileged. A logical base address (LBA) field has been added to the associated format as well.Note: RKey space is 0x1000 to 0x1FFF. This command is privileged; thus, the implementation is not required to filter accesses. If anything about this changes, the hardware would need to force the upper 4 bits of the handle. */
                       RKEY_FREE = 79,          /* Set the F (Free) bit in a Memory Region / Memory Window. Generate a command complete. if the ref count is 0, use a success encoding. If not, use the MR_IN_USE' failure coding. If the RKEY is not valid, use the INVALID_RKEY failure coding. */
                TRIGGERED_APPEND = 80,          /* Insert a triggered operation into the list. This command will cause hardware to insert a Triggered Operation in the proper position in the list, according to the threshold. Hardware will walk the list until the correct position is found, so this command will perform slowly if many entries must be walked. For commands that have the same threshold, the insert will occur after all commands with the same threshold. */
             ORDERED_TRIG_APPEND = 81,          /* Append a triggered operation to the end of the list. This command variant must have a threshold greater than or equal to the last item in the list in order to maintain an ordered list. Hardware will not enforce list ordering for this command, so it is left to software to ensure the list remains ordered when using this command. */
               TRIGGERED_DISABLE = 82,          /* Remove all triggered ops pending on a CT. The logic will clear the PT (pending triggered) bit in the CT so that any triggered ops hanging from it are unlinked. The triggered ops themselves become orphaned (still valid but not linked to any CT). Other fields are unmodified/uninitialized until PT transitions from 0 to 1 via a new TO append, so the old threshold and head/tail pointers are preserved. The head/tail pointers could potentially be used to reclaim the orphaned TOs; however, this is probably better handled through the existing garbage collecting scheme. */
                       QP_UPDATE = 83,          /* Update the QP state under mask. This works like the other 'under mask' commands (e.g. PT_UPDATE). */
                          CT_SET = 96,          /* Set the value of a counting event (needed to insure that the Triggered Operation Unit gets a copy of the update) using the low 16 bytes of the write command. Only changes the success and failure counts. Masks do not exist for this command format. */
                  CT_INC_SUCCESS = 97,          /* Increment the value of the success field of a counting event by a specified amount (needed to insure that the Triggered Operation Unit gets a copy of the update). The mask is not applied to this operation, since it implies increment semantics. The low 8 bytes of the command are used for the increment value. Software may increment by a negative value by placing a signed 64 bit integer in this field. Strictly speaking, this relies on two's complement formats that are not required by C. Instead, software should view this as 'increment by a large number and cause wrap-around'. For example, increment by INT_MAX should be the same as 'subtract 1'. */
                  CT_INC_FAILURE = 98,          /* Increment the value of the failure field of a counting event by a specified amount (needed to insure that the Triggered Operation Unit gets a copy of the update). The mask is not applied to this operation, since it implies increment semantics. Bytes 8 to 15 of the command are used for the increment value. Software may increment by a negative value by placing a signed 64 bit integer in this field. Strictly speaking, this relies on two's complement formats that are not required by C. Instead, software should view this as 'increment by a large number and cause wrap-around'. For example, increment by INT_MAX should be the same as 'subtract 1'. */
                CT_SET_THRESHOLD = 99,          /* Sets the threshold associated with the CT using the low 8 bytes of the write command. Does not impact the success or failure count. The success and threshold field are evaluated to determine if the triggering logic should be invoked. */
                       CT_UPDATE = 100,         /* Update the top two bytes of the counting event under mask. The fields in this range are V, I, NI, and IRQ (see Figure 22-55). The lower two bytes of the mask/payload in the command are used. */
                      PD_CLEANUP = 128,         /* Cleanup state for a given PD instance. */
                    PD_DO_STUFF1 = 129,         /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
                    PD_DO_STUFF2 = 130,         /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
                    PD_DO_STUFF3 = 131,         /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
                    PD_DO_STUFF4 = 132,         /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
                    PD_DO_STUFF5 = 133,         /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
                    PD_DO_STUFF6 = 134,         /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
                    PD_DO_STUFF7 = 135          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
};

#else

#define                  PT_READ   0            /* Generate an event (PTL_EVENT_PT_READ) with the contents of the lower 16 bytes of the Portal table entry. */
#define          PT_UPDATE_LOWER   1            /* Must not be used to create or manipulate a fastpath entry. If the operation would result in a Fast Path entry, the operation will fail without changing the Portal Table Entry. May be used to convert a fastpath entry to a non-fastpath entry or to manipulate non-fastpath entries. Updates the lower 16 bytes of the Portal Table Entry under mask. This operation enables commands containing only 64B to perform common updates (e.g. PTE_ENABLE/PTE_DISABLE). Races caused by other partial updates are the responsibility of the library, which should use extreme caution.In order to prevent modifications of privileged fields in Gen1 Portal Table Entries, the following pseudo-code test is applied://unprivileged accesses must not flip from FP=1 to FP=0/BC=1.if (old_PTEntry.FP==1 && new_PTEntry.FP==0 && new_PTEntry.BC==1) fail_the_write(); //unpriviledged accesses must not flip the BC bit to being set.if (old_PTEntry.BC==0 && new_PTEntry.BC==1) fail_the_write();//Limit writes to the Enable bit and bottom 38 bits for the E/TID=1//case plus the TID Base Index and TIDPairCnt// a 1 allows a write.  Mask away mask bits that are not allowed.if (old_PTEntry.BC==1 && old_PTEntry.ETID==1) {mask_bytes_low= mask_bytes_low & 0x0080003FFFFFFFFF;mask_bytes_high=mask_bytes_high & 0x00000000000FFFFF;} // In the E/TID=0 case, limit accesses to the Enable bit, EagerTail,// and EagerHead fields.if (old_PTEntry.BC==1 && old_PTEntry.ETID==0) { mask_bytes_low= mask_bytes_low & 0x0080000000000000; mask_bytes_high=mask_bytes_high & 0x0000000007FF07FF;} */
#define                 PT_WRITE   2            /* Directly store a PT Entry. Only Allowed to convert a Portal Table Entry to Fast Path and manipulate fast path Portal Table Entries. If the operation would not result in a Fast Path entry, the operation will fail without changing the Portal Table Entry.If PT_WRITE targets a matching NI, the valid bit is set to zero. */
#define                PT_UPDATE   3            /* Uses a larger (128B) command format to update the entire PT Entry under mask.Only Allowed to convert a Portal Table Entry to Fast Path and manipulate fast path Portal Table Entries. If the operation would not result in a Fast Path entry, the operation will fail without changing the Portal Table Entry.For all fields above the first 128 bits, this operation performs a write instead of an update. This is a microarchitectural limitation due to the read width of the Portal Table Entry.If PT_UPDATE targets a matching NI, the valid bit is set to zero. */
#define     PT_UPDATE_LOWER_PRIV   4            /* Updates the lower 16 bytes of the Portal Table Entry under mask. This operation enables commands containing only 64B to perform common updates (e.g. PTE_ENABLE/PTE_DISABLE). Races caused by other partial updates are the responsibility of the library, which should use extreme caution. This access does not filter any of the PTE accesses. */
#define           EQ_DESC_UPDATE   5            /* Update EQ Descriptor under mask (update an arbitrary set of sub-fields). Limited to kernel use models. */
#define     EQ_DESC_HEAD_REFETCH   6            /* Force the EQD cache to refetch the EQD Head Pointer from main memory. Only PID and EQH are relevant in the command. */
#define          EQ_DESC_RESERVE   7            /* Reserve an entry in the corresponding EQD. If reservation fails, flow control is not entered but the failure is indicated in the PTL_CMD_COMPLETE event, if requested. Only PID and EQH are relevant in the command. */
#define          EQ_DESC_RELEASE   8            /* Release a reservation in the corresponding EQD. Only PID and EQH are relevant in the command. */
#define          APPEND_PRIORITY   64           /* Append and ME or LE (chosen by the NI) to the priority list. */
#define          APPEND_OVERFLOW   65           /* Append and ME or LE (chosen by the NI) to the overflow list. */
#define                   SEARCH   66           /* Search the unexpected header list for matching items and return matches. */
#define            SEARCH_DELETE   67           /* Search the unexpected header list for matching items, return matches, and delete them from the unexpected header list. Generate a COMM_*_OVERFLOW event on success or a SEARCH event on failure. */
#define                   UNLINK   68           /* Unlink the specified ME handle. If the specified handle is found to be invalid/unlinked, then PTL_IN_USE is returned. */
#define             ASYNC_UNLINK   69           /* Asynchronous unlink of the specified ME/LE handle. Causes an PTL_EVENT_AUTO_UNLINK on the EQ associated with the PTE for the ME/LE handle when the unlink is completed.If an ME is in use at the time of the ASYNC_UNLINK, the ME is removed from the matching list and marked to be freed. This will cause it to generate an unlink event when the refcount goes to zero.If the ME is already unlinked, nothing is returned, since an earlier unlink event should have been generated. */
#define              ENTRY_WRITE   70           /* Write a ME/LE entry. Used for maintaining the Eager list for a 'backward compatibility' entry as well as for cleanup (eg. PTFree). */
#define             REFCOUNT_DEC   71           /* Decrement the ME/LE refcount as the result of a reply to a Get completing. NB: This is an internal command that will only be issued by the OTR logic. */
#define               ENTRY_READ   72           /* Generate an event containing the contents of the ME. The event can store the next/previous and 56 bytes of the ME as shown in the entry read event format. See Figure 22-61 and Table 22-154 */
#define               SCRUB_PEER   73           /* Invoke scrubbing of the peer identified by INITIATOR_ID and USER_ID in the context of the PID (CMD_PID), PTL_IDX, and NI indicated in the command. This enables software to start a specific clean-up of resources related to that peer. Rendezvous tracking entries associated with that peer are eliminated and refcounts are decremented appropriately. Entries that would have delivered an event on completion deliver that event with a fail type of PTL_NI_UNDELIVERABLE.Wildcard options can be used when specifying both the INITIATOR_ID and USER_ID selection criteria.When SCRUB_PEER has delivered all of the events associated with terminated messages, it delivers a PTL_CMD_COMPLETE (if requested) */
#define               RECVQ_INIT   74           /* Initialize a receive queue. Set the next and previous pointers to invalid. Other fields are undefined. Do not perform a PTE lookup. The ME handle of the receive queue is placed in the lower 16 bits of the min free field. This is illustrated in Figure 22-36. */
#define             RECVQ_APPEND   75           /* Add an entry to the receive queue. Command PID is the PID for the receive queue. ME Handle contains the new ME handle to use. The ME handle of the receive queue is placed in the lower 16 bits of the min free field. This is illustrated in Figure 22-36. */
#define                 QP_WRITE   76           /* Write to the queue pair state of a queue pair. */
#define             RECVQ_UNLINK   77           /* Remove first unused entry from the receive queue. Command PID is the PID for the receive queue. The ME Handle of the receive queue is placed in the lower 16 bits of the min free field. This is illustrated in Figure 22-36.Completion of the RECVQ_UNLINK generates a PTL_CMD_COMPLETE event. In addition to the typical command complete event fields, it places the USER_PTR from the ME that is unlinked into the space typically used by HDR_DATA. The ptl_ni_fail_t in the event will be set to PTL_NI_CANCELLED. */
#define               RKEY_WRITE   78           /* Write to an RKey location in unexpected header (UH) space. The MEHandle becomes the handle into UH space. This semantically matches an ENTRY_WRITE, except that it writes to UH space and is privileged. A logical base address (LBA) field has been added to the associated format as well.Note: RKey space is 0x1000 to 0x1FFF. This command is privileged; thus, the implementation is not required to filter accesses. If anything about this changes, the hardware would need to force the upper 4 bits of the handle. */
#define                RKEY_FREE   79           /* Set the F (Free) bit in a Memory Region / Memory Window. Generate a command complete. if the ref count is 0, use a success encoding. If not, use the MR_IN_USE' failure coding. If the RKEY is not valid, use the INVALID_RKEY failure coding. */
#define         TRIGGERED_APPEND   80           /* Insert a triggered operation into the list. This command will cause hardware to insert a Triggered Operation in the proper position in the list, according to the threshold. Hardware will walk the list until the correct position is found, so this command will perform slowly if many entries must be walked. For commands that have the same threshold, the insert will occur after all commands with the same threshold. */
#define      ORDERED_TRIG_APPEND   81           /* Append a triggered operation to the end of the list. This command variant must have a threshold greater than or equal to the last item in the list in order to maintain an ordered list. Hardware will not enforce list ordering for this command, so it is left to software to ensure the list remains ordered when using this command. */
#define        TRIGGERED_DISABLE   82           /* Remove all triggered ops pending on a CT. The logic will clear the PT (pending triggered) bit in the CT so that any triggered ops hanging from it are unlinked. The triggered ops themselves become orphaned (still valid but not linked to any CT). Other fields are unmodified/uninitialized until PT transitions from 0 to 1 via a new TO append, so the old threshold and head/tail pointers are preserved. The head/tail pointers could potentially be used to reclaim the orphaned TOs; however, this is probably better handled through the existing garbage collecting scheme. */
#define                QP_UPDATE   83           /* Update the QP state under mask. This works like the other 'under mask' commands (e.g. PT_UPDATE). */
#define                   CT_SET   96           /* Set the value of a counting event (needed to insure that the Triggered Operation Unit gets a copy of the update) using the low 16 bytes of the write command. Only changes the success and failure counts. Masks do not exist for this command format. */
#define           CT_INC_SUCCESS   97           /* Increment the value of the success field of a counting event by a specified amount (needed to insure that the Triggered Operation Unit gets a copy of the update). The mask is not applied to this operation, since it implies increment semantics. The low 8 bytes of the command are used for the increment value. Software may increment by a negative value by placing a signed 64 bit integer in this field. Strictly speaking, this relies on two's complement formats that are not required by C. Instead, software should view this as 'increment by a large number and cause wrap-around'. For example, increment by INT_MAX should be the same as 'subtract 1'. */
#define           CT_INC_FAILURE   98           /* Increment the value of the failure field of a counting event by a specified amount (needed to insure that the Triggered Operation Unit gets a copy of the update). The mask is not applied to this operation, since it implies increment semantics. Bytes 8 to 15 of the command are used for the increment value. Software may increment by a negative value by placing a signed 64 bit integer in this field. Strictly speaking, this relies on two's complement formats that are not required by C. Instead, software should view this as 'increment by a large number and cause wrap-around'. For example, increment by INT_MAX should be the same as 'subtract 1'. */
#define         CT_SET_THRESHOLD   99           /* Sets the threshold associated with the CT using the low 8 bytes of the write command. Does not impact the success or failure count. The success and threshold field are evaluated to determine if the triggering logic should be invoked. */
#define                CT_UPDATE   100          /* Update the top two bytes of the counting event under mask. The fields in this range are V, I, NI, and IRQ (see Figure 22-55). The lower two bytes of the mask/payload in the command are used. */
#define               PD_CLEANUP   128          /* Cleanup state for a given PD instance. */
#define             PD_DO_STUFF1   129          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
#define             PD_DO_STUFF2   130          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
#define             PD_DO_STUFF3   131          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
#define             PD_DO_STUFF4   132          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
#define             PD_DO_STUFF5   133          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
#define             PD_DO_STUFF6   134          /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */
#define             PD_DO_STUFF7   135           /* Reserved opcode with unique firmware entry point to enable future hardware/software interaction expansion. Yes, this is the CYA opcode. */

#endif


/* Enumeration from Table titled: Receive Triggered Operation Target Queue (Enum - rx_tq_t) - 1 bit
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum rx_tq {
         TRIG_TX = 0,           /* Triggered operation command will go to the TX command queue. */
         TRIG_RX = 1            /* Triggered operation command will go to the RX command queue. */
};

#else

#define  TRIG_TX   0            /* Triggered operation command will go to the TX command queue. */
#define  TRIG_RX   1             /* Triggered operation command will go to the RX command queue. */

#endif


/* Enumeration from Table titled: Event Type (Enum - ptl_event_kind_t) - 6 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_event_kind {
                                           PTL_EVENT_GET = 0,           /* Data was 'pulled' from a local list entry as part of a 'get' operation. A get operation completed at the target. Portals will not read from memory on behalf of this operation once this event has been logged */
                               PTL_EVENT_GET_AUTO_UNLINK = 1,           /* A merged PTL_EVENT_GET and PTL_EVENT_AUTO_UNLINK. */
                          PTL_EVENT_GET_AUTO_UNLINK_FREE = 2,           /* A merged PTL_EVENT_GET, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE. */
                                           PTL_EVENT_PUT = 4,           /* A put matched a previously posted list entry. A put operation completed at the target. Portals will not alter memory on behalf of this operation once this event has been logged */
                               PTL_EVENT_PUT_AUTO_UNLINK = 5,           /* A merged PTL_EVENT_PUT and PTL_EVENT_AUTO_UNLINK. */
                          PTL_EVENT_PUT_AUTO_UNLINK_FREE = 6,           /* A merged PTL_EVENT_PUT, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE.1 */
                                        PTL_EVENT_ATOMIC = 8,           /* An atomic operation that does not return data to the initiator completed at the target. Portals will not read from or alter memory on behalf of this operation once this event has been logged. */
                            PTL_EVENT_ATOMIC_AUTO_UNLINK = 9,           /* A merged PTL_EVENT_ATOMIC and PTL_EVENT_AUTO_UNLINK. */
                       PTL_EVENT_ATOMIC_AUTO_UNLINK_FREE = 10,          /* A merged PTL_EVENT_ATOMIC, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE.1 */
                                  PTL_EVENT_FETCH_ATOMIC = 12,          /* An atomic operation that returns data to the initiator completed at the target. These include PtlFetchAtomic() and PtlSwap(). Portals will not read from or alter memory on behalf of this operation once this event has been logged. */
                      PTL_EVENT_FETCH_ATOMIC_AUTO_UNLINK = 13,          /* A merged PTL_EVENT_FETCH_ATOMIC and PTL_EVENT_AUTO_UNLINK. */
                 PTL_EVENT_FETCH_ATOMIC_AUTO_UNLINK_FREE = 14,          /* A merged PTL_EVENT_FETCH_ATOMIC, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE.1 */
                                  PTL_EVENT_GET_OVERFLOW = 16,          /* A list entry posted by PtlLEAppend(), PtlMEAppend() or PtlSearch() with SEARCH_DELETE matched a get header in the unexpected list. Data of length MLENGTH was 'pulled' from an entry in the overflow list as part of the get operation beginning at the Start address */
                      PTL_EVENT_GET_OVERFLOW_AUTO_UNLINK = 17,          /* A merged PTL_EVENT_GET_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
                                  PTL_EVENT_PUT_OVERFLOW = 18,          /* A list entry posted by PtlLEAppend(), PtlMEAppend()or PtlSearch() with SEARCH_DELETE matched a put header in the unexpected list. A put that previously arrived matched a new list entry. Data of length MLENGTH was deposited at the Start address. */
                      PTL_EVENT_PUT_OVERFLOW_AUTO_UNLINK = 19,          /* A merged PTL_EVENT_PUT_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
                               PTL_EVENT_ATOMIC_OVERFLOW = 20,          /* A list entry posted by PtlLEAppend(), PtlMEAppend()or PtlSearch() with SEARCH_DELETE matched an atomic header in the unexpected list for an operation which does not return data to the initiator. */
                   PTL_EVENT_ATOMIC_OVERFLOW_AUTO_UNLINK = 21,          /* A merged PTL_EVENT_ATOMIC_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
                         PTL_EVENT_FETCH_ATOMIC_OVERFLOW = 22,          /* A list entry posted by PtlLEAppend(),  PtlMEAppend()or PtlSearch() with SEARCH_DELETE matched an atomic header in the unexpected list for an operation which returns data to the initiator */
             PTL_EVENT_FETCH_ATOMIC_OVERFLOW_AUTO_UNLINK = 23,          /* A merged PTL_EVENT_FETCH_ATOMIC_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
                                   PTL_EVENT_PT_DISABLED = 24,          /* Resources exhaustion has occurred on this portal table entry, which has entered a flow control situation. */
                                   PTL_EVENT_AUTO_UNLINK = 25,          /* A list entry/match list entry was automatically unlinked. A PTL_EVENT_AUTO_UNLINK event is generated even if the list entry/match list entry passed into the PtlLEAppend()/PtlMEAppend() operation was marked with the PTL_LE_USE_ONCE/PTL_ME_USE_ONCE option and found a corresponding unexpected message before being 'linked' into the priority list. A PTL_EVENT_AUTO_UNLINK must be delivered after all PTL_EVENT_GET, PTL_EVENT_PUT, PTL_EVENT_ATOMIC, and PTL_EVENT_FETCH_ATOMIC events associated with the list entry/match list entry have been delivered. */
                              PTL_EVENT_AUTO_UNLINK_FREE = 26,          /* A merged PTL_EVENT_AUTO_UNLINK and PTL_EVENT_AUTO_FREE.1 */
                                     PTL_EVENT_AUTO_FREE = 27,          /* A list entry/match list entry previously automatically unlinked from the overflow list is now free to be reused by the application. A PTL_EVENT_AUTO_FREE event is generated when Portals will not generate any further events1 which resulted from messages delivered into the specified overflow list entry. This also indicates that the unexpected list contains no more items associated with this entry. A list entry/match list entry which disabled unexpected headers will not generate this event, even if placed in the overflow list. */
                                        PTL_EVENT_SEARCH = 28,          /* A PtlLESearch() or PtlMESearch() call completed. If a matching message was found in the overflow list, PTL_NI_OK is returned in the ni_fail_type field of the event and the event queue entries are filled in as if it were an overflow event. Otherwise, a failure is recorded in the ni_fail_type field using PTL_NI_NO_MATCH, the user_ptr is filled in correctly, and the other fields are undefined. */
                                          PTL_EVENT_LINK = 29,          /* A list entry posted by PtlLEAppend() or PtlMEAppend() has successfully linked into the specified list */
                                         PTL_EVENT_REPLY = 30,          /* A reply operation has completed at the initiator, either due to a get operation or an atomic which returned data to the initiator. This event is logged after the data (if any) from the reply has been written into the memory descriptor. Receipt of a PTL_EVENT_REPLY indicates remote completion of the operation. */
                                          PTL_EVENT_SEND = 31,          /* A put or atomic has completed at the initiator. This event is logged after it is safe to reuse the buffer, but does not mean the message has been processed by the target. */
                                           PTL_EVENT_ACK = 32,          /* An acknowledgment was received. This event is logged when the acknowledgment is received. Receipt of a PTL_EVENT_ACK indicates remote completion of the operation. Remote completion indicates that local completion has also occurred. */
                                      PTL_EVENT_SEND_ACK = 33,          /* A combined PTL_EVENT_SEND and PTL_EVENT_ACK */
                                         PTL_EVENT_ERROR = 34,          /* An error occurred that is not specified or cannot return all of the required fields in a valid error type. PTL_EVENT_ERROR is intended to be used in cases where unspecified errors may e deductible and recoverable by the application. For example, file systems may be able to recover from errors that cannot be fully described by the Portals implementation. */
                                        PTL_CMD_COMPLETE = 35,          /* A command that was issue to the HFI has completed. PTL_CMD_COMPLETE always posts onto EQ=0 for NI=0 regardless of which NI it was issued on. This event can be delivered at the target using the simplified event format (Figure 22-59), where only the event type, fail type, PTL_IDX and user pointer are valid. */
                             PTL_EVENT_INITIATOR_CONNECT = 36,          /* A connection has been completed. This event can be delivered at the initiator using the simplified event format (Figure 22-59), where only the event type, fail type, PTL_IDX (containing the Protocol Version requested) and user pointer are valid. This event is delivered to the EQ and NI specified in the command that initiated the connection. */
                                PTL_EVENT_TARGET_CONNECT = 37,          /* A connection has been completed. This event can be delivered at the target using the target event format (Figure 22-58), where only the event type, port, fail type, LID field of the initiator and user pointer are valid. The TC is placed in the lower order bits of the user pointer. These events are hard-coded to go to EQ=0 / NI=NONMATCHING_LOGICAL */
                                    PTL_EVENT_DISCONNECT = 38,          /* A disconnection has been completed. This event can be delivered at the target using the target event format (Figure 22-58), where only the event type, fail type, LID field of the initiator and user pointer are valid. The TC is placed in the lower order bits of the user pointer. */
                                       PTL_EVENT_PT_READ = 39,          /* An event containing the Portal Table Entry being read. */
                                       PTL_EVENT_ME_READ = 40,          /* An event containing the ME that is being read */
                                  NON_PTL_EVENT_RX_TYPE0 = 48,          /* WFR Compatible RcvType0 */
                                  NON_PTL_EVENT_RX_TYPE1 = 49,          /* WFR Compatible RcvType1 */
                                  NON_PTL_EVENT_RX_TYPE2 = 50,          /* WFR Compatible RcvType2 */
                                  NON_PTL_EVENT_RX_TYPE3 = 51,          /* WFR Compatible RcvType3 */
                                  NON_PTL_EVENT_RX_TYPE4 = 52,          /* WFR Compatible RcvType4 */
                                  NON_PTL_EVENT_RX_TYPE5 = 53,          /* WFR Compatible RcvType5 */
                                  NON_PTL_EVENT_RX_TYPE6 = 54,          /* WFR Compatible RcvType6 */
                                  NON_PTL_EVENT_RX_TYPE7 = 55,          /* WFR Compatible RcvType7 */
                                  NON_PTL_EVENT_VERBS_RX = 56,          /* Verbs receive side completion */
                                  NON_PTL_EVENT_VERBS_TX = 62,          /* Verbs transmit side completion */
                               NON_PTL_EVENT_TX_COMPLETE = 63           /* Completion of a Non Portals transmit DMA operation. */
};

#else

#define                                    PTL_EVENT_GET   0            /* Data was 'pulled' from a local list entry as part of a 'get' operation. A get operation completed at the target. Portals will not read from memory on behalf of this operation once this event has been logged */
#define                        PTL_EVENT_GET_AUTO_UNLINK   1            /* A merged PTL_EVENT_GET and PTL_EVENT_AUTO_UNLINK. */
#define                   PTL_EVENT_GET_AUTO_UNLINK_FREE   2            /* A merged PTL_EVENT_GET, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE. */
#define                                    PTL_EVENT_PUT   4            /* A put matched a previously posted list entry. A put operation completed at the target. Portals will not alter memory on behalf of this operation once this event has been logged */
#define                        PTL_EVENT_PUT_AUTO_UNLINK   5            /* A merged PTL_EVENT_PUT and PTL_EVENT_AUTO_UNLINK. */
#define                   PTL_EVENT_PUT_AUTO_UNLINK_FREE   6            /* A merged PTL_EVENT_PUT, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE.1 */
#define                                 PTL_EVENT_ATOMIC   8            /* An atomic operation that does not return data to the initiator completed at the target. Portals will not read from or alter memory on behalf of this operation once this event has been logged. */
#define                     PTL_EVENT_ATOMIC_AUTO_UNLINK   9            /* A merged PTL_EVENT_ATOMIC and PTL_EVENT_AUTO_UNLINK. */
#define                PTL_EVENT_ATOMIC_AUTO_UNLINK_FREE   10           /* A merged PTL_EVENT_ATOMIC, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE.1 */
#define                           PTL_EVENT_FETCH_ATOMIC   12           /* An atomic operation that returns data to the initiator completed at the target. These include PtlFetchAtomic() and PtlSwap(). Portals will not read from or alter memory on behalf of this operation once this event has been logged. */
#define               PTL_EVENT_FETCH_ATOMIC_AUTO_UNLINK   13           /* A merged PTL_EVENT_FETCH_ATOMIC and PTL_EVENT_AUTO_UNLINK. */
#define          PTL_EVENT_FETCH_ATOMIC_AUTO_UNLINK_FREE   14           /* A merged PTL_EVENT_FETCH_ATOMIC, PTL_EVENT_AUTO_UNLINK, and PTL_EVENT_AUTO_FREE.1 */
#define                           PTL_EVENT_GET_OVERFLOW   16           /* A list entry posted by PtlLEAppend(), PtlMEAppend() or PtlSearch() with SEARCH_DELETE matched a get header in the unexpected list. Data of length MLENGTH was 'pulled' from an entry in the overflow list as part of the get operation beginning at the Start address */
#define               PTL_EVENT_GET_OVERFLOW_AUTO_UNLINK   17           /* A merged PTL_EVENT_GET_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
#define                           PTL_EVENT_PUT_OVERFLOW   18           /* A list entry posted by PtlLEAppend(), PtlMEAppend()or PtlSearch() with SEARCH_DELETE matched a put header in the unexpected list. A put that previously arrived matched a new list entry. Data of length MLENGTH was deposited at the Start address. */
#define               PTL_EVENT_PUT_OVERFLOW_AUTO_UNLINK   19           /* A merged PTL_EVENT_PUT_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
#define                        PTL_EVENT_ATOMIC_OVERFLOW   20           /* A list entry posted by PtlLEAppend(), PtlMEAppend()or PtlSearch() with SEARCH_DELETE matched an atomic header in the unexpected list for an operation which does not return data to the initiator. */
#define            PTL_EVENT_ATOMIC_OVERFLOW_AUTO_UNLINK   21           /* A merged PTL_EVENT_ATOMIC_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
#define                  PTL_EVENT_FETCH_ATOMIC_OVERFLOW   22           /* A list entry posted by PtlLEAppend(),  PtlMEAppend()or PtlSearch() with SEARCH_DELETE matched an atomic header in the unexpected list for an operation which returns data to the initiator */
#define      PTL_EVENT_FETCH_ATOMIC_OVERFLOW_AUTO_UNLINK   23           /* A merged PTL_EVENT_FETCH_ATOMIC_OVERFLOW and PTL_EVENT_AUTO_UNLINK. */
#define                            PTL_EVENT_PT_DISABLED   24           /* Resources exhaustion has occurred on this portal table entry, which has entered a flow control situation. */
#define                            PTL_EVENT_AUTO_UNLINK   25           /* A list entry/match list entry was automatically unlinked. A PTL_EVENT_AUTO_UNLINK event is generated even if the list entry/match list entry passed into the PtlLEAppend()/PtlMEAppend() operation was marked with the PTL_LE_USE_ONCE/PTL_ME_USE_ONCE option and found a corresponding unexpected message before being 'linked' into the priority list. A PTL_EVENT_AUTO_UNLINK must be delivered after all PTL_EVENT_GET, PTL_EVENT_PUT, PTL_EVENT_ATOMIC, and PTL_EVENT_FETCH_ATOMIC events associated with the list entry/match list entry have been delivered. */
#define                       PTL_EVENT_AUTO_UNLINK_FREE   26           /* A merged PTL_EVENT_AUTO_UNLINK and PTL_EVENT_AUTO_FREE.1 */
#define                              PTL_EVENT_AUTO_FREE   27           /* A list entry/match list entry previously automatically unlinked from the overflow list is now free to be reused by the application. A PTL_EVENT_AUTO_FREE event is generated when Portals will not generate any further events1 which resulted from messages delivered into the specified overflow list entry. This also indicates that the unexpected list contains no more items associated with this entry. A list entry/match list entry which disabled unexpected headers will not generate this event, even if placed in the overflow list. */
#define                                 PTL_EVENT_SEARCH   28           /* A PtlLESearch() or PtlMESearch() call completed. If a matching message was found in the overflow list, PTL_NI_OK is returned in the ni_fail_type field of the event and the event queue entries are filled in as if it were an overflow event. Otherwise, a failure is recorded in the ni_fail_type field using PTL_NI_NO_MATCH, the user_ptr is filled in correctly, and the other fields are undefined. */
#define                                   PTL_EVENT_LINK   29           /* A list entry posted by PtlLEAppend() or PtlMEAppend() has successfully linked into the specified list */
#define                                  PTL_EVENT_REPLY   30           /* A reply operation has completed at the initiator, either due to a get operation or an atomic which returned data to the initiator. This event is logged after the data (if any) from the reply has been written into the memory descriptor. Receipt of a PTL_EVENT_REPLY indicates remote completion of the operation. */
#define                                   PTL_EVENT_SEND   31           /* A put or atomic has completed at the initiator. This event is logged after it is safe to reuse the buffer, but does not mean the message has been processed by the target. */
#define                                    PTL_EVENT_ACK   32           /* An acknowledgment was received. This event is logged when the acknowledgment is received. Receipt of a PTL_EVENT_ACK indicates remote completion of the operation. Remote completion indicates that local completion has also occurred. */
#define                               PTL_EVENT_SEND_ACK   33           /* A combined PTL_EVENT_SEND and PTL_EVENT_ACK */
#define                                  PTL_EVENT_ERROR   34           /* An error occurred that is not specified or cannot return all of the required fields in a valid error type. PTL_EVENT_ERROR is intended to be used in cases where unspecified errors may e deductible and recoverable by the application. For example, file systems may be able to recover from errors that cannot be fully described by the Portals implementation. */
#define                                 PTL_CMD_COMPLETE   35           /* A command that was issue to the HFI has completed. PTL_CMD_COMPLETE always posts onto EQ=0 for NI=0 regardless of which NI it was issued on. This event can be delivered at the target using the simplified event format (Figure 22-59), where only the event type, fail type, PTL_IDX and user pointer are valid. */
#define                      PTL_EVENT_INITIATOR_CONNECT   36           /* A connection has been completed. This event can be delivered at the initiator using the simplified event format (Figure 22-59), where only the event type, fail type, PTL_IDX (containing the Protocol Version requested) and user pointer are valid. This event is delivered to the EQ and NI specified in the command that initiated the connection. */
#define                         PTL_EVENT_TARGET_CONNECT   37           /* A connection has been completed. This event can be delivered at the target using the target event format (Figure 22-58), where only the event type, port, fail type, LID field of the initiator and user pointer are valid. The TC is placed in the lower order bits of the user pointer. These events are hard-coded to go to EQ=0 / NI=NONMATCHING_LOGICAL */
#define                             PTL_EVENT_DISCONNECT   38           /* A disconnection has been completed. This event can be delivered at the target using the target event format (Figure 22-58), where only the event type, fail type, LID field of the initiator and user pointer are valid. The TC is placed in the lower order bits of the user pointer. */
#define                                PTL_EVENT_PT_READ   39           /* An event containing the Portal Table Entry being read. */
#define                                PTL_EVENT_ME_READ   40           /* An event containing the ME that is being read */
#define                           NON_PTL_EVENT_RX_TYPE0   48           /* WFR Compatible RcvType0 */
#define                           NON_PTL_EVENT_RX_TYPE1   49           /* WFR Compatible RcvType1 */
#define                           NON_PTL_EVENT_RX_TYPE2   50           /* WFR Compatible RcvType2 */
#define                           NON_PTL_EVENT_RX_TYPE3   51           /* WFR Compatible RcvType3 */
#define                           NON_PTL_EVENT_RX_TYPE4   52           /* WFR Compatible RcvType4 */
#define                           NON_PTL_EVENT_RX_TYPE5   53           /* WFR Compatible RcvType5 */
#define                           NON_PTL_EVENT_RX_TYPE6   54           /* WFR Compatible RcvType6 */
#define                           NON_PTL_EVENT_RX_TYPE7   55           /* WFR Compatible RcvType7 */
#define                           NON_PTL_EVENT_VERBS_RX   56           /* Verbs receive side completion */
#define                           NON_PTL_EVENT_VERBS_TX   62           /* Verbs transmit side completion */
#define                        NON_PTL_EVENT_TX_COMPLETE   63            /* Completion of a Non Portals transmit DMA operation. */

#endif


/* Enumeration from Table titled: Event Fail Type (Enum - ptl_ni_fail_t) - 6 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_ni_fail {
                       PTL_NI_OK = 0,           /* The operation causing the event was successful */
            PTL_NI_UNDELIVERABLE = 1,           /* Indicates a system failure that prevents message delivery. Typically, this error is seen at the initiator when a time-out limit is reached. */
                  PTL_NI_DROPPED = 2,           /* Indicates that the message associated with this full event was dropped at the target for reasons other than a disabled portal table entry. This failure type should only be returned on initiator events. */
                      PTL_IN_USE = 3,           /* The ME/LE is busy and cannot be unlinked. This is only generated when querying local list state. */
               PTL_NI_CMD_FAILED = 4,           /* Indicates that a TX command failed due to an uncorrectable error at the initiator.Note: this encoding is not required of the implementation at this time. */
           PTL_NI_INVALID_TARGET = 8,           /* Indicates that the message associated with this full event was dropped at the target because either the PID or PT Index was invalid. This failure type should only be returned on initiator events. */
              PTL_NI_PT_DISABLED = 9,           /* Indicates that the portal table entry at the target was disabled and did not process the operation, either because the entry was disabled with PtlPTDisable() or because the entry provides flow control and a resource has been exhausted. This failure type should only be returned on initiator events. */
           PTL_NI_PERM_VIOLATION = 10,          /* Indicates that the remote Portals addressing has indicated a permissions violation for the operation that caused this event. This failure type should only be returned on initiator events. */
             PTL_NI_OP_VIOLATION = 11,          /* Indicates that the remote Portals addressing has indicated an operation violation for the operation that caused this event. This failure type should only be returned on initiator events. */
                     PTL_NI_SEGV = 12,          /* Indicates that the message associated with this full event failed because it would have caused a segmentation fault (address translation failure). There are some situations where a segmentation fault happens for operations related to a message, but the failureor the failure reason is not known by the time the event is generated. See Table 22-150 for details on how segmentation faults at different stages of the protocol are reported. */
                 PTL_NI_NO_MATCH = 13,          /* On a PTL_EVENT_SEARCH, this indicates that a match was not found. This is only generated when querying local list state. */
                PTL_NI_CANCELLED = 14,          /* Indicates that the event is the result of canceling a message. This failure type should only be returned on initiator events or reply events. */
              PTL_NI_UNSUPPORTED = 15,          /* An unsupported operation was attempted. This is delivered at the initiator when a PTL_NACK_UNSUPPORTED is received or an unsupported operation is detected locally and prevented. As an example, a Put with IOVEC or an MEAppend with IOVEC could have a pointer to the IOVEC that is not aligned. */
              PTL_NI_ACK_REFUSED = 16,          /* Failure type provided when OTR is configured to enable events after a PTL_ACK_REFUSED. This failure type should only be returned on initiator events. */
           PTL_NI_CONNECT_FAILED = 17,          /* A connection attempt failed. Only the initiator indicates a connection failure. */
              PTL_NI_UNREQUESTED = 18,          /* This event was not requested by software, but was delivered anyway. This is for use in any scenario where an event is being delivered that the software configured off. Specifically, overflow entries will always deliver an even for any incoming network operation. For example, if PTL_EVENT_PUT in an overflow entry, the overflow entry will deliver at least one event. If no request was requested for the scenario, the delivered event will have a PTL_NI_UNREQUESTED failure type. PTL_NI_UNREQUESTED will never be used for a 'combined' event. */
                  PTL_NI_TX_SEGV = 28           /* Indicates that the message associated with this full event failed because it would have caused a segmentation fault (address translation failure). There are some situations where a segmentation fault happens for operations related to a message, but the failureor the failure reason is not known by the time the event is generated. See Table 22-150 for details on how segmentation faults at different stages of the protocol are reported. */
};

#else

#define                PTL_NI_OK   0            /* The operation causing the event was successful */
#define     PTL_NI_UNDELIVERABLE   1            /* Indicates a system failure that prevents message delivery. Typically, this error is seen at the initiator when a time-out limit is reached. */
#define           PTL_NI_DROPPED   2            /* Indicates that the message associated with this full event was dropped at the target for reasons other than a disabled portal table entry. This failure type should only be returned on initiator events. */
#define               PTL_IN_USE   3            /* The ME/LE is busy and cannot be unlinked. This is only generated when querying local list state. */
#define        PTL_NI_CMD_FAILED   4            /* Indicates that a TX command failed due to an uncorrectable error at the initiator.Note: this encoding is not required of the implementation at this time. */
#define    PTL_NI_INVALID_TARGET   8            /* Indicates that the message associated with this full event was dropped at the target because either the PID or PT Index was invalid. This failure type should only be returned on initiator events. */
#define       PTL_NI_PT_DISABLED   9            /* Indicates that the portal table entry at the target was disabled and did not process the operation, either because the entry was disabled with PtlPTDisable() or because the entry provides flow control and a resource has been exhausted. This failure type should only be returned on initiator events. */
#define    PTL_NI_PERM_VIOLATION   10           /* Indicates that the remote Portals addressing has indicated a permissions violation for the operation that caused this event. This failure type should only be returned on initiator events. */
#define      PTL_NI_OP_VIOLATION   11           /* Indicates that the remote Portals addressing has indicated an operation violation for the operation that caused this event. This failure type should only be returned on initiator events. */
#define              PTL_NI_SEGV   12           /* Indicates that the message associated with this full event failed because it would have caused a segmentation fault (address translation failure). There are some situations where a segmentation fault happens for operations related to a message, but the failureor the failure reason is not known by the time the event is generated. See Table 22-150 for details on how segmentation faults at different stages of the protocol are reported. */
#define          PTL_NI_NO_MATCH   13           /* On a PTL_EVENT_SEARCH, this indicates that a match was not found. This is only generated when querying local list state. */
#define         PTL_NI_CANCELLED   14           /* Indicates that the event is the result of canceling a message. This failure type should only be returned on initiator events or reply events. */
#define       PTL_NI_UNSUPPORTED   15           /* An unsupported operation was attempted. This is delivered at the initiator when a PTL_NACK_UNSUPPORTED is received or an unsupported operation is detected locally and prevented. As an example, a Put with IOVEC or an MEAppend with IOVEC could have a pointer to the IOVEC that is not aligned. */
#define       PTL_NI_ACK_REFUSED   16           /* Failure type provided when OTR is configured to enable events after a PTL_ACK_REFUSED. This failure type should only be returned on initiator events. */
#define    PTL_NI_CONNECT_FAILED   17           /* A connection attempt failed. Only the initiator indicates a connection failure. */
#define       PTL_NI_UNREQUESTED   18           /* This event was not requested by software, but was delivered anyway. This is for use in any scenario where an event is being delivered that the software configured off. Specifically, overflow entries will always deliver an even for any incoming network operation. For example, if PTL_EVENT_PUT in an overflow entry, the overflow entry will deliver at least one event. If no request was requested for the scenario, the delivered event will have a PTL_NI_UNREQUESTED failure type. PTL_NI_UNREQUESTED will never be used for a 'combined' event. */
#define           PTL_NI_TX_SEGV   28            /* Indicates that the message associated with this full event failed because it would have caused a segmentation fault (address translation failure). There are some situations where a segmentation fault happens for operations related to a message, but the failureor the failure reason is not known by the time the event is generated. See Table 22-150 for details on how segmentation faults at different stages of the protocol are reported. */

#endif


/* Enumeration from Table titled: Portals Status Registers (Enum - ptl_sr_index_t) - 4bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum ptl_sr_index {
                       PTL_SR_DROP_COUNT = 0,           /* The count of all dropped/NACKed Portals messages, exclusive of those dropped for permission violations or operation violations (i.e. whenever a PTL_NACK_PERMV or PTL_NACK_OPV would be sent). Among the reasons for dropping a message are length/alignment/opcode/data-type violations, especially for atomics. This counter does not include any messages that were dropped/NACKed as part of the E2E protocol, since those will be retransmitted until the retransmit limit is reached. If flow control is not enabled, packets that are dropped due to resource exhaustion increment PTL_SR_DROP_COUNT. If flow control is enabled, flow control is invoked and does not increment SR_DROP_COUNT. For the Rendezvous protocol, only the RTS packet is considered. This counter is incremented at the target, and is not incremented at the initiator. */
            PTL_SR_PERMISSION_VIOLATIONS = 1,           /* The count of all attempted permission violations (USER ID mismatch). The error precedence for this counter matches the error precedence for sending a PTL_NACK_PERMV (e.g. it is not incremented when a failure results in a different type of NACK). For the Rendezvous protocol, only the RTS packet is considered. This counter is incremented at the target, and is not incremented at the initiator. In the case of Native Verbs, this counter is incremented if a PTL_NACK_PERMV is sent. */
             PTL_SR_OPERATION_VIOLATIONS = 2,           /* The count of all attempted Put/Get operation violations (read/write violation). The error precedence for this counter matches the error precedence for sending a PTL_NACK_OPV (e.g. it is not incremented when a failure results in a different type of NACK). For the Rendezvous protocol, only the RTS packet is considered. This counter is incremented at the target, and is not incremented at the initiator. In the case of Native Verbs, this counter is incremented if a PTL_NACK_OPV is sent. */
             PTL_SR_MAX_RETRANSMIT_LIMIT = 3            /* The count of all of the messages that have failed due to one or more packets reaching a retransmit limit. */
};

#else

#define                PTL_SR_DROP_COUNT   0            /* The count of all dropped/NACKed Portals messages, exclusive of those dropped for permission violations or operation violations (i.e. whenever a PTL_NACK_PERMV or PTL_NACK_OPV would be sent). Among the reasons for dropping a message are length/alignment/opcode/data-type violations, especially for atomics. This counter does not include any messages that were dropped/NACKed as part of the E2E protocol, since those will be retransmitted until the retransmit limit is reached. If flow control is not enabled, packets that are dropped due to resource exhaustion increment PTL_SR_DROP_COUNT. If flow control is enabled, flow control is invoked and does not increment SR_DROP_COUNT. For the Rendezvous protocol, only the RTS packet is considered. This counter is incremented at the target, and is not incremented at the initiator. */
#define     PTL_SR_PERMISSION_VIOLATIONS   1            /* The count of all attempted permission violations (USER ID mismatch). The error precedence for this counter matches the error precedence for sending a PTL_NACK_PERMV (e.g. it is not incremented when a failure results in a different type of NACK). For the Rendezvous protocol, only the RTS packet is considered. This counter is incremented at the target, and is not incremented at the initiator. In the case of Native Verbs, this counter is incremented if a PTL_NACK_PERMV is sent. */
#define      PTL_SR_OPERATION_VIOLATIONS   2            /* The count of all attempted Put/Get operation violations (read/write violation). The error precedence for this counter matches the error precedence for sending a PTL_NACK_OPV (e.g. it is not incremented when a failure results in a different type of NACK). For the Rendezvous protocol, only the RTS packet is considered. This counter is incremented at the target, and is not incremented at the initiator. In the case of Native Verbs, this counter is incremented if a PTL_NACK_OPV is sent. */
#define      PTL_SR_MAX_RETRANSMIT_LIMIT   3             /* The count of all of the messages that have failed due to one or more packets reaching a retransmit limit. */

#endif


/* Enumeration from Table titled: Privilege Level (Enum - priv_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum priv {
          KERNEL = 0,           /* Privilege level zero (kernel / ring 0 level of privilege) */
            USER = 1            /* Privilege level one (ring 3 / user level of privilege) */
};

#else

#define   KERNEL   0            /* Privilege level zero (kernel / ring 0 level of privilege) */
#define     USER   1             /* Privilege level one (ring 3 / user level of privilege) */

#endif


/* Enumeration from Table titled: Buffer State (Enum - rend_buff_state_t) - 3 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum rend_buff_state {
                     Unallocated = 0,           /* Entry is not currently allocated. */
                   AWAITING_RESP = 1,           /* An Request (RTS or Standard) has been sent for this message, and the buffer expects a response (CTS or Portals ACK or Reply). */
               CTS_AWAITING_CNT0 = 4,           /* A CTS has been received for this message, and this message is awaiting the completion of all of the packets (correctly or in error). */
              ECTS_AWAITING_CNT0 = 5,           /* An ECTS has been received for this message, and this message is awaiting the completion of all of the packets (correctly or in error). */
              AWAITING_EVENT_ACK = 6,           /* The final event message for an ECTS flow has been sent and is awaiting acknowledgement. */
                   AWAITING_CNT0 = 7            /* Gen1 state used to wait for the message to complete. */
};

#else

#define              Unallocated   0            /* Entry is not currently allocated. */
#define            AWAITING_RESP   1            /* An Request (RTS or Standard) has been sent for this message, and the buffer expects a response (CTS or Portals ACK or Reply). */
#define        CTS_AWAITING_CNT0   4            /* A CTS has been received for this message, and this message is awaiting the completion of all of the packets (correctly or in error). */
#define       ECTS_AWAITING_CNT0   5            /* An ECTS has been received for this message, and this message is awaiting the completion of all of the packets (correctly or in error). */
#define       AWAITING_EVENT_ACK   6            /* The final event message for an ECTS flow has been sent and is awaiting acknowledgement. */
#define            AWAITING_CNT0   7             /* Gen1 state used to wait for the message to complete. */

#endif


/* Enumeration from Table titled: OMB Entry Type (Enum - omb_entry_type_t) - 1 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum omb_entry_type {
              FIRST_DESC = 0,           /* Entry holds the first (or only) of two entries used to describe a message. This can be the message descriptor (e.g. a buffered operation) or the first entry for a rendezvous operation. */
             SECOND_DESC = 1            /* Entry holds the second descriptor used to describe a message. This can be used to hold data (e.g. a buffered operation) or the CTS information for a rendezvous operation. */
};

#else

#define       FIRST_DESC   0            /* Entry holds the first (or only) of two entries used to describe a message. This can be the message descriptor (e.g. a buffered operation) or the first entry for a rendezvous operation. */
#define      SECOND_DESC   1             /* Entry holds the second descriptor used to describe a message. This can be used to hold data (e.g. a buffered operation) or the CTS information for a rendezvous operation. */

#endif


/* Enumeration from Table titled: OPB Buffer State (Enum - opb_buff_state_t) - 4 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum opb_buff_state {
                     PACKET_SENT = 0,           /* A packet has been sent. The OPB entry is waiting on an E2E Acknowledgement and possibly a response. */
                    ACK_RECEIVED = 1,           /* Packet has been acknowledged by an E2E ACK, but has not received the response that is required. The packet will not be retransmitted, but OPB entry is subject to harvesting if the peer node goes away. Harvesting occurs when the packet goes through a retransmit limit number of time-outs. */
               RESPONSE_RECEIVED = 2,           /* DEPRECATED: The response has been received (and processed, including sending the E2E Ack), but the E2E acknowledgement has not. The OPB entry will be held until the next time-out occurs, at which point the E2E acknowledgement can be assumed to be lost (safely). */
                         PENDING = 3,           /* Packet has been queued for later transmit (e.g. retransmit). */
                 ACK_CMD_PENDING = 4,           /* An OPB entry has seen a response (e.g. Reply to a Get or Portals ACK with piggybacked E2E Ack) and is waiting for an acknowledgement command to propagate through the RXDMA pipeline and re-enter the OPB. */
              ACK_CMD_PENDING_NA = 5,           /* An OPB entry has seen a response (e.g. Reply to a Get) and is waiting for an acknowledgement to propagate through the pipeline, but the E2E ack has not been received yet. This correlates to the RESPONSE_RECEIVED path through the state machine. */
                     ACK_PENDING = 6,           /* OPB entry is being used to hold a pending acknowledgement. Entry is held until acknowledgement is issued into the correct MC/TC into the DMA engine. */
                  ACK_PENDING_NA = 7,           /* OPB entry is being used to hold a pending acknowledgement. Entry is held until acknowledgement is issued into the correct MC/TC into the DMA engine and a protocol acknowledgement is received. */
                PKT_DONE_PENDING = 8,           
             PKT_DONE_PENDING_NA = 9,           
                  PACKET_SENT_NA = 10           
};

#else

#define              PACKET_SENT   0            /* A packet has been sent. The OPB entry is waiting on an E2E Acknowledgement and possibly a response. */
#define             ACK_RECEIVED   1            /* Packet has been acknowledged by an E2E ACK, but has not received the response that is required. The packet will not be retransmitted, but OPB entry is subject to harvesting if the peer node goes away. Harvesting occurs when the packet goes through a retransmit limit number of time-outs. */
#define        RESPONSE_RECEIVED   2            /* DEPRECATED: The response has been received (and processed, including sending the E2E Ack), but the E2E acknowledgement has not. The OPB entry will be held until the next time-out occurs, at which point the E2E acknowledgement can be assumed to be lost (safely). */
#define                  PENDING   3            /* Packet has been queued for later transmit (e.g. retransmit). */
#define          ACK_CMD_PENDING   4            /* An OPB entry has seen a response (e.g. Reply to a Get or Portals ACK with piggybacked E2E Ack) and is waiting for an acknowledgement command to propagate through the RXDMA pipeline and re-enter the OPB. */
#define       ACK_CMD_PENDING_NA   5            /* An OPB entry has seen a response (e.g. Reply to a Get) and is waiting for an acknowledgement to propagate through the pipeline, but the E2E ack has not been received yet. This correlates to the RESPONSE_RECEIVED path through the state machine. */
#define              ACK_PENDING   6            /* OPB entry is being used to hold a pending acknowledgement. Entry is held until acknowledgement is issued into the correct MC/TC into the DMA engine. */
#define           ACK_PENDING_NA   7            /* OPB entry is being used to hold a pending acknowledgement. Entry is held until acknowledgement is issued into the correct MC/TC into the DMA engine and a protocol acknowledgement is received. */
#define         PKT_DONE_PENDING   8            
#define      PKT_DONE_PENDING_NA   9            
#define           PACKET_SENT_NA   10            

#endif


/* Enumeration from Table titled: Transmit Protocol Control Field (Enum - tx_proto_ctrl_t) - 4 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum tx_proto_ctrl {
          TX_UNCONNECTED = 0,           /* The transmit protocol state is always initialized to unconnected. */
         TX_CONNECTED_P0 = 1,           /* Transmits to this DLID may only be sent over Port0. The Adaptive enable bit to LinkMux must be off. DEPRECATED */
         TX_CONNECTED_P1 = 2,           /* Transmits to this DLID may only be sent over Port1. The Adaptive enable bit to LinkMux must be off. DEPRECATED */
            TX_CONNECTED = 3            /* Transmits to this DLID may be sent. */
};

#else

#define   TX_UNCONNECTED   0            /* The transmit protocol state is always initialized to unconnected. */
#define  TX_CONNECTED_P0   1            /* Transmits to this DLID may only be sent over Port0. The Adaptive enable bit to LinkMux must be off. DEPRECATED */
#define  TX_CONNECTED_P1   2            /* Transmits to this DLID may only be sent over Port1. The Adaptive enable bit to LinkMux must be off. DEPRECATED */
#define     TX_CONNECTED   3             /* Transmits to this DLID may be sent. */

#endif


/* Enumeration from Table titled: Performance counter names (Enum - perf_counter_t) - 9 bits
*                        In File: 020_TOC
*/
#if defined(__STDC__)

enum perf_counter {
                     txci_stall_hcq_empty_events = 0,           /* Host transmit command queues are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
                     txci_stall_rcq_empty_events = 1,           /* RX to TX command queues are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
                      txci_stall_cq_empty_events = 2,           /* All command queues in TxCI are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
                                   txci_cmds_mc0 = 3,           /* Total Commands Issued on MC0 */
                                   txci_cmds_mc1 = 4,           /* Total Commands Issued on MC1 */
                      txci_rcq_mc0_slots_written = 5,           /* Total Number of slots written by Rx on MC0 */
                      txci_rcq_mc1_slots_written = 6,           /* Total Number of slots written by Rx on MC1 */
                          txci_hcq_slots_written = 7,           /* Total Number of slots written into the Tx Command queue (either in full 64B writes or by partial writes). */
                     txci_hcq_nonfull_slot_write = 8,           /* A slot in the TX Command queue was partially written (less than 64B written is a single transaction, regardless of whether it fills a slot or not). */
                        txci_stall_otr_credits_w = 9,           /* Transmit command queues are stalled because no credits are available in the downstream interface (OTR) for the MC/TC. Commands must be available for this event to be counted. The TC/MC for this counter is selected in the TXCI block by a CSR.Cross Reference to W: xrefCross Reference to X: xrefCross Reference to Y: xrefCross Reference to Z: xref */
                        txci_stall_otr_credits_x = 10,          
                        txci_stall_otr_credits_y = 11,          
                        txci_stall_otr_credits_z = 12,          
                                 txci_reserved_a = 13,          /* Reserved */
                                 txci_reserved_b = 14,          /* Reserved */
                         otr_stall_omb_entries_x = 15,          /* The OTR is stalled waiting for OMB entries. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.1, 'Stall OMB Entries X Performance CSR'Cross Reference to Y: Section 32.8.8.2, 'Stall OMB Entries Y Performance CSR' */
                         otr_stall_omb_entries_y = 16,          
                       otr_stall_rxdma_credits_x = 17,          /* The OTR is stalled waiting for credits to the RXDMA block. The TC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.3, 'Stall RXDMA Credits X Performance CSR'Cross Reference to Y: Section 32.8.8.4, 'Stall RXDMA Credits Y Performance CSR' */
                       otr_stall_rxdma_credits_y = 18,          
                                   otr_stall_cts = 19,          /* The CTS queue within OTR has stalled for lack of credits. */
                      otr_m_to_p_stall_credits_x = 20,          /* The OMB to OPB queues are stalled waiting on credits. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.5, 'Stall Message Partition to Packet Partition Credits X Performance CSR'Cross Reference to Y: Section 32.8.8.6, 'Stall Message Partition to Packet Partition Credits Y Performance CSR' */
                      otr_m_to_p_stall_credits_y = 21,          
                     otr_prefrag_stall_credits_x = 22,          /* The pre-fragmentation queue is stalled waiting for access to the fragmentation PE. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.7, 'Stall Pre-Fragmentation Credits X Performance CSR'Cross Reference to Y: Section 32.8.8.8, 'Stall Pre-Fragmentation Credits Y Performance CSR' */
                     otr_prefrag_stall_credits_y = 23,          
                          otr_cmd_ordering_stall = 24,          /* The OTR is stalled to enforce command ordering */
                           otr_messages_opened_x = 25,          /* Total number of messages generated by OTR (sum of both fastpath and fragmentation messages). This reflects the number of OMB entries allocated. The TC/MC is selected in the OTR block.Cross Reference to X: */
                           otr_messages_closed_x = 26,          /* Total number of messages completed by OTR. This reflects the number of OMB entries closed. The TC/MC is selected in the OTR block.Cross Reference to X: */
                  otr_cmd_portals_ordering_stall = 27,          /* The OTR is stalled to enforce Portals command ordering (8.3.4.1) */
                   otr_cmd_compat_ordering_stall = 28,          /* The OTR is stalled to enforce compatibility (KDETH/Verbs) command ordering (8.3.4.2) */
                   otr_cmd_fragpe_ordering_stall = 29,          /* The OTR is stalled to enforce programmable engine ordering command ordering (8.3.4.3) */
                        otr_omb_collision_replay = 30,          /* The OTR pipeline was flushed due to an OMB collision. (Bongjin suggested this fix for a bug, I want it counted to assess how often it happens) */
                              otr_msg_reserved_a = 31,          /* Reserved */
                            otr_rsp_special_acks = 32,          /* This counter counts the special ACKs received by the OTR on any TC */
                         otr_stall_opb_entries_x = 33,          /* The OTR is stalled waiting for OPB entries. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 29.7.3.152, 'Stall OPB Entries X Performance CSR'Cross Reference to Y: Section 32.7.8.2, 'Stall OMB Entries Y Performance CSR' */
                         otr_stall_opb_entries_y = 34,          
                       otr_stall_txdma_credits_x = 35,          /* The OTR is stalled waiting for credits to the TXDMA block. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.7.8.3, 'Stall TXDMA Credits X Performance CSR'Cross Reference to Y: Section 32.7.8.4, 'Stall TXDMA Credits Y Performance CSR' */
                       otr_stall_txdma_credits_y = 36,          
                       otr_opb_stall_mem_credits = 37,          /* The OTR/OPB engine has stalled due to not having credits available for requests to memory. */
                    otr_opb_stall_mem_rsp_events = 38,          /* The OTR/OPB engine is waiting on memory responses and has no other work to do. */
                    otr_opb_stall_mem_rsp_cycles = 39,          /* The OTR/OPB engine is waiting on memory responses and has no other work to do. */
                        otr_opb_stall_at_credits = 40,          /* The OTR/OPB engine has stalled due to a lack of available AT credits */
                     otr_opb_stall_at_rsp_events = 41,          /* The OTR/OPB engine is waiting on AT responses and had no other work to do. */
                     otr_opb_stall_at_rsp_cycles = 42,          /* The OTR/OPB engine is waiting on AT responses and had no other work to do. */
                      otr_p_to_m_stall_credits_x = 43,          /* The OPB to OMB queues are stalled waiting on credits. The TC for this counter is selected in the OTR block.Cross Reference to X: Section 32.7.8.5, 'Stall Packet Partition to Message Partition Credits X Performance CSR'Cross Reference to Y: Section 32.7.8.6, 'Stall Packet Partition to Message Partition Credits Y Performance CSR' */
                      otr_p_to_m_stall_credits_y = 44,          
                  otr_pktid_list_conflict_replay = 45,          /* A PKTID update conflict caused a Tx command to be replayed through the pipeline. */
                          otr_psn_distance_stall = 46,          /* The OTR is stalled to enforce PSN distance */
                                otr_fastpath_req = 47,          /* Number of requests generated into the fastpath in OTR. */
                                  otr_fragpe_req = 48,          /* Number of requests generated into the fragmentation path in OTR. */
                                  otr_txdma_cmds = 49,          /* The number of commands issued from OTR to TXDMA. This may be more than one command per packet. */
                            otr_packets_opened_x = 50,          /* Total number of packets generated by OTR. Total packets is the sum of the fastpath packets and the fragmentation PE packets. This reflects the number of OPB entries allocated. The TC/MC is selected in the OTR block.Cross Reference to X: */
                            otr_packets_closed_x = 51,          /* Total number of packets completed by OTR. Total packets is the sum of the fastpath packets and the fragmentation PE packets. This represents the number of OPB entries closed. The TC/MC is selected in the OTR block.Cross Reference to X: */
                             otr_packets_retrans = 52,          /* Total number of retransmitted packets. Included NACK-based retransmit, timeout-based retransmit, and retransmits internally scheduled due to max sequence distance violations. */
                                 otr_latency_0_a = 53,          /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was A or less.Note: granularity of the time is likely to be at least 1 millisecond.Cross Reference to A: Section 32.7.8.7, 'Latency Performance CSR' */
                                 otr_latency_a_b = 54,          /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than A and less than or equal to B.Cross Reference to B: Section 32.7.8.7, 'Latency Performance CSR' */
                                 otr_latency_b_c = 55,          /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than B and less than or equal to C.Cross Reference to C: Section 32.7.8.7, 'Latency Performance CSR' */
                                 otr_latency_c_d = 56,          /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than C and less than or equal to D.Cross Reference to D: Section 32.7.8.7, 'Latency Performance CSR' */
                               otr_latency_d_max = 57,          /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than D. */
                        otr_retrans_limit_rchd_x = 58,          /* Retransmit Limit reached. This counter increments only once after the retransmission limit is reached for that TC. The TC for this counter is selected in the OTR block.Cross Reference to X: xref */
                          otr_cleanup_cmd_detect = 59,          /* Increments the counter when an cleanup command is detected in the OTR */
                           otr_local_seq_stall_x = 60,          /* Indicates that a local sequence has stalled due to the maximum distance between the oldest outstanding local packet sequence number and the next available local packet sequence number exceeding half of the sequence number space. This counter increments once when this condition is detected. The MC/TC for this counter is selected in the OTR block.Cross Reference to X: xref */
                                      txpsn_hits = 61,          /* Number of hits in the TXPSN cache */
                                      txpsn_miss = 62,          /* Number of misses in the TXPSN cache */
                                txpsn_fill_stall = 63,          /* Number of stall cycles due to the fill FIFO in the TXPSN cache being full */
                               txpsn_evict_stall = 64,          /* Number of stall cycles due to the evict FIFO in the TXPSN cache being full */
                                    txpsn_evicts = 65,          /* Number of TXPSN cache evictions (capacity only, not CSR-based evictions) */
                              txpsn_membus_stall = 66,          /* Number of stall cycles due to the memory access port in the TXPSN cache being busy */
                              otr_pkt_reserved_a = 67,          /* Reserved */
                              otr_pkt_reserved_b = 68,          /* Reserved */
                              otr_pkt_reserved_c = 69,          /* Reserved */
                              otr_pkt_reserved_d = 70,          /* Reserved */
                                  txdma_tx_reads = 71,          /* Total read accesses done over the TX interface to memory. */
                         txdma_mc1_packet_match0 = 72,          /* A packet ,match triggered on MC1 */
                         txdma_mc1_packet_match1 = 73,          /* A packet match triggered on MC1 */
                           txdma_tx_flits_tcmc_w = 74,          /* Total flits transmitted by TXDMA on a TC/MC as selected in the TXDMA block.Cross Reference to W: xrefCross Reference to X: xrefCross Reference to Y: xrefCross Reference to Z: xref */
                           txdma_tx_flits_tcmc_x = 75,          
                           txdma_tx_flits_tcmc_y = 76,          
                           txdma_tx_flits_tcmc_z = 77,          
                         txdma_stall_mem_credits = 78,          /* The TX DMA engine has stalled due to not having outstanding credits to memory available for use. */
                      txdma_stall_mem_rsp_events = 79,          /* The TX DMA engine is waiting on memory responses and has no other work to do. */
                      txdma_stall_mem_rsp_cycles = 80,          /* The TX DMA engine is waiting on memory responses and has no other work to do. */
                          txdma_stall_at_credits = 81,          /* The TX DMA engine has stalled due to a lack of available AT credits */
                       txdma_stall_at_rsp_events = 82,          /* The TX DMA engine is waiting on AT responses and had no other work to do. */
                       txdma_stall_at_rsp_cycles = 83,          /* The TX DMA engine is waiting on AT responses and had no other work to do. */
                      txdma_stall_empty_events_x = 84,          /* Transmit DMA is stalled because there is nothing in the request pipeline. Event is counted once per event (i.e. input was not empty and then was empty). The TC/MC for this counter is selected in the TXDMA block.Cross Reference to X: xrefCross Reference to Y: xref */
                      txdma_stall_empty_events_y = 85,          
                           txdma_stall_credits_x = 86,          /* Transmit DMA is stalled because it has no credits for the Link Mux. The TC/MC for this counter is selected in the TXDMA block.Cross Reference to X: xrefCross Reference to Y: xref */
                           txdma_stall_credits_y = 87,          
                         txdma_mc0_packet_match0 = 88,          /* A generic packet header match triggered (matching logic TBD) */
                         txdma_mc0_packet_match1 = 89,          
                         txdma_mc0_packet_match2 = 90,          
                         txdma_mc0_packet_match3 = 91,          
                                txdma_reserved_a = 92,          /* Reserved */
                                txdma_reserved_b = 93,          /* Reserved */
                                txdma_reserved_c = 94,          /* Reserved */
                                txdma_reserved_d = 95,          /* Reserved */
                                lm_fecn_rcvd_pt0 = 96,          /* Count of the number of packets received on port 0 that are marked with FECN. */
                                lm_becn_rcvd_pt0 = 97,          /* Count of the number of packets received on port 0 that are marked with BECN. */
                                lm_pkts_sent_pt0 = 98,          /* Count of the number of packets sent on port 0 */
                                lm_pkts_rcvd_pt0 = 99,          /* Count of the number of packets received on port 0 */
                            lm_stall_rm_fifo_pt0 = 100,         /* Number of cycles stalled because the rate matching FIFO on Port 0 is full */
                                    lm_byp_pkt_x = 101,         /* MCTC counter increment signal for the bypass send to self packets Cross Reference to X: xrefCross Reference to Y: yrefCross Reference to z: zref */
                                    lm_byp_pkt_y = 102,         
                                    lm_byp_pkt_z = 103,         
                                  lm_byp_qflit_x = 104,         /* MCTC counter increment signal for the bypass send to self qflitsCross Reference to X: xrefCross Reference to Y: yrefCross Reference to z: zref */
                                  lm_byp_qflit_y = 105,         
                                  lm_byp_qflit_z = 106,         
                                   lm_byp_wait_x = 107,         /* MCTC counter increment signal for the bypass send to self, the MCTC data available but fifo is full.Cross Reference to X: xrefCross Reference to Y: yrefCross Reference to z: zref */
                                   lm_byp_wait_y = 108,         
                                   lm_byp_wait_z = 109,         
                               lm_xmit_multicast = 110,         /* Count the Multicast Packets being transmitted. */
                                   lm_reserved_a = 111,         /* Reserved */
                                   lm_reserved_b = 112,         /* Reserved */
                                   lm_reserved_c = 113,         /* Reserved */
                                   lm_reserved_d = 114,         /* Reserved */
                                   lm_reserved_e = 115,         /* Reserved */
                                   lm_reserved_f = 116,         /* Reserved */
                                   lm_reserved_g = 117,         /* Reserved */
                                   lm_reserved_h = 118,         /* Reserved */
                      rxci_stall_cq_empty_events = 119,         /* User receive command queues are stalled because all command queues are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
                              rxci_slots_written = 120,         /* Total Number of slots written into the Rx Command queue (either in full 64B writes or by partial writes). */
                         rxci_nonfull_slot_write = 121,         /* A slot in the RX Command queue was partially written (less than 64B written is a single transaction. */
                         rxci_stall_rxhp_credits = 122,         /* Receive command queues are stalled because no credits are available in the downstream interface (RXHP). Commands must be available for this event to be counted. */
                                       rxci_cmds = 123,         /* Number of commands processed by the RXCI interface */
                                 rxci_reserved_a = 124,         /* Reserved */
                                 rxci_reserved_b = 125,         /* Reserved */
                                 rxci_reserved_c = 126,         /* Reserved */
                                 rxci_reserved_d = 127,         /* Reserved */
                         rxe2e_no_big_scoreboard = 128,         /* Number of unordered packets wanting a big scoreboard, but unable to obtain one */
                         rxe2e_beyond_scoreboard = 129,         /* Number of unordered packets that arrived with a packet sequence number (PSN) that could not be scored in either a small scoreboard or a big scoreboard */
                             rxe2e_psn_dist_0_31 = 130,         /* Number of unordered packets that arrived with a PSN distance from expected psn of 0-31 */
                            rxe2e_psn_dist_32_63 = 131,         /* Number of unordered packets that arrived with a PSN distance from expected psn of 32-63. */
                           rxe2e_psn_dist_64_127 = 132,         /* Number of unordered packets that arrived with a PSN distance from expected psn of 64-127 */
                          rxe2e_psn_dist_128_255 = 133,         /* Number of unordered packets that arrived with a PSN distance from expected psn of 128-255 */
                          rxe2e_psn_dist_256_511 = 134,         /* Number of unordered packets that arrived with a PSN distance from expected psn of 256-511 */
                          rxe2e_psn_dist_512_767 = 135,         /* Number of unordered packets that arrived with a PSN distance from expected psn of 512-767 */
                         rxe2e_psn_dist_768_plus = 136,         /* Number of unordered packets that arrived with a PSN that exceeds the expected sequence number by 768 or more */
                         rxe2e_mc0_packet_match0 = 137,         /* A generic MC0 packet header match triggered (matching logic TBD) */
                         rxe2e_mc0_packet_match1 = 138,         /* A generic MC0 packet header match triggered (matching logic TBD) */
                         rxe2e_mc0_packet_match2 = 139,         /* A generic MC0 packet header match triggered (matching logic TBD) */
                         rxe2e_mc0_packet_match3 = 140,         /* A generic MC0 packet header match triggered (matching logic TBD) */
                         rxe2e_mc1_packet_match0 = 141,         /* A generic MC1 packet header match triggered (matching logic TBD) */
                         rxe2e_mc1_packet_match1 = 142,         /* A generic MC1 packet header match triggered (matching logic TBD) */
                                      rxpsn_hits = 143,         /* Number of hits in the RXPSN cache */
                                      rxpsn_miss = 144,         /* Number of misses in the RXPSN cache */
                                rxpsn_fill_stall = 145,         /* Number of stall cycles due to the fill FIFO in the RXPSN cache being full */
                               rxpsn_evict_stall = 146,         /* Number of stall cycles due to the evict FIFO in the RXPSN cache being full */
                                    rxpsn_evicts = 147,         /* Number of RXPSN cache evictions (capacity only, not CSR-based evictions) */
                              rxpsn_membus_stall = 148,         /* Number of stall cycles due to the memory access port in the RXPSN cache being busy */
                                rxe2e_reserved_a = 149,         /* Reserved */
                                rxe2e_reserved_b = 150,         /* Reserved */
                                rxe2e_reserved_c = 151,         /* Reserved */
                                rxe2e_reserved_d = 152,         /* Reserved */
                                rxe2e_reserved_e = 153,         /* Reserved */
                                rxe2e_reserved_f = 154,         /* Reserved */
                                rxe2e_reserved_g = 155,         /* Reserved */
                                rxe2e_reserved_h = 156,         /* Reserved */
                                rxe2e_reserved_i = 157,         /* Reserved */
                                rxe2e_reserved_j = 158,         /* Reserved */
                                rxe2e_reserved_k = 159,         /* Reserved */
                                   rxhp_fastpath = 160,         /* Number of requests entering the RXHP fastpath */
                                    rxhp_rpc0_t0 = 161,         /* Number of requests utilizing RPC0 thread 0 */
                                    rxhp_rpc0_t1 = 162,         /* Number of requests utilizing RPC0 thread 1 */
                                    rxhp_rpc0_t2 = 163,         /* Number of requests utilizing RPC0 thread 2 */
                                    rxhp_rpc0_t3 = 164,         /* Number of requests utilizing RPC0 thread 3 */
                                    rxhp_rpc1_t0 = 165,         /* Number of requests utilizing RPC1 thread 0 */
                                    rxhp_rpc1_t1 = 166,         /* Number of requests utilizing RPC1 thread 1 */
                                    rxhp_rpc1_t2 = 167,         /* Number of requests utilizing RPC1 thread 2 */
                                    rxhp_rpc1_t3 = 168,         /* Number of requests utilizing RPC1 thread 3 */
                                        rxhp_pe0 = 169,         /* Number of requests for the RXHP PE0 pipeline */
                                        rxhp_pe1 = 170,         /* Number of requests for the RXHP PE1 pipeline */
                                        rxhp_pe2 = 171,         /* Number of requests for the RXHP PE2 pipeline */
                                        rxhp_pe3 = 172,         /* Number of requests for the RXHP PE3 pipeline */
                                        rxhp_put = 173,         /* Number of Put operations handled by RXHP */
                                        rxhp_get = 174,         /* Number of Get operations handled by RXHP (fetchingoperations also increment the Get count) */
                                     rxhp_atomic = 175,         /* Number of Atomic operations handled by RXHP. Vector atomics increment this once permessage. */
                                        rxhp_vop = 176,         /* Number of Verbs over Portals operations handled by RXHP */
                                       rxhp_gen1 = 177,         /* Number of PSM/OFED operations handled by RXHP */
                                         rxhp_to = 178,         /* Number of triggered operations handled by the RXHP */
                                        rxhp_rts = 179,         /* Number of Request-to-send operations handled by the RXHP */
                      rxhp_stall_rxdma_credits_x = 180,         /* Header processing stalls due to insufficient credits toissue RXDMA commands. The TC is selected in RXHP.Cross Reference to X: xref */
                      rxhp_stall_rxdma_credits_y = 181,         /* Cross Reference to Y: xref */
                             rxhp_et_resrv_stall = 182,         /* Number of cycles an input into RXHP arbiter was stalled due to an ET reservation stall condition */
                         rxhp_pid_conflict_stall = 183,         /* Header processing pipeline is stalled due to PID conflicts.This event only counts if the next packet is able to issuebased on RXDMA credits. */
                              rxhp_pe_busy_stall = 184,         /* Header processing pipeline is stalled due to all PEs beingbusy. This event only counts if the next packet is able toissue (no RXDMA credit stalls, no PID conflicts) */
                       rxhp_pkt_status_rpc_stall = 185,         /* RPC pipeline is stalled due a lack of status good from RXE2E */
                        rxhp_pkt_status_fp_stall = 186,         /* FP pipeline is stalled due a lack of status good from RXE2E */
                             rxhp_rpc_busy_stall = 187,         /* RPC pipeline is stalled due to all RPCs beingbusy. This event only counts if the next packet is able toissue (no RXDMA credit stalls, no PID conflicts) */
                              rxhp_psc_req_stall = 188,         /* More than one request is arbitrating for PSC pipeline.This event counts how many total cycles the conflictingrequests are delayed. */
                              rxhp_psc_rsp_stall = 189,         /* More than one response is arbitrating from the PSC pipeline.This event counts how many total cycles the conflictingrequests are delayed. */
                                  pte_cache_hits = 190,         /* Number of hits in the PTE cache */
                                  pte_cache_miss = 191,         /* Number of misses in the PTE cache */
                            pte_cache_fill_stall = 192,         /* Number of stall cycles due to the fill FIFO in the PortalTable Entry (PTE) cache being full */
                           pte_cache_evict_stall = 193,         /* Number of stall cycles due to the evict FIFO in the PortalTable Entry (PTE) cache being full */
                                pte_cache_evicts = 194,         /* Number of Portal Table Entry (PTE) cache evictions(capacity only, not CSR-based evictions) */
                          pte_cache_membus_stall = 195,         /* Number of stall cycles due to the memory access port inthe Portal Table Entry (PTE) cache being busy */
                                  psc_cache_hits = 196,         /* Number of hits in the Portals State Cache (PSC) per bank path (prim and sec) */
                                  psc_cache_miss = 197,         /* Number of misses in the Portals State Cache (PSC) per bank path (prim and sec) */
                            psc_cache_fill_stall = 198,         /* Number of stall cycles due to the fill FIFO in the PortalsState Cache (PSC) being full */
                           psc_cache_evict_stall = 199,         /* Number of stall cycles due to the evict FIFO in the PortalsState Cache (PSC) being full */
                                psc_cache_evicts = 200,         /* Number of Portals State Cache (PSC) evictions(capacity only, not CSR-based evictions) */
                          psc_cache_membus_stall = 201,         /* Number of stall cycles due to the memory access port inthe Portals State Cache (PSC) being busy */
                           psc_cache_cmd_port0_x = 202,         /* Count of PSC cache commands by command type X on port 0.  Cross Reference to X: xref */
                           psc_cache_cmd_port1_x = 203,         /* Count of PSC cache commands by command type X on port 1. Cross Reference to X: xref */
                           psc_cache_cmd_bank0_x = 204,         /* Count of PSC cache commands by command type X on bank 0. Cross Reference to X: xref */
                           psc_cache_cmd_bank1_x = 205,         /* Count of PSC cache commands by command type X on bank 1. Cross Reference to X: xref */
                       rxhp_digest_matches_port0 = 206,         /* Number of times the digest filter was not sufficient (hence it matches) to allow the walker to skip reading the full entry on port 0 */
                       rxhp_digest_matches_port1 = 207,         /* Number of times the digest filter was not sufficient (hence it matches) to allow the walker to skip reading the full entry on port 1 */
                                rxhp_cmd_q_empty = 208,         /* Number of cycles the command queue into the RXHP arbiter is empty */
                              rxhp_req_q_empty_x = 209,         /* Number of cycles the X TC request queue into the RXHP arbiter is empty. Cross Reference to X: xref */
                              rxhp_mem_lat_count = 210,         /* Number of memory requests that we have tracked latency for.  (Divide RXHP_MEM_LAT_CYCLES by this counter to get average round trip memory latency for the caches). */
                             rxhp_mem_lat_cycles = 211,         /* Number of cycles all tracked memory requests from PSC or PTE spent outstanding */
                                 rxhp_reserved_a = 212,         /* Reserved */
                                 rxhp_reserved_b = 213,         /* Reserved */
                                 rxhp_reserved_c = 214,         /* Reserved */
                                 rxhp_reserved_d = 215,         /* Reserved */
                                 rxhp_reserved_e = 216,         /* Reserved */
                                 rxhp_reserved_f = 217,         /* Reserved */
                                 rxhp_reserved_g = 218,         /* Reserved */
                                 rxhp_reserved_h = 219,         /* Reserved */
                                 rxhp_reserved_i = 220,         /* Reserved */
                                 rxhp_reserved_j = 221,         /* Reserved */
                                 rxhp_reserved_k = 222,         /* Reserved */
                                 rxhp_reserved_l = 223,         /* Reserved */
                                 rxdma_rx_writes = 224,         /* Total write accesses done over the RX interface to HIARB. An atomic counts as a write. A fetching atomic counts as a write and a read. This includes event writes. */
                                  rxdma_rx_reads = 225,         /* Total read accesses done over the RX interface to HIARB. A fetching atomic counts as a write and a read. */
                           rxdma_rx_flits_tcmc_x = 226,         /* Total flits received by RXDMA on a TC/MC as selected in the RXDMA block.Appendix , 'rx_flits_mctc_x'Appendix , 'rx_flits_mctc_y' */
                           rxdma_rx_flits_tcmc_y = 227,         
                  rxdma_stall_mem_credits_cycles = 228,         /* The RX DMA engine has stalled due to not having available outstanding credits to memory. Total stalled cycles are counted. */
                      rxdma_stall_mem_rsp_events = 229,         /* The RX DMA engine is waiting on memory responses and has no other work to do. Stalls are counted once per event. */
                      rxdma_stall_mem_rsp_cycles = 230,         /* The RX DMA engine is waiting on memory responses and has no other work to do. Total stalled cycles are counted. */
                      rxdma_stall_empty_events_x = 231,         /* Receive DMA is stalled because there is nothing in the request pipeline. Event is counted once per event (i.e. input was not empty and then was empty). The TC/MC for this counter is selected in the RXDMA block.Appendix , 'no_cmd_mctc_x'Appendix , 'no_cmd_mctc_y' */
                      rxdma_stall_empty_events_y = 232,         
                           rxdma_stall_credits_x = 233,         /* Receive DMA is stalled because it has no credits for the HI ARB. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'no_credits_mctc_x'Appendix , 'no_credits_mctc_y' */
                           rxdma_stall_credits_y = 234,         
                            rxdma_stall_no_cmd_x = 235,         /* Receive DMA is stalled because it has data, but does not have a command. The MC/TC is selected by a CSR in the RXDMA block.Appendix , 'no_cmd_mctc_x'Appendix , 'no_cmd_mctc_y' */
                            rxdma_stall_no_cmd_y = 236,         
                      rxdma_stall_no_txci_cred_x = 237,         /* Receive DMA is stalled because it does not have credits to the TX command interface to generate the ACK/Reply to the TxCI. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'tx_ci_mctc_x'Appendix , 'tx_ci_mctc_y' */
                      rxdma_stall_no_txci_cred_y = 238,         
                     rxdma_stall_no_txdma_cred_x = 239,         /* Receive DMA is stalled because it does not have credits to the TX command interface to generate the ACK/Reply to the TxDMA. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'tx_dma_mctc_x'Appendix , 'tx_dma_mctc_y' */
                     rxdma_stall_no_txdma_cred_y = 240,         
                           rxdma_stall_to_cred_x = 241,         /* Receive DMA is stalled because it does not have credits to the Triggered Op Request logic to request TOs for processing. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'to_mctc_x'Appendix , 'to_mctc_y' */
                           rxdma_stall_to_cred_y = 242,         
                          rxdma_stall_tid_full_x = 243,         /* RXDMA TID buffer is full and stalling future gets. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'tid_mctc_x'Appendix , 'tid_mctc_y' */
                          rxdma_stall_tid_full_y = 244,         
                          rxdma_stall_ack_full_x = 245,         /* RXDMA Acknowledgment buffers is full and stalling future gets. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'ack_mctc_x'Appendix , 'ack_mctc_y' */
                          rxdma_stall_ack_full_y = 246,         
                          rxdma_stall_war_full_x = 247,         /* RXDMA WAR buffer is full and stalling future gets. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'war_mctc_x'Appendix , 'war_mctc_y' */
                          rxdma_stall_war_full_y = 248,         
                           rxdma_trig_op_issue_x = 249,         /* RXDMA successfully issued a Triggered Op to the TxCI. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'to_issue_mctc_x'Appendix , 'to_issue_mctc_y' */
                           rxdma_trig_op_issue_y = 250,         
                           rxdma_trig_op_queue_x = 251,         /* RXDMA sent a Cache Line of Triggered Op Pointers to user memory. A Cache Line contains 16 pointers. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'to_queue_mctc_x'Appendix , 'to_queue_mctc_y' */
                           rxdma_trig_op_queue_y = 252,         
                            rxdma_trig_op_append = 253,         /* A Triggered Op Append command completed with the CT Update in the RxDMA. */
                                rxdma_reserved_a = 254,         /* Reserved */
                                rxdma_reserved_b = 255,         /* Reserved */
                                   ct_cache_hits = 256,         /* Number of hits in the CT cache */
                                   ct_cache_miss = 257,         /* Number of misses in the CT cache */
                           ct_cache_writethrough = 258,         /* Number of write-through writes from CT cache */
                             ct_cache_fill_stall = 259,         /* Number of stall cycles due to the fill FIFO in the CT cache being full */
                            ct_cache_evict_stall = 260,         /* Number of stall cycles due to the evict FIFO in the CT cache being full */
                                 ct_cache_evicts = 261,         /* Number of CT cache evictions (capacity only, not CSR-based evictions) */
                           ct_cache_membus_stall = 262,         /* Number of stall cycles due to the memory access port in the CT cache being busy */
                                  eqd_cache_hits = 263,         /* Number of hits in the EQ descriptor cache */
                                  eqd_cache_miss = 264,         /* Number of misses in the EQ descriptor cache */
                            eqd_cache_fill_stall = 265,         /* Number of stall cycles due to the fill FIFO in the EQ descriptor cache being full */
                           eqd_cache_evict_stall = 266,         /* Number of stall cycles due to the evict FIFO in the EQ descriptor cache being full */
                                eqd_cache_evicts = 267,         /* Number of EQ descriptor cache evictions (capacity only, not CSR-based evictions) */
                          eqd_cache_membus_stall = 268,         /* Number of stall cycles due to the memory access port in the EQ descriptor cache being busy */
                              trig_op_cache_hits = 269,         /* Number of hits in the Triggered Operation cache */
                              trig_op_cache_miss = 270,         /* Number of misses in the Triggered Operation cache */
                        trig_op_cache_fill_stall = 271,         /* Number of stall cycles due to the fill FIFO in the Triggered Operation cache being full */
                       trig_op_cache_evict_stall = 272,         /* Number of stall cycles due to the evict FIFO in the Triggered Operation cache being full */
                            trig_op_cache_evicts = 273,         /* Number of Triggered Operation cache evictions (capacity only, not CSR-based evictions) */
                      trig_op_cache_membus_stall = 274,         /* Number of stall cycles due to the memory access port in the Triggered Operation cache being busy */
                                 rxet_reserved_a = 275,         /* Reserved */
                                 rxet_reserved_b = 276,         /* Reserved */
                                 rxet_reserved_c = 277,         /* Reserved */
                                 rxet_reserved_d = 278,         /* Reserved */
                                 rxet_reserved_e = 279,         /* Reserved */
                                 rxet_reserved_f = 280,         /* Reserved */
                                 rxet_reserved_g = 281,         /* Reserved */
                                 rxet_reserved_h = 282,         /* Reserved */
                                 rxet_reserved_i = 283,         /* Reserved */
                                 rxet_reserved_j = 284,         /* Reserved */
                                 rxet_reserved_k = 285,         /* Reserved */
                                 rxet_reserved_l = 286,         /* Reserved */
                                 rxet_reserved_m = 287,         /* Reserved */
                                 at_tlb_accesses = 288,         /* Number of total translation requests */
                                     at_tlb_miss = 289,         /* Number of Misses in the TLB cache */
                                      at_tlb_hit = 290,         /* Number of Hits in the TLB cache */
                                   at_tlb_evicts = 291,         /* Number of TLB cache evictions */
                                  at_tlb_hits_4k = 292,         /* Number of hits in the TLB cache for 4K page entries */
                                  at_tlb_hits_2m = 293,         /* Number of hits in the TLB cache for 2M page entries */
                                  at_tlb_hits_1g = 294,         /* Number of hits in the TLB cache for 1G page entries */
                                at_tlb_evicts_4k = 295,         /* Number of TLB cache evictions for 4K page entries */
                                at_tlb_evicts_2m = 296,         /* Number of TLB cache evictions for 2M page entries */
                                at_tlb_evicts_1g = 297,         /* Number of TLB cache evictions for 1G page entries */
                                at_tlb_req_stall = 298,         /* Number of stalls due to the request FIFO to the IOMMU being full */
                               at_tlb_shootdowns = 299,         /* Number of shutdowns received from software */
                                   at_reserved_a = 300,         /* Reserved */
                                   at_reserved_b = 301,         /* Reserved */
                              rxhiarb_rxdma_reqs = 320,         /* Total requests received by HIARB from RXDMA port-head pointer updates: count here or in RXCID? */
                              rxhiarb_rxcid_reqs = 321,         /* Total requests received by HIARB from RXCID port-head pointer updates: count here or in RXCID? */
                               rxhiarb_rxhp_reqs = 322,         /* Total requests received by HIARB from RXHP port-count here or in RXHP? */
                               rxhiarb_rxet_reqs = 323,         /* Total requests received by HIARB from RXET port-counted by EQD cache + trig op cache? */
                              rxhiarb_rxe2e_reqs = 324,         /* Total requests received by HIARB from RXE2E port */
                                rxhiarb_hi_flits = 325,         /* Total number of request flits sent from HIARB to HI */
                         rxhiarb_hi_stall_cycles = 326,         /* Total clock cycles when the HIARB has an available request to send but is back-pressured by the HI */
                         rxhiarb_hi_stall_events = 327,         /* Number of times a stall occurs due to HI backpressure (counts once per stall interval) */
                                rxhiarb_at_flush = 328,         /* Number of AT flushes */
                         rxhiarb_at_flush_stalls = 329,         /* Total clock cycles during the period after an AT flush occurs and before the HIARB can send the next newly address translated request to the HI. This is intended to represent the total interruption in traffic flow due to AT flushes. */
                     rxhiarb_stall_at_req_events = 330,         /* The RX HIARB engine has stalled due to a lack of available AT credits */
                     rxhiarb_stall_at_req_cycles = 331,         /* The RX HIARB engine has stalled due to a lack of available AT credits */
                     rxhiarb_stall_at_rsp_events = 332,         /* The RX HIARB engine is waiting on AT responses and had no other work to do. */
                     rxhiarb_stall_at_rsp_cycles = 333,         /* The RX HIARB engine is waiting on AT responses and had no other work to do. */
                                rxhiarb_tlb_hits = 334,         /* Total number of requests that hit in the mini-TLB cache (regardless of presence state), This can be used in conjunction with RXHIARB_REQS to determine raw mini-TLB hit/miss rates. */
                        rxhiarb_tlb_present_hits = 335,         /* Total number of requests that hit in the mini-TLB cache 'and' the physical address is available in the cache. This can be used in conjunction with RXHIARB_REQS to determine hit/miss rates to cache entries with a physical address present. */
                        rxhiarb_slow_resp_stalls = 336,         /* Count of number of stalls caused by using the low bandwidth paths back to RXHP and RXET. */
                          rxhiarb_resp_cnt_rxdma = 337,         /* Count number of responses from HI to RXDMA */
                           rxhiarb_resp_cnt_rxhp = 338,         /* Count number of responses from HI to RXHP */
                           rxhiarb_resp_cnt_rxet = 339,         /* Count number of responses from HI to RXET */
                          rxhiarb_resp_cnt_rxe2e = 340,         /* Count number of responses from HI to RXE2E */
                             rxhiarb_pcb_lookups = 341,         /* Total number of handle-based requests performing lookups to the PCB table. */
                         rxhiarb_stall_hq_events = 342,         /* The RX HIARB input queues are stalled waiting on holding queue entries to become free. */
                         rxhiarb_stall_hq_cycles = 343,         /* The RX HIARB input queues are stalled waiting on holding queue entries to become free. */
                            rxhiarb_at_match_cnt = 344,         /* Total number of 'matching' requests seeking a translated physical address from the AT. This will only monitor requests which miss in the mini-TLB. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section.-is this the matching latency measurement thing? */
                            rxhiarb_at_match_dly = 345,         /* Total number of clock cycles for 'matching' requests to obtain a translated physical address from the AT. This will only monitor requests which miss in the mini-TLB. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section. */
                           rxhiarb_mrd_match_cnt = 346,         /* Total number of 'matching' read requests. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section-is this the matching latency measurement thing? */
                           rxhiarb_mrd_match_dly = 347,         /* Total number of clock cycles for 'matching' read requests to have their response payload returned. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section. */
                              rxhiarb_reserved_a = 348,         /* Reserved */
                              rxhiarb_reserved_b = 349,         /* Reserved */
                              rxhiarb_reserved_c = 350,         /* Reserved */
                              rxhiarb_reserved_d = 351,         /* Reserved */
                                pcim_hpi_req_cnt = 352,         
                            pcim_p2sb_np_req_cnt = 353,         
                            pcim_p2sb_pc_req_cnt = 354,         
                              pcim_iommu_req_cnt = 355,         
                                 pcim_ur_req_cnt = 356,         
                           pcim_hpi_splt_req_cnt = 357,         
                          pcim_p2sb_splt_req_cnt = 358,         
                                 pcim_hpi_fc_cnt = 359,         
                                pcim_p2sb_fc_cnt = 360,         
                              pcim_marb_p_fc_cnt = 361,         
                             pcim_marb_np_fc_cnt = 362,         
                            pcim_marb_cpl_fc_cnt = 363,         
                             pcim_marb_p_req_cnt = 364,         
                            pcim_marb_np_req_cnt = 365,         
                           pcim_marb_cpl_req_cnt = 366,         
                            pcim_io2p_np_req_cnt = 367,         
                             pcim_sb2p_p_req_cnt = 368,         
                            pcim_sb2p_np_req_cnt = 369,         
                           pcim_sb2p_cpl_req_cnt = 370,         
                             pcim_init_p_req_cnt = 371,         
                            pcim_hpi_cpl_req_cnt = 372,         
                                 pcim_reserved_a = 373,         /* Reserved */
                                 pcim_reserved_b = 374,         /* Reserved */
                                 pcim_reserved_c = 375,         /* Reserved */
                                 pcim_reserved_d = 376,         /* Reserved */
                                 pcim_reserved_e = 377,         /* Reserved */
                                 pcim_reserved_f = 378,         /* Reserved */
                                 pcim_reserved_g = 379,         /* Reserved */
                                 pcim_reserved_h = 380,         /* Reserved */
                                 pcim_reserved_i = 381,         /* Reserved */
                                 pcim_reserved_j = 382,         /* Reserved */
                                 pcim_reserved_k = 383,         /* Reserved */
                          hi_loca_hcc_new_tx_req = 384,         /* New Tx sourced request count. Enabled by tx_cnt_ena. */
                          hi_loca_hcc_new_rx_req = 385,         /* New Rx sourced request count. Enabled by rx_cnt_ena. */
                          hi_loca_hcc_new_at_req = 386,         /* New AT sourced request count. Enabled by at_cnt_ena. */
                         hi_loca_hcc_new_get_req = 387,         /* New GET request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                         hi_loca_hcc_new_put_req = 388,         /* New PUT request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                      hi_loca_hcc_new_atomic_req = 389,         /* New ATOMIC request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                     hi_loca_hcc_new_fatomic_req = 390,         /* New FATOMIC request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                         hi_loca_hcc_new_zbr_req = 391,         /* New ZBR request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                         hi_loca_hcc_new_irq_req = 392,         /* New IRQ request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                         hi_loca_hcc_new_nop_req = 393,         /* New NOP request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                         hi_loca_hcc_new_fid_req = 394,         /* New FID request count. The GID/FID counted is selectedby the fid_cnt_id and fid_cnt_msk fields. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                        hi_loca_hcc_new_conq_req = 395,         /* Total number of New requests pushed to CONQ */
                    hi_loca_parb_addr_replay_req = 396,         /* Address enabled Replay request count. */
                   hi_loca_parb_order_replay_req = 397,         /* Order enabled Replay request count. */
                        hi_loca_hcc_replay_abort = 398,         /* Total number of aborted replay requests */
                           hi_loca_parb_fill_req = 399,         /* Fill request count. */
                      hi_loca_hcc_fill_chain_req = 400,         /* Fill Pass request that temporally allocates a line in the cache for subsequent chaining with delayed requests */
                              hi_loca_hcc_0b_req = 401,         /* New 0 Byte request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                              hi_loca_hcc_sm_req = 402,         /* New (Small) request count with blen between 1-63 Bytes. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                             hi_loca_hcc_64b_req = 403,         /* New 64 Byte request count with blen equal 64B. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                            hi_loca_hcc_128b_req = 404,         /* New request count with blen between 65-128 Bytes. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                            hi_loca_hcc_256b_req = 405,         /* New request count with blen between 129-256 Bytes. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                             hi_loca_addr_range0 = 406,         /* Request match for ADDR Range 0. Enabled by upper_addr_range and lower_addr_range. */
                             hi_loca_addr_range1 = 407,         /* Request match for ADDR Range 1. Enabled by upper_addr_range and lower_addr_range. */
                             hi_loca_addr_range2 = 408,         /* Request match for ADDR Range 2. Enabled by upper_addr_range and lower_addr_range. */
                             hi_loca_addr_range3 = 409,         /* Request match for ADDR Range 3. Enabled by upper_addr_range and lower_addr_range. */
                            hi_loca_parb_proq_fc = 410,         /* Clock cycle count of PROQ flow control signaling due tolack of PROQ entries. */
                            hi_loca_parb_conq_fc = 411,         /* Clock cycle count of ConQ flow control signaling due tolack of ConQ entries. */
                             hi_loca_parb_new_fc = 412,         /* Clock cycle count of New/Replay Request flow controlsignaling due to lack of TIDs. */
                           hi_loca_parb_hifis_fc = 413,         /* Clock cycle count of HIFIS flow control signaling. */
                  hi_loca_parb_new_timeout_stall = 414,         /* New request timeout cycles stalled by a New hazard. */
                        hi_loca_parb_new_timeout = 415,         /* New request timeout cycles at PARB head. */
               hi_loca_parb_replay_timeout_stall = 416,         /* Replay request timeout cycles stalled by a Replay hazard. */
                     hi_loca_parb_replay_timeout = 417,         /* Replay request timeout cycles at PARB head. */
                 hi_loca_parb_fill_timeout_stall = 418,         /* Fill request timeout cycles stalled by a New hazard. */
                       hi_loca_parb_fill_timeout = 419,         /* Fill request timeout cycles at PARB head. */
                 hi_loca_parb_emec_timeout_stall = 420,         /* EMEC request timeout cycles stalled by a EMEC hazard. */
                       hi_loca_parb_emec_timeout = 421,         /* EMEC request timeout cycles at PARB head. */
                       hi_loca_parb_new_fc_stall = 422,         /* New request cycles stalled by flow control. */
                       hi_loca_parb_new_ic_stall = 423,         /* New request cycles stalled by PMI CAM hazard. */
                       hi_loca_parb_new_pc_stall = 424,         /* New request cycles stalled by Pipe CAM hazard. */
                        hi_loca_parb_new_req_cyc = 425,         /* New request cycles count at PARB head. */
                    hi_loca_parb_replay_fc_stall = 426,         /* Replay request cycles stalled by flow control. */
                    hi_loca_parb_replay_ic_stall = 427,         /* Replay request cycles stalled by IMI CAM hazard. */
                    hi_loca_parb_replay_pc_stall = 428,         /* Replay request cycles stalled by Pipe CAM hazard. */
                     hi_loca_parb_replay_req_cyc = 429,         /* Replay request cycles count at PARB head. */
                      hi_loca_parb_fill_fc_stall = 430,         /* Fill request cycles stalled by flow control. */
                      hi_loca_parb_fill_ic_stall = 431,         /* Fill request cycles stalled by IMI CAM hazard. */
                      hi_loca_parb_fill_pc_stall = 432,         /* Fill request cycles stalled by Pipe CAM hazard. */
                       hi_loca_parb_fill_req_cyc = 433,         /* Fill request cycles count at PARB head. */
                      hi_loca_parb_emec_fc_stall = 434,         /* EMEC request cycles stalled by flow control. */
                      hi_loca_parb_emec_ic_stall = 435,         /* EMEC request cycles stalled by IMI CAM hazard. */
                      hi_loca_parb_emec_pc_stall = 436,         /* EMEC request cycles stalled by Pipe CAM hazard. */
                       hi_loca_parb_emec_req_cyc = 437,         /* EMEC request cycles count at PARB head. */
                           hi_loca_dcache_pmi_fc = 438,         /* LOCA Pipeline stall due to PMI back-pressure */
                            hi_loca_dcache_go_fc = 439,         /* LOCA Pipeline stall due to GO block back-pressure */
                           hi_loca_dcache_raw_fc = 440,         /* LOCA Pipeline stall due to Read-After-Write hazard */
                           hi_loca_dcache_ava_fc = 441,         /* LOCA Pipeline stall due to multi-cycle execution of a Vector Atomic request. */
                           hi_loca_dcache_alr_fc = 442,         /* LOCA Pipeline stall due to multi-cycle execution of a Large (>64B) GET or PUT request. */
                           hi_loca_pmi_req_stall = 443,         /* Valid PMI request stalled on Client IF to PCIC */
                       hi_loca_hcc_alloc_get_req = 444,         /* Allocating GET request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                       hi_loca_hcc_alloc_get_hit = 445,         /* Allocating GET request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                       hi_loca_hcc_alloc_put_req = 446,         /* Allocating PUT request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                       hi_loca_hcc_alloc_put_hit = 447,         /* Allocating PUT request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                    hi_loca_hcc_alloc_atomic_req = 448,         /* Allocating Atomic (fetching or not) request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                    hi_loca_hcc_alloc_atomic_hit = 449,         /* Allocating Atomic (fetching/not) request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                    hi_loca_hcc_nonalloc_get_req = 450,         /* Non-Allocating GET request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                    hi_loca_hcc_nonalloc_get_hit = 451,         /* Non-Allocating GET request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                    hi_loca_hcc_nonalloc_put_req = 452,         /* Non-Allocating PUT request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                    hi_loca_hcc_nonalloc_put_hit = 453,         /* Non-Allocating PUT request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                 hi_loca_hcc_nonalloc_atomic_req = 454,         /* Non-Allocating Atomic (fetching or not) request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                 hi_loca_hcc_nonalloc_atomic_hit = 455,         /* Non-Allocating Atomic (fetching/not) request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
                        hi_loca_hcc_alloc_dc_hit = 456,         /* Allocating Request Hit Count. All allocating requests */
                        hi_loca_hcc_alloc_dc_req = 457,         /* Allocating Request Count. */
                          hi_loca_hcc_all_dc_hit = 458,         /* All Request Hit Count. All requests (alloc or not) */
                          hi_loca_hcc_all_dc_req = 459,         /* All Request Count. */
                          hi_loca_hcc_fid_dc_hit = 460,         /* Flow ID based Request Hit Count. Enabled by fid_cnt_id/fid_cnt_msk */
                          hi_loca_hcc_fid_dc_req = 461,         /* Flow ID based Request Count. Enabled byfid_cnt_id/fid_cnt_msk */
                    hi_loca_hcc_replay_chain_hit = 462,         /* Replay request that hits a chained cache line. Compare with HI_LOCA_HCC_FILL_CHAIN_REQ for Chain hit opportunities. */
                            hi_loca_pmi_read_req = 463,         /* Sampled PCIe Read requests count. */
                        hi_loca_pmi_read_latency = 464,         /* Sampled PCIe Read requests latency. Divide by HI_LOCA_PMI_READ_REQ to get average data response latency (in cclks). */
                         hi_loca_pmi_rxwrite_req = 465,         /* Sampled PCIe RX Write requests count. */
                        hi_loca_pmi_rxgo_latency = 466,         /* Sampled PCIe RX Write request latency to GO response. Divide by HI_LOCA_PMI_RXWRITE_REQ to get average GO latency (in cclks). */
                             hi_loca_dcache_read = 467,         /* DCache read cycles */
                            hi_loca_dcache_write = 468,         /* DCache Write cycles */
                            hi_loca_reserved_1d5 = 469,         
                            hi_loca_reserved_1d6 = 470,         
                            hi_loca_reserved_1d7 = 471,         
                            hi_loca_reserved_1d8 = 472,         
                            hi_loca_reserved_1d9 = 473,         
                            hi_loca_reserved_1da = 474,         
                            hi_loca_reserved_1db = 475,         
                            hi_loca_reserved_1dc = 476,         
                            hi_loca_reserved_1dd = 477,         
                            hi_loca_reserved_1de = 478,         
                            hi_loca_reserved_1df = 479,         
                            hi_loca_reserved_1e0 = 480,         
                            hi_loca_reserved_1e1 = 481,         
                            hi_loca_reserved_1e2 = 482,         
                            hi_loca_reserved_1e3 = 483,         
                            hi_loca_reserved_1e4 = 484,         
                            hi_loca_reserved_1e5 = 485,         
                            hi_loca_reserved_1e6 = 486,         
                            hi_loca_reserved_1e7 = 487,         
                            hi_loca_reserved_1e8 = 488,         
                            hi_loca_reserved_1e9 = 489,         
                            hi_loca_reserved_1ea = 490,         
                            hi_loca_reserved_1eb = 491,         
                            hi_loca_reserved_1ec = 492,         
                            hi_loca_reserved_1ed = 493,         
                            hi_loca_reserved_1ee = 494,         
                            hi_loca_reserved_1ef = 495,         
                            hi_loca_reserved_1f0 = 496,         
                            hi_loca_reserved_1f1 = 497,         
                            hi_loca_reserved_1f2 = 498,         
                            hi_loca_reserved_1f3 = 499,         
                            hi_loca_reserved_1f4 = 500,         
                            hi_loca_reserved_1f5 = 501,         
                            hi_loca_reserved_1f6 = 502,         
                            hi_loca_reserved_1f7 = 503,         
                            hi_loca_reserved_1f8 = 504,         
                            hi_loca_reserved_1f9 = 505,         
                            hi_loca_reserved_1fa = 506,         
                            hi_loca_reserved_1fb = 507,         
                            hi_loca_reserved_1fc = 508,         
                            hi_loca_reserved_1fd = 509,         
                            hi_loca_reserved_1fe = 510,         
                            hi_loca_reserved_1ff = 511          
};

#else

#define              txci_stall_hcq_empty_events   0            /* Host transmit command queues are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
#define              txci_stall_rcq_empty_events   1            /* RX to TX command queues are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
#define               txci_stall_cq_empty_events   2            /* All command queues in TxCI are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
#define                            txci_cmds_mc0   3            /* Total Commands Issued on MC0 */
#define                            txci_cmds_mc1   4            /* Total Commands Issued on MC1 */
#define               txci_rcq_mc0_slots_written   5            /* Total Number of slots written by Rx on MC0 */
#define               txci_rcq_mc1_slots_written   6            /* Total Number of slots written by Rx on MC1 */
#define                   txci_hcq_slots_written   7            /* Total Number of slots written into the Tx Command queue (either in full 64B writes or by partial writes). */
#define              txci_hcq_nonfull_slot_write   8            /* A slot in the TX Command queue was partially written (less than 64B written is a single transaction, regardless of whether it fills a slot or not). */
#define                 txci_stall_otr_credits_w   9            /* Transmit command queues are stalled because no credits are available in the downstream interface (OTR) for the MC/TC. Commands must be available for this event to be counted. The TC/MC for this counter is selected in the TXCI block by a CSR.Cross Reference to W: xrefCross Reference to X: xrefCross Reference to Y: xrefCross Reference to Z: xref */
#define                 txci_stall_otr_credits_x   10           
#define                 txci_stall_otr_credits_y   11           
#define                 txci_stall_otr_credits_z   12           
#define                          txci_reserved_a   13           /* Reserved */
#define                          txci_reserved_b   14           /* Reserved */
#define                  otr_stall_omb_entries_x   15           /* The OTR is stalled waiting for OMB entries. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.1, 'Stall OMB Entries X Performance CSR'Cross Reference to Y: Section 32.8.8.2, 'Stall OMB Entries Y Performance CSR' */
#define                  otr_stall_omb_entries_y   16           
#define                otr_stall_rxdma_credits_x   17           /* The OTR is stalled waiting for credits to the RXDMA block. The TC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.3, 'Stall RXDMA Credits X Performance CSR'Cross Reference to Y: Section 32.8.8.4, 'Stall RXDMA Credits Y Performance CSR' */
#define                otr_stall_rxdma_credits_y   18           
#define                            otr_stall_cts   19           /* The CTS queue within OTR has stalled for lack of credits. */
#define               otr_m_to_p_stall_credits_x   20           /* The OMB to OPB queues are stalled waiting on credits. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.5, 'Stall Message Partition to Packet Partition Credits X Performance CSR'Cross Reference to Y: Section 32.8.8.6, 'Stall Message Partition to Packet Partition Credits Y Performance CSR' */
#define               otr_m_to_p_stall_credits_y   21           
#define              otr_prefrag_stall_credits_x   22           /* The pre-fragmentation queue is stalled waiting for access to the fragmentation PE. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.8.8.7, 'Stall Pre-Fragmentation Credits X Performance CSR'Cross Reference to Y: Section 32.8.8.8, 'Stall Pre-Fragmentation Credits Y Performance CSR' */
#define              otr_prefrag_stall_credits_y   23           
#define                   otr_cmd_ordering_stall   24           /* The OTR is stalled to enforce command ordering */
#define                    otr_messages_opened_x   25           /* Total number of messages generated by OTR (sum of both fastpath and fragmentation messages). This reflects the number of OMB entries allocated. The TC/MC is selected in the OTR block.Cross Reference to X: */
#define                    otr_messages_closed_x   26           /* Total number of messages completed by OTR. This reflects the number of OMB entries closed. The TC/MC is selected in the OTR block.Cross Reference to X: */
#define           otr_cmd_portals_ordering_stall   27           /* The OTR is stalled to enforce Portals command ordering (8.3.4.1) */
#define            otr_cmd_compat_ordering_stall   28           /* The OTR is stalled to enforce compatibility (KDETH/Verbs) command ordering (8.3.4.2) */
#define            otr_cmd_fragpe_ordering_stall   29           /* The OTR is stalled to enforce programmable engine ordering command ordering (8.3.4.3) */
#define                 otr_omb_collision_replay   30           /* The OTR pipeline was flushed due to an OMB collision. (Bongjin suggested this fix for a bug, I want it counted to assess how often it happens) */
#define                       otr_msg_reserved_a   31           /* Reserved */
#define                     otr_rsp_special_acks   32           /* This counter counts the special ACKs received by the OTR on any TC */
#define                  otr_stall_opb_entries_x   33           /* The OTR is stalled waiting for OPB entries. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 29.7.3.152, 'Stall OPB Entries X Performance CSR'Cross Reference to Y: Section 32.7.8.2, 'Stall OMB Entries Y Performance CSR' */
#define                  otr_stall_opb_entries_y   34           
#define                otr_stall_txdma_credits_x   35           /* The OTR is stalled waiting for credits to the TXDMA block. The TC/MC for this counter is selected in the OTR block.Cross Reference to X: Section 32.7.8.3, 'Stall TXDMA Credits X Performance CSR'Cross Reference to Y: Section 32.7.8.4, 'Stall TXDMA Credits Y Performance CSR' */
#define                otr_stall_txdma_credits_y   36           
#define                otr_opb_stall_mem_credits   37           /* The OTR/OPB engine has stalled due to not having credits available for requests to memory. */
#define             otr_opb_stall_mem_rsp_events   38           /* The OTR/OPB engine is waiting on memory responses and has no other work to do. */
#define             otr_opb_stall_mem_rsp_cycles   39           /* The OTR/OPB engine is waiting on memory responses and has no other work to do. */
#define                 otr_opb_stall_at_credits   40           /* The OTR/OPB engine has stalled due to a lack of available AT credits */
#define              otr_opb_stall_at_rsp_events   41           /* The OTR/OPB engine is waiting on AT responses and had no other work to do. */
#define              otr_opb_stall_at_rsp_cycles   42           /* The OTR/OPB engine is waiting on AT responses and had no other work to do. */
#define               otr_p_to_m_stall_credits_x   43           /* The OPB to OMB queues are stalled waiting on credits. The TC for this counter is selected in the OTR block.Cross Reference to X: Section 32.7.8.5, 'Stall Packet Partition to Message Partition Credits X Performance CSR'Cross Reference to Y: Section 32.7.8.6, 'Stall Packet Partition to Message Partition Credits Y Performance CSR' */
#define               otr_p_to_m_stall_credits_y   44           
#define           otr_pktid_list_conflict_replay   45           /* A PKTID update conflict caused a Tx command to be replayed through the pipeline. */
#define                   otr_psn_distance_stall   46           /* The OTR is stalled to enforce PSN distance */
#define                         otr_fastpath_req   47           /* Number of requests generated into the fastpath in OTR. */
#define                           otr_fragpe_req   48           /* Number of requests generated into the fragmentation path in OTR. */
#define                           otr_txdma_cmds   49           /* The number of commands issued from OTR to TXDMA. This may be more than one command per packet. */
#define                     otr_packets_opened_x   50           /* Total number of packets generated by OTR. Total packets is the sum of the fastpath packets and the fragmentation PE packets. This reflects the number of OPB entries allocated. The TC/MC is selected in the OTR block.Cross Reference to X: */
#define                     otr_packets_closed_x   51           /* Total number of packets completed by OTR. Total packets is the sum of the fastpath packets and the fragmentation PE packets. This represents the number of OPB entries closed. The TC/MC is selected in the OTR block.Cross Reference to X: */
#define                      otr_packets_retrans   52           /* Total number of retransmitted packets. Included NACK-based retransmit, timeout-based retransmit, and retransmits internally scheduled due to max sequence distance violations. */
#define                          otr_latency_0_a   53           /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was A or less.Note: granularity of the time is likely to be at least 1 millisecond.Cross Reference to A: Section 32.7.8.7, 'Latency Performance CSR' */
#define                          otr_latency_a_b   54           /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than A and less than or equal to B.Cross Reference to B: Section 32.7.8.7, 'Latency Performance CSR' */
#define                          otr_latency_b_c   55           /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than B and less than or equal to C.Cross Reference to C: Section 32.7.8.7, 'Latency Performance CSR' */
#define                          otr_latency_c_d   56           /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than C and less than or equal to D.Cross Reference to D: Section 32.7.8.7, 'Latency Performance CSR' */
#define                        otr_latency_d_max   57           /* Number of packets where the acknowledgement was received when the difference between the timestamp in the OPB and the current timestamp was greater than D. */
#define                 otr_retrans_limit_rchd_x   58           /* Retransmit Limit reached. This counter increments only once after the retransmission limit is reached for that TC. The TC for this counter is selected in the OTR block.Cross Reference to X: xref */
#define                   otr_cleanup_cmd_detect   59           /* Increments the counter when an cleanup command is detected in the OTR */
#define                    otr_local_seq_stall_x   60           /* Indicates that a local sequence has stalled due to the maximum distance between the oldest outstanding local packet sequence number and the next available local packet sequence number exceeding half of the sequence number space. This counter increments once when this condition is detected. The MC/TC for this counter is selected in the OTR block.Cross Reference to X: xref */
#define                               txpsn_hits   61           /* Number of hits in the TXPSN cache */
#define                               txpsn_miss   62           /* Number of misses in the TXPSN cache */
#define                         txpsn_fill_stall   63           /* Number of stall cycles due to the fill FIFO in the TXPSN cache being full */
#define                        txpsn_evict_stall   64           /* Number of stall cycles due to the evict FIFO in the TXPSN cache being full */
#define                             txpsn_evicts   65           /* Number of TXPSN cache evictions (capacity only, not CSR-based evictions) */
#define                       txpsn_membus_stall   66           /* Number of stall cycles due to the memory access port in the TXPSN cache being busy */
#define                       otr_pkt_reserved_a   67           /* Reserved */
#define                       otr_pkt_reserved_b   68           /* Reserved */
#define                       otr_pkt_reserved_c   69           /* Reserved */
#define                       otr_pkt_reserved_d   70           /* Reserved */
#define                           txdma_tx_reads   71           /* Total read accesses done over the TX interface to memory. */
#define                  txdma_mc1_packet_match0   72           /* A packet ,match triggered on MC1 */
#define                  txdma_mc1_packet_match1   73           /* A packet match triggered on MC1 */
#define                    txdma_tx_flits_tcmc_w   74           /* Total flits transmitted by TXDMA on a TC/MC as selected in the TXDMA block.Cross Reference to W: xrefCross Reference to X: xrefCross Reference to Y: xrefCross Reference to Z: xref */
#define                    txdma_tx_flits_tcmc_x   75           
#define                    txdma_tx_flits_tcmc_y   76           
#define                    txdma_tx_flits_tcmc_z   77           
#define                  txdma_stall_mem_credits   78           /* The TX DMA engine has stalled due to not having outstanding credits to memory available for use. */
#define               txdma_stall_mem_rsp_events   79           /* The TX DMA engine is waiting on memory responses and has no other work to do. */
#define               txdma_stall_mem_rsp_cycles   80           /* The TX DMA engine is waiting on memory responses and has no other work to do. */
#define                   txdma_stall_at_credits   81           /* The TX DMA engine has stalled due to a lack of available AT credits */
#define                txdma_stall_at_rsp_events   82           /* The TX DMA engine is waiting on AT responses and had no other work to do. */
#define                txdma_stall_at_rsp_cycles   83           /* The TX DMA engine is waiting on AT responses and had no other work to do. */
#define               txdma_stall_empty_events_x   84           /* Transmit DMA is stalled because there is nothing in the request pipeline. Event is counted once per event (i.e. input was not empty and then was empty). The TC/MC for this counter is selected in the TXDMA block.Cross Reference to X: xrefCross Reference to Y: xref */
#define               txdma_stall_empty_events_y   85           
#define                    txdma_stall_credits_x   86           /* Transmit DMA is stalled because it has no credits for the Link Mux. The TC/MC for this counter is selected in the TXDMA block.Cross Reference to X: xrefCross Reference to Y: xref */
#define                    txdma_stall_credits_y   87           
#define                  txdma_mc0_packet_match0   88           /* A generic packet header match triggered (matching logic TBD) */
#define                  txdma_mc0_packet_match1   89           
#define                  txdma_mc0_packet_match2   90           
#define                  txdma_mc0_packet_match3   91           
#define                         txdma_reserved_a   92           /* Reserved */
#define                         txdma_reserved_b   93           /* Reserved */
#define                         txdma_reserved_c   94           /* Reserved */
#define                         txdma_reserved_d   95           /* Reserved */
#define                         lm_fecn_rcvd_pt0   96           /* Count of the number of packets received on port 0 that are marked with FECN. */
#define                         lm_becn_rcvd_pt0   97           /* Count of the number of packets received on port 0 that are marked with BECN. */
#define                         lm_pkts_sent_pt0   98           /* Count of the number of packets sent on port 0 */
#define                         lm_pkts_rcvd_pt0   99           /* Count of the number of packets received on port 0 */
#define                     lm_stall_rm_fifo_pt0   100          /* Number of cycles stalled because the rate matching FIFO on Port 0 is full */
#define                             lm_byp_pkt_x   101          /* MCTC counter increment signal for the bypass send to self packets Cross Reference to X: xrefCross Reference to Y: yrefCross Reference to z: zref */
#define                             lm_byp_pkt_y   102          
#define                             lm_byp_pkt_z   103          
#define                           lm_byp_qflit_x   104          /* MCTC counter increment signal for the bypass send to self qflitsCross Reference to X: xrefCross Reference to Y: yrefCross Reference to z: zref */
#define                           lm_byp_qflit_y   105          
#define                           lm_byp_qflit_z   106          
#define                            lm_byp_wait_x   107          /* MCTC counter increment signal for the bypass send to self, the MCTC data available but fifo is full.Cross Reference to X: xrefCross Reference to Y: yrefCross Reference to z: zref */
#define                            lm_byp_wait_y   108          
#define                            lm_byp_wait_z   109          
#define                        lm_xmit_multicast   110          /* Count the Multicast Packets being transmitted. */
#define                            lm_reserved_a   111          /* Reserved */
#define                            lm_reserved_b   112          /* Reserved */
#define                            lm_reserved_c   113          /* Reserved */
#define                            lm_reserved_d   114          /* Reserved */
#define                            lm_reserved_e   115          /* Reserved */
#define                            lm_reserved_f   116          /* Reserved */
#define                            lm_reserved_g   117          /* Reserved */
#define                            lm_reserved_h   118          /* Reserved */
#define               rxci_stall_cq_empty_events   119          /* User receive command queues are stalled because all command queues are empty. Event is counted once per event (i.e. CQs were not empty and then were empty). */
#define                       rxci_slots_written   120          /* Total Number of slots written into the Rx Command queue (either in full 64B writes or by partial writes). */
#define                  rxci_nonfull_slot_write   121          /* A slot in the RX Command queue was partially written (less than 64B written is a single transaction. */
#define                  rxci_stall_rxhp_credits   122          /* Receive command queues are stalled because no credits are available in the downstream interface (RXHP). Commands must be available for this event to be counted. */
#define                                rxci_cmds   123          /* Number of commands processed by the RXCI interface */
#define                          rxci_reserved_a   124          /* Reserved */
#define                          rxci_reserved_b   125          /* Reserved */
#define                          rxci_reserved_c   126          /* Reserved */
#define                          rxci_reserved_d   127          /* Reserved */
#define                  rxe2e_no_big_scoreboard   128          /* Number of unordered packets wanting a big scoreboard, but unable to obtain one */
#define                  rxe2e_beyond_scoreboard   129          /* Number of unordered packets that arrived with a packet sequence number (PSN) that could not be scored in either a small scoreboard or a big scoreboard */
#define                      rxe2e_psn_dist_0_31   130          /* Number of unordered packets that arrived with a PSN distance from expected psn of 0-31 */
#define                     rxe2e_psn_dist_32_63   131          /* Number of unordered packets that arrived with a PSN distance from expected psn of 32-63. */
#define                    rxe2e_psn_dist_64_127   132          /* Number of unordered packets that arrived with a PSN distance from expected psn of 64-127 */
#define                   rxe2e_psn_dist_128_255   133          /* Number of unordered packets that arrived with a PSN distance from expected psn of 128-255 */
#define                   rxe2e_psn_dist_256_511   134          /* Number of unordered packets that arrived with a PSN distance from expected psn of 256-511 */
#define                   rxe2e_psn_dist_512_767   135          /* Number of unordered packets that arrived with a PSN distance from expected psn of 512-767 */
#define                  rxe2e_psn_dist_768_plus   136          /* Number of unordered packets that arrived with a PSN that exceeds the expected sequence number by 768 or more */
#define                  rxe2e_mc0_packet_match0   137          /* A generic MC0 packet header match triggered (matching logic TBD) */
#define                  rxe2e_mc0_packet_match1   138          /* A generic MC0 packet header match triggered (matching logic TBD) */
#define                  rxe2e_mc0_packet_match2   139          /* A generic MC0 packet header match triggered (matching logic TBD) */
#define                  rxe2e_mc0_packet_match3   140          /* A generic MC0 packet header match triggered (matching logic TBD) */
#define                  rxe2e_mc1_packet_match0   141          /* A generic MC1 packet header match triggered (matching logic TBD) */
#define                  rxe2e_mc1_packet_match1   142          /* A generic MC1 packet header match triggered (matching logic TBD) */
#define                               rxpsn_hits   143          /* Number of hits in the RXPSN cache */
#define                               rxpsn_miss   144          /* Number of misses in the RXPSN cache */
#define                         rxpsn_fill_stall   145          /* Number of stall cycles due to the fill FIFO in the RXPSN cache being full */
#define                        rxpsn_evict_stall   146          /* Number of stall cycles due to the evict FIFO in the RXPSN cache being full */
#define                             rxpsn_evicts   147          /* Number of RXPSN cache evictions (capacity only, not CSR-based evictions) */
#define                       rxpsn_membus_stall   148          /* Number of stall cycles due to the memory access port in the RXPSN cache being busy */
#define                         rxe2e_reserved_a   149          /* Reserved */
#define                         rxe2e_reserved_b   150          /* Reserved */
#define                         rxe2e_reserved_c   151          /* Reserved */
#define                         rxe2e_reserved_d   152          /* Reserved */
#define                         rxe2e_reserved_e   153          /* Reserved */
#define                         rxe2e_reserved_f   154          /* Reserved */
#define                         rxe2e_reserved_g   155          /* Reserved */
#define                         rxe2e_reserved_h   156          /* Reserved */
#define                         rxe2e_reserved_i   157          /* Reserved */
#define                         rxe2e_reserved_j   158          /* Reserved */
#define                         rxe2e_reserved_k   159          /* Reserved */
#define                            rxhp_fastpath   160          /* Number of requests entering the RXHP fastpath */
#define                             rxhp_rpc0_t0   161          /* Number of requests utilizing RPC0 thread 0 */
#define                             rxhp_rpc0_t1   162          /* Number of requests utilizing RPC0 thread 1 */
#define                             rxhp_rpc0_t2   163          /* Number of requests utilizing RPC0 thread 2 */
#define                             rxhp_rpc0_t3   164          /* Number of requests utilizing RPC0 thread 3 */
#define                             rxhp_rpc1_t0   165          /* Number of requests utilizing RPC1 thread 0 */
#define                             rxhp_rpc1_t1   166          /* Number of requests utilizing RPC1 thread 1 */
#define                             rxhp_rpc1_t2   167          /* Number of requests utilizing RPC1 thread 2 */
#define                             rxhp_rpc1_t3   168          /* Number of requests utilizing RPC1 thread 3 */
#define                                 rxhp_pe0   169          /* Number of requests for the RXHP PE0 pipeline */
#define                                 rxhp_pe1   170          /* Number of requests for the RXHP PE1 pipeline */
#define                                 rxhp_pe2   171          /* Number of requests for the RXHP PE2 pipeline */
#define                                 rxhp_pe3   172          /* Number of requests for the RXHP PE3 pipeline */
#define                                 rxhp_put   173          /* Number of Put operations handled by RXHP */
#define                                 rxhp_get   174          /* Number of Get operations handled by RXHP (fetchingoperations also increment the Get count) */
#define                              rxhp_atomic   175          /* Number of Atomic operations handled by RXHP. Vector atomics increment this once permessage. */
#define                                 rxhp_vop   176          /* Number of Verbs over Portals operations handled by RXHP */
#define                                rxhp_gen1   177          /* Number of PSM/OFED operations handled by RXHP */
#define                                  rxhp_to   178          /* Number of triggered operations handled by the RXHP */
#define                                 rxhp_rts   179          /* Number of Request-to-send operations handled by the RXHP */
#define               rxhp_stall_rxdma_credits_x   180          /* Header processing stalls due to insufficient credits toissue RXDMA commands. The TC is selected in RXHP.Cross Reference to X: xref */
#define               rxhp_stall_rxdma_credits_y   181          /* Cross Reference to Y: xref */
#define                      rxhp_et_resrv_stall   182          /* Number of cycles an input into RXHP arbiter was stalled due to an ET reservation stall condition */
#define                  rxhp_pid_conflict_stall   183          /* Header processing pipeline is stalled due to PID conflicts.This event only counts if the next packet is able to issuebased on RXDMA credits. */
#define                       rxhp_pe_busy_stall   184          /* Header processing pipeline is stalled due to all PEs beingbusy. This event only counts if the next packet is able toissue (no RXDMA credit stalls, no PID conflicts) */
#define                rxhp_pkt_status_rpc_stall   185          /* RPC pipeline is stalled due a lack of status good from RXE2E */
#define                 rxhp_pkt_status_fp_stall   186          /* FP pipeline is stalled due a lack of status good from RXE2E */
#define                      rxhp_rpc_busy_stall   187          /* RPC pipeline is stalled due to all RPCs beingbusy. This event only counts if the next packet is able toissue (no RXDMA credit stalls, no PID conflicts) */
#define                       rxhp_psc_req_stall   188          /* More than one request is arbitrating for PSC pipeline.This event counts how many total cycles the conflictingrequests are delayed. */
#define                       rxhp_psc_rsp_stall   189          /* More than one response is arbitrating from the PSC pipeline.This event counts how many total cycles the conflictingrequests are delayed. */
#define                           pte_cache_hits   190          /* Number of hits in the PTE cache */
#define                           pte_cache_miss   191          /* Number of misses in the PTE cache */
#define                     pte_cache_fill_stall   192          /* Number of stall cycles due to the fill FIFO in the PortalTable Entry (PTE) cache being full */
#define                    pte_cache_evict_stall   193          /* Number of stall cycles due to the evict FIFO in the PortalTable Entry (PTE) cache being full */
#define                         pte_cache_evicts   194          /* Number of Portal Table Entry (PTE) cache evictions(capacity only, not CSR-based evictions) */
#define                   pte_cache_membus_stall   195          /* Number of stall cycles due to the memory access port inthe Portal Table Entry (PTE) cache being busy */
#define                           psc_cache_hits   196          /* Number of hits in the Portals State Cache (PSC) per bank path (prim and sec) */
#define                           psc_cache_miss   197          /* Number of misses in the Portals State Cache (PSC) per bank path (prim and sec) */
#define                     psc_cache_fill_stall   198          /* Number of stall cycles due to the fill FIFO in the PortalsState Cache (PSC) being full */
#define                    psc_cache_evict_stall   199          /* Number of stall cycles due to the evict FIFO in the PortalsState Cache (PSC) being full */
#define                         psc_cache_evicts   200          /* Number of Portals State Cache (PSC) evictions(capacity only, not CSR-based evictions) */
#define                   psc_cache_membus_stall   201          /* Number of stall cycles due to the memory access port inthe Portals State Cache (PSC) being busy */
#define                    psc_cache_cmd_port0_x   202          /* Count of PSC cache commands by command type X on port 0.  Cross Reference to X: xref */
#define                    psc_cache_cmd_port1_x   203          /* Count of PSC cache commands by command type X on port 1. Cross Reference to X: xref */
#define                    psc_cache_cmd_bank0_x   204          /* Count of PSC cache commands by command type X on bank 0. Cross Reference to X: xref */
#define                    psc_cache_cmd_bank1_x   205          /* Count of PSC cache commands by command type X on bank 1. Cross Reference to X: xref */
#define                rxhp_digest_matches_port0   206          /* Number of times the digest filter was not sufficient (hence it matches) to allow the walker to skip reading the full entry on port 0 */
#define                rxhp_digest_matches_port1   207          /* Number of times the digest filter was not sufficient (hence it matches) to allow the walker to skip reading the full entry on port 1 */
#define                         rxhp_cmd_q_empty   208          /* Number of cycles the command queue into the RXHP arbiter is empty */
#define                       rxhp_req_q_empty_x   209          /* Number of cycles the X TC request queue into the RXHP arbiter is empty. Cross Reference to X: xref */
#define                       rxhp_mem_lat_count   210          /* Number of memory requests that we have tracked latency for.  (Divide RXHP_MEM_LAT_CYCLES by this counter to get average round trip memory latency for the caches). */
#define                      rxhp_mem_lat_cycles   211          /* Number of cycles all tracked memory requests from PSC or PTE spent outstanding */
#define                          rxhp_reserved_a   212          /* Reserved */
#define                          rxhp_reserved_b   213          /* Reserved */
#define                          rxhp_reserved_c   214          /* Reserved */
#define                          rxhp_reserved_d   215          /* Reserved */
#define                          rxhp_reserved_e   216          /* Reserved */
#define                          rxhp_reserved_f   217          /* Reserved */
#define                          rxhp_reserved_g   218          /* Reserved */
#define                          rxhp_reserved_h   219          /* Reserved */
#define                          rxhp_reserved_i   220          /* Reserved */
#define                          rxhp_reserved_j   221          /* Reserved */
#define                          rxhp_reserved_k   222          /* Reserved */
#define                          rxhp_reserved_l   223          /* Reserved */
#define                          rxdma_rx_writes   224          /* Total write accesses done over the RX interface to HIARB. An atomic counts as a write. A fetching atomic counts as a write and a read. This includes event writes. */
#define                           rxdma_rx_reads   225          /* Total read accesses done over the RX interface to HIARB. A fetching atomic counts as a write and a read. */
#define                    rxdma_rx_flits_tcmc_x   226          /* Total flits received by RXDMA on a TC/MC as selected in the RXDMA block.Appendix , 'rx_flits_mctc_x'Appendix , 'rx_flits_mctc_y' */
#define                    rxdma_rx_flits_tcmc_y   227          
#define           rxdma_stall_mem_credits_cycles   228          /* The RX DMA engine has stalled due to not having available outstanding credits to memory. Total stalled cycles are counted. */
#define               rxdma_stall_mem_rsp_events   229          /* The RX DMA engine is waiting on memory responses and has no other work to do. Stalls are counted once per event. */
#define               rxdma_stall_mem_rsp_cycles   230          /* The RX DMA engine is waiting on memory responses and has no other work to do. Total stalled cycles are counted. */
#define               rxdma_stall_empty_events_x   231          /* Receive DMA is stalled because there is nothing in the request pipeline. Event is counted once per event (i.e. input was not empty and then was empty). The TC/MC for this counter is selected in the RXDMA block.Appendix , 'no_cmd_mctc_x'Appendix , 'no_cmd_mctc_y' */
#define               rxdma_stall_empty_events_y   232          
#define                    rxdma_stall_credits_x   233          /* Receive DMA is stalled because it has no credits for the HI ARB. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'no_credits_mctc_x'Appendix , 'no_credits_mctc_y' */
#define                    rxdma_stall_credits_y   234          
#define                     rxdma_stall_no_cmd_x   235          /* Receive DMA is stalled because it has data, but does not have a command. The MC/TC is selected by a CSR in the RXDMA block.Appendix , 'no_cmd_mctc_x'Appendix , 'no_cmd_mctc_y' */
#define                     rxdma_stall_no_cmd_y   236          
#define               rxdma_stall_no_txci_cred_x   237          /* Receive DMA is stalled because it does not have credits to the TX command interface to generate the ACK/Reply to the TxCI. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'tx_ci_mctc_x'Appendix , 'tx_ci_mctc_y' */
#define               rxdma_stall_no_txci_cred_y   238          
#define              rxdma_stall_no_txdma_cred_x   239          /* Receive DMA is stalled because it does not have credits to the TX command interface to generate the ACK/Reply to the TxDMA. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'tx_dma_mctc_x'Appendix , 'tx_dma_mctc_y' */
#define              rxdma_stall_no_txdma_cred_y   240          
#define                    rxdma_stall_to_cred_x   241          /* Receive DMA is stalled because it does not have credits to the Triggered Op Request logic to request TOs for processing. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'to_mctc_x'Appendix , 'to_mctc_y' */
#define                    rxdma_stall_to_cred_y   242          
#define                   rxdma_stall_tid_full_x   243          /* RXDMA TID buffer is full and stalling future gets. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'tid_mctc_x'Appendix , 'tid_mctc_y' */
#define                   rxdma_stall_tid_full_y   244          
#define                   rxdma_stall_ack_full_x   245          /* RXDMA Acknowledgment buffers is full and stalling future gets. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'ack_mctc_x'Appendix , 'ack_mctc_y' */
#define                   rxdma_stall_ack_full_y   246          
#define                   rxdma_stall_war_full_x   247          /* RXDMA WAR buffer is full and stalling future gets. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'war_mctc_x'Appendix , 'war_mctc_y' */
#define                   rxdma_stall_war_full_y   248          
#define                    rxdma_trig_op_issue_x   249          /* RXDMA successfully issued a Triggered Op to the TxCI. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'to_issue_mctc_x'Appendix , 'to_issue_mctc_y' */
#define                    rxdma_trig_op_issue_y   250          
#define                    rxdma_trig_op_queue_x   251          /* RXDMA sent a Cache Line of Triggered Op Pointers to user memory. A Cache Line contains 16 pointers. The TC/MC for this counter is selected in the RXDMA block.Appendix , 'to_queue_mctc_x'Appendix , 'to_queue_mctc_y' */
#define                    rxdma_trig_op_queue_y   252          
#define                     rxdma_trig_op_append   253          /* A Triggered Op Append command completed with the CT Update in the RxDMA. */
#define                         rxdma_reserved_a   254          /* Reserved */
#define                         rxdma_reserved_b   255          /* Reserved */
#define                            ct_cache_hits   256          /* Number of hits in the CT cache */
#define                            ct_cache_miss   257          /* Number of misses in the CT cache */
#define                    ct_cache_writethrough   258          /* Number of write-through writes from CT cache */
#define                      ct_cache_fill_stall   259          /* Number of stall cycles due to the fill FIFO in the CT cache being full */
#define                     ct_cache_evict_stall   260          /* Number of stall cycles due to the evict FIFO in the CT cache being full */
#define                          ct_cache_evicts   261          /* Number of CT cache evictions (capacity only, not CSR-based evictions) */
#define                    ct_cache_membus_stall   262          /* Number of stall cycles due to the memory access port in the CT cache being busy */
#define                           eqd_cache_hits   263          /* Number of hits in the EQ descriptor cache */
#define                           eqd_cache_miss   264          /* Number of misses in the EQ descriptor cache */
#define                     eqd_cache_fill_stall   265          /* Number of stall cycles due to the fill FIFO in the EQ descriptor cache being full */
#define                    eqd_cache_evict_stall   266          /* Number of stall cycles due to the evict FIFO in the EQ descriptor cache being full */
#define                         eqd_cache_evicts   267          /* Number of EQ descriptor cache evictions (capacity only, not CSR-based evictions) */
#define                   eqd_cache_membus_stall   268          /* Number of stall cycles due to the memory access port in the EQ descriptor cache being busy */
#define                       trig_op_cache_hits   269          /* Number of hits in the Triggered Operation cache */
#define                       trig_op_cache_miss   270          /* Number of misses in the Triggered Operation cache */
#define                 trig_op_cache_fill_stall   271          /* Number of stall cycles due to the fill FIFO in the Triggered Operation cache being full */
#define                trig_op_cache_evict_stall   272          /* Number of stall cycles due to the evict FIFO in the Triggered Operation cache being full */
#define                     trig_op_cache_evicts   273          /* Number of Triggered Operation cache evictions (capacity only, not CSR-based evictions) */
#define               trig_op_cache_membus_stall   274          /* Number of stall cycles due to the memory access port in the Triggered Operation cache being busy */
#define                          rxet_reserved_a   275          /* Reserved */
#define                          rxet_reserved_b   276          /* Reserved */
#define                          rxet_reserved_c   277          /* Reserved */
#define                          rxet_reserved_d   278          /* Reserved */
#define                          rxet_reserved_e   279          /* Reserved */
#define                          rxet_reserved_f   280          /* Reserved */
#define                          rxet_reserved_g   281          /* Reserved */
#define                          rxet_reserved_h   282          /* Reserved */
#define                          rxet_reserved_i   283          /* Reserved */
#define                          rxet_reserved_j   284          /* Reserved */
#define                          rxet_reserved_k   285          /* Reserved */
#define                          rxet_reserved_l   286          /* Reserved */
#define                          rxet_reserved_m   287          /* Reserved */
#define                          at_tlb_accesses   288          /* Number of total translation requests */
#define                              at_tlb_miss   289          /* Number of Misses in the TLB cache */
#define                               at_tlb_hit   290          /* Number of Hits in the TLB cache */
#define                            at_tlb_evicts   291          /* Number of TLB cache evictions */
#define                           at_tlb_hits_4k   292          /* Number of hits in the TLB cache for 4K page entries */
#define                           at_tlb_hits_2m   293          /* Number of hits in the TLB cache for 2M page entries */
#define                           at_tlb_hits_1g   294          /* Number of hits in the TLB cache for 1G page entries */
#define                         at_tlb_evicts_4k   295          /* Number of TLB cache evictions for 4K page entries */
#define                         at_tlb_evicts_2m   296          /* Number of TLB cache evictions for 2M page entries */
#define                         at_tlb_evicts_1g   297          /* Number of TLB cache evictions for 1G page entries */
#define                         at_tlb_req_stall   298          /* Number of stalls due to the request FIFO to the IOMMU being full */
#define                        at_tlb_shootdowns   299          /* Number of shutdowns received from software */
#define                            at_reserved_a   300          /* Reserved */
#define                            at_reserved_b   301          /* Reserved */
#define                       rxhiarb_rxdma_reqs   320          /* Total requests received by HIARB from RXDMA port-head pointer updates: count here or in RXCID? */
#define                       rxhiarb_rxcid_reqs   321          /* Total requests received by HIARB from RXCID port-head pointer updates: count here or in RXCID? */
#define                        rxhiarb_rxhp_reqs   322          /* Total requests received by HIARB from RXHP port-count here or in RXHP? */
#define                        rxhiarb_rxet_reqs   323          /* Total requests received by HIARB from RXET port-counted by EQD cache + trig op cache? */
#define                       rxhiarb_rxe2e_reqs   324          /* Total requests received by HIARB from RXE2E port */
#define                         rxhiarb_hi_flits   325          /* Total number of request flits sent from HIARB to HI */
#define                  rxhiarb_hi_stall_cycles   326          /* Total clock cycles when the HIARB has an available request to send but is back-pressured by the HI */
#define                  rxhiarb_hi_stall_events   327          /* Number of times a stall occurs due to HI backpressure (counts once per stall interval) */
#define                         rxhiarb_at_flush   328          /* Number of AT flushes */
#define                  rxhiarb_at_flush_stalls   329          /* Total clock cycles during the period after an AT flush occurs and before the HIARB can send the next newly address translated request to the HI. This is intended to represent the total interruption in traffic flow due to AT flushes. */
#define              rxhiarb_stall_at_req_events   330          /* The RX HIARB engine has stalled due to a lack of available AT credits */
#define              rxhiarb_stall_at_req_cycles   331          /* The RX HIARB engine has stalled due to a lack of available AT credits */
#define              rxhiarb_stall_at_rsp_events   332          /* The RX HIARB engine is waiting on AT responses and had no other work to do. */
#define              rxhiarb_stall_at_rsp_cycles   333          /* The RX HIARB engine is waiting on AT responses and had no other work to do. */
#define                         rxhiarb_tlb_hits   334          /* Total number of requests that hit in the mini-TLB cache (regardless of presence state), This can be used in conjunction with RXHIARB_REQS to determine raw mini-TLB hit/miss rates. */
#define                 rxhiarb_tlb_present_hits   335          /* Total number of requests that hit in the mini-TLB cache 'and' the physical address is available in the cache. This can be used in conjunction with RXHIARB_REQS to determine hit/miss rates to cache entries with a physical address present. */
#define                 rxhiarb_slow_resp_stalls   336          /* Count of number of stalls caused by using the low bandwidth paths back to RXHP and RXET. */
#define                   rxhiarb_resp_cnt_rxdma   337          /* Count number of responses from HI to RXDMA */
#define                    rxhiarb_resp_cnt_rxhp   338          /* Count number of responses from HI to RXHP */
#define                    rxhiarb_resp_cnt_rxet   339          /* Count number of responses from HI to RXET */
#define                   rxhiarb_resp_cnt_rxe2e   340          /* Count number of responses from HI to RXE2E */
#define                      rxhiarb_pcb_lookups   341          /* Total number of handle-based requests performing lookups to the PCB table. */
#define                  rxhiarb_stall_hq_events   342          /* The RX HIARB input queues are stalled waiting on holding queue entries to become free. */
#define                  rxhiarb_stall_hq_cycles   343          /* The RX HIARB input queues are stalled waiting on holding queue entries to become free. */
#define                     rxhiarb_at_match_cnt   344          /* Total number of 'matching' requests seeking a translated physical address from the AT. This will only monitor requests which miss in the mini-TLB. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section.-is this the matching latency measurement thing? */
#define                     rxhiarb_at_match_dly   345          /* Total number of clock cycles for 'matching' requests to obtain a translated physical address from the AT. This will only monitor requests which miss in the mini-TLB. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section. */
#define                    rxhiarb_mrd_match_cnt   346          /* Total number of 'matching' read requests. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section-is this the matching latency measurement thing? */
#define                    rxhiarb_mrd_match_dly   347          /* Total number of clock cycles for 'matching' read requests to have their response payload returned. The matching criteria and sampling control can be found in the TBD CSRs described in the HIARB's CSR section. */
#define                       rxhiarb_reserved_a   348          /* Reserved */
#define                       rxhiarb_reserved_b   349          /* Reserved */
#define                       rxhiarb_reserved_c   350          /* Reserved */
#define                       rxhiarb_reserved_d   351          /* Reserved */
#define                         pcim_hpi_req_cnt   352          
#define                     pcim_p2sb_np_req_cnt   353          
#define                     pcim_p2sb_pc_req_cnt   354          
#define                       pcim_iommu_req_cnt   355          
#define                          pcim_ur_req_cnt   356          
#define                    pcim_hpi_splt_req_cnt   357          
#define                   pcim_p2sb_splt_req_cnt   358          
#define                          pcim_hpi_fc_cnt   359          
#define                         pcim_p2sb_fc_cnt   360          
#define                       pcim_marb_p_fc_cnt   361          
#define                      pcim_marb_np_fc_cnt   362          
#define                     pcim_marb_cpl_fc_cnt   363          
#define                      pcim_marb_p_req_cnt   364          
#define                     pcim_marb_np_req_cnt   365          
#define                    pcim_marb_cpl_req_cnt   366          
#define                     pcim_io2p_np_req_cnt   367          
#define                      pcim_sb2p_p_req_cnt   368          
#define                     pcim_sb2p_np_req_cnt   369          
#define                    pcim_sb2p_cpl_req_cnt   370          
#define                      pcim_init_p_req_cnt   371          
#define                     pcim_hpi_cpl_req_cnt   372          
#define                          pcim_reserved_a   373          /* Reserved */
#define                          pcim_reserved_b   374          /* Reserved */
#define                          pcim_reserved_c   375          /* Reserved */
#define                          pcim_reserved_d   376          /* Reserved */
#define                          pcim_reserved_e   377          /* Reserved */
#define                          pcim_reserved_f   378          /* Reserved */
#define                          pcim_reserved_g   379          /* Reserved */
#define                          pcim_reserved_h   380          /* Reserved */
#define                          pcim_reserved_i   381          /* Reserved */
#define                          pcim_reserved_j   382          /* Reserved */
#define                          pcim_reserved_k   383          /* Reserved */
#define                   hi_loca_hcc_new_tx_req   384          /* New Tx sourced request count. Enabled by tx_cnt_ena. */
#define                   hi_loca_hcc_new_rx_req   385          /* New Rx sourced request count. Enabled by rx_cnt_ena. */
#define                   hi_loca_hcc_new_at_req   386          /* New AT sourced request count. Enabled by at_cnt_ena. */
#define                  hi_loca_hcc_new_get_req   387          /* New GET request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                  hi_loca_hcc_new_put_req   388          /* New PUT request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define               hi_loca_hcc_new_atomic_req   389          /* New ATOMIC request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define              hi_loca_hcc_new_fatomic_req   390          /* New FATOMIC request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                  hi_loca_hcc_new_zbr_req   391          /* New ZBR request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                  hi_loca_hcc_new_irq_req   392          /* New IRQ request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                  hi_loca_hcc_new_nop_req   393          /* New NOP request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                  hi_loca_hcc_new_fid_req   394          /* New FID request count. The GID/FID counted is selectedby the fid_cnt_id and fid_cnt_msk fields. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                 hi_loca_hcc_new_conq_req   395          /* Total number of New requests pushed to CONQ */
#define             hi_loca_parb_addr_replay_req   396          /* Address enabled Replay request count. */
#define            hi_loca_parb_order_replay_req   397          /* Order enabled Replay request count. */
#define                 hi_loca_hcc_replay_abort   398          /* Total number of aborted replay requests */
#define                    hi_loca_parb_fill_req   399          /* Fill request count. */
#define               hi_loca_hcc_fill_chain_req   400          /* Fill Pass request that temporally allocates a line in the cache for subsequent chaining with delayed requests */
#define                       hi_loca_hcc_0b_req   401          /* New 0 Byte request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                       hi_loca_hcc_sm_req   402          /* New (Small) request count with blen between 1-63 Bytes. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                      hi_loca_hcc_64b_req   403          /* New 64 Byte request count with blen equal 64B. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                     hi_loca_hcc_128b_req   404          /* New request count with blen between 65-128 Bytes. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                     hi_loca_hcc_256b_req   405          /* New request count with blen between 129-256 Bytes. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                      hi_loca_addr_range0   406          /* Request match for ADDR Range 0. Enabled by upper_addr_range and lower_addr_range. */
#define                      hi_loca_addr_range1   407          /* Request match for ADDR Range 1. Enabled by upper_addr_range and lower_addr_range. */
#define                      hi_loca_addr_range2   408          /* Request match for ADDR Range 2. Enabled by upper_addr_range and lower_addr_range. */
#define                      hi_loca_addr_range3   409          /* Request match for ADDR Range 3. Enabled by upper_addr_range and lower_addr_range. */
#define                     hi_loca_parb_proq_fc   410          /* Clock cycle count of PROQ flow control signaling due tolack of PROQ entries. */
#define                     hi_loca_parb_conq_fc   411          /* Clock cycle count of ConQ flow control signaling due tolack of ConQ entries. */
#define                      hi_loca_parb_new_fc   412          /* Clock cycle count of New/Replay Request flow controlsignaling due to lack of TIDs. */
#define                    hi_loca_parb_hifis_fc   413          /* Clock cycle count of HIFIS flow control signaling. */
#define           hi_loca_parb_new_timeout_stall   414          /* New request timeout cycles stalled by a New hazard. */
#define                 hi_loca_parb_new_timeout   415          /* New request timeout cycles at PARB head. */
#define        hi_loca_parb_replay_timeout_stall   416          /* Replay request timeout cycles stalled by a Replay hazard. */
#define              hi_loca_parb_replay_timeout   417          /* Replay request timeout cycles at PARB head. */
#define          hi_loca_parb_fill_timeout_stall   418          /* Fill request timeout cycles stalled by a New hazard. */
#define                hi_loca_parb_fill_timeout   419          /* Fill request timeout cycles at PARB head. */
#define          hi_loca_parb_emec_timeout_stall   420          /* EMEC request timeout cycles stalled by a EMEC hazard. */
#define                hi_loca_parb_emec_timeout   421          /* EMEC request timeout cycles at PARB head. */
#define                hi_loca_parb_new_fc_stall   422          /* New request cycles stalled by flow control. */
#define                hi_loca_parb_new_ic_stall   423          /* New request cycles stalled by PMI CAM hazard. */
#define                hi_loca_parb_new_pc_stall   424          /* New request cycles stalled by Pipe CAM hazard. */
#define                 hi_loca_parb_new_req_cyc   425          /* New request cycles count at PARB head. */
#define             hi_loca_parb_replay_fc_stall   426          /* Replay request cycles stalled by flow control. */
#define             hi_loca_parb_replay_ic_stall   427          /* Replay request cycles stalled by IMI CAM hazard. */
#define             hi_loca_parb_replay_pc_stall   428          /* Replay request cycles stalled by Pipe CAM hazard. */
#define              hi_loca_parb_replay_req_cyc   429          /* Replay request cycles count at PARB head. */
#define               hi_loca_parb_fill_fc_stall   430          /* Fill request cycles stalled by flow control. */
#define               hi_loca_parb_fill_ic_stall   431          /* Fill request cycles stalled by IMI CAM hazard. */
#define               hi_loca_parb_fill_pc_stall   432          /* Fill request cycles stalled by Pipe CAM hazard. */
#define                hi_loca_parb_fill_req_cyc   433          /* Fill request cycles count at PARB head. */
#define               hi_loca_parb_emec_fc_stall   434          /* EMEC request cycles stalled by flow control. */
#define               hi_loca_parb_emec_ic_stall   435          /* EMEC request cycles stalled by IMI CAM hazard. */
#define               hi_loca_parb_emec_pc_stall   436          /* EMEC request cycles stalled by Pipe CAM hazard. */
#define                hi_loca_parb_emec_req_cyc   437          /* EMEC request cycles count at PARB head. */
#define                    hi_loca_dcache_pmi_fc   438          /* LOCA Pipeline stall due to PMI back-pressure */
#define                     hi_loca_dcache_go_fc   439          /* LOCA Pipeline stall due to GO block back-pressure */
#define                    hi_loca_dcache_raw_fc   440          /* LOCA Pipeline stall due to Read-After-Write hazard */
#define                    hi_loca_dcache_ava_fc   441          /* LOCA Pipeline stall due to multi-cycle execution of a Vector Atomic request. */
#define                    hi_loca_dcache_alr_fc   442          /* LOCA Pipeline stall due to multi-cycle execution of a Large (>64B) GET or PUT request. */
#define                    hi_loca_pmi_req_stall   443          /* Valid PMI request stalled on Client IF to PCIC */
#define                hi_loca_hcc_alloc_get_req   444          /* Allocating GET request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                hi_loca_hcc_alloc_get_hit   445          /* Allocating GET request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                hi_loca_hcc_alloc_put_req   446          /* Allocating PUT request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                hi_loca_hcc_alloc_put_hit   447          /* Allocating PUT request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define             hi_loca_hcc_alloc_atomic_req   448          /* Allocating Atomic (fetching or not) request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define             hi_loca_hcc_alloc_atomic_hit   449          /* Allocating Atomic (fetching/not) request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define             hi_loca_hcc_nonalloc_get_req   450          /* Non-Allocating GET request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define             hi_loca_hcc_nonalloc_get_hit   451          /* Non-Allocating GET request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define             hi_loca_hcc_nonalloc_put_req   452          /* Non-Allocating PUT request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define             hi_loca_hcc_nonalloc_put_hit   453          /* Non-Allocating PUT request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define          hi_loca_hcc_nonalloc_atomic_req   454          /* Non-Allocating Atomic (fetching or not) request count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define          hi_loca_hcc_nonalloc_atomic_hit   455          /* Non-Allocating Atomic (fetching/not) request cache Hit count. Enabled by one or more of rx_cnt_ena,tx_cnt_ena,at_cnt_ena. */
#define                 hi_loca_hcc_alloc_dc_hit   456          /* Allocating Request Hit Count. All allocating requests */
#define                 hi_loca_hcc_alloc_dc_req   457          /* Allocating Request Count. */
#define                   hi_loca_hcc_all_dc_hit   458          /* All Request Hit Count. All requests (alloc or not) */
#define                   hi_loca_hcc_all_dc_req   459          /* All Request Count. */
#define                   hi_loca_hcc_fid_dc_hit   460          /* Flow ID based Request Hit Count. Enabled by fid_cnt_id/fid_cnt_msk */
#define                   hi_loca_hcc_fid_dc_req   461          /* Flow ID based Request Count. Enabled byfid_cnt_id/fid_cnt_msk */
#define             hi_loca_hcc_replay_chain_hit   462          /* Replay request that hits a chained cache line. Compare with HI_LOCA_HCC_FILL_CHAIN_REQ for Chain hit opportunities. */
#define                     hi_loca_pmi_read_req   463          /* Sampled PCIe Read requests count. */
#define                 hi_loca_pmi_read_latency   464          /* Sampled PCIe Read requests latency. Divide by HI_LOCA_PMI_READ_REQ to get average data response latency (in cclks). */
#define                  hi_loca_pmi_rxwrite_req   465          /* Sampled PCIe RX Write requests count. */
#define                 hi_loca_pmi_rxgo_latency   466          /* Sampled PCIe RX Write request latency to GO response. Divide by HI_LOCA_PMI_RXWRITE_REQ to get average GO latency (in cclks). */
#define                      hi_loca_dcache_read   467          /* DCache read cycles */
#define                     hi_loca_dcache_write   468          /* DCache Write cycles */
#define                     hi_loca_reserved_1d5   469          
#define                     hi_loca_reserved_1d6   470          
#define                     hi_loca_reserved_1d7   471          
#define                     hi_loca_reserved_1d8   472          
#define                     hi_loca_reserved_1d9   473          
#define                     hi_loca_reserved_1da   474          
#define                     hi_loca_reserved_1db   475          
#define                     hi_loca_reserved_1dc   476          
#define                     hi_loca_reserved_1dd   477          
#define                     hi_loca_reserved_1de   478          
#define                     hi_loca_reserved_1df   479          
#define                     hi_loca_reserved_1e0   480          
#define                     hi_loca_reserved_1e1   481          
#define                     hi_loca_reserved_1e2   482          
#define                     hi_loca_reserved_1e3   483          
#define                     hi_loca_reserved_1e4   484          
#define                     hi_loca_reserved_1e5   485          
#define                     hi_loca_reserved_1e6   486          
#define                     hi_loca_reserved_1e7   487          
#define                     hi_loca_reserved_1e8   488          
#define                     hi_loca_reserved_1e9   489          
#define                     hi_loca_reserved_1ea   490          
#define                     hi_loca_reserved_1eb   491          
#define                     hi_loca_reserved_1ec   492          
#define                     hi_loca_reserved_1ed   493          
#define                     hi_loca_reserved_1ee   494          
#define                     hi_loca_reserved_1ef   495          
#define                     hi_loca_reserved_1f0   496          
#define                     hi_loca_reserved_1f1   497          
#define                     hi_loca_reserved_1f2   498          
#define                     hi_loca_reserved_1f3   499          
#define                     hi_loca_reserved_1f4   500          
#define                     hi_loca_reserved_1f5   501          
#define                     hi_loca_reserved_1f6   502          
#define                     hi_loca_reserved_1f7   503          
#define                     hi_loca_reserved_1f8   504          
#define                     hi_loca_reserved_1f9   505          
#define                     hi_loca_reserved_1fa   506          
#define                     hi_loca_reserved_1fb   507          
#define                     hi_loca_reserved_1fc   508          
#define                     hi_loca_reserved_1fd   509          
#define                     hi_loca_reserved_1fe   510          
#define                     hi_loca_reserved_1ff   511           

#endif



#endif 		/* DEF_FXR_SW_SW_DEF */
